{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import copy\n",
    "import logging\n",
    "import re\n",
    "from itertools import chain,combinations\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from google.cloud import bigquery\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['LOGGING_FILE'] = \"../../../Local/logs/wallet_modeling.log\"\n",
    "os.environ['NOTIFICATION_SOUNDS_DIR'] = \"../../../Local\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.clustering_features as wcl\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.performance_features as wpf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.scenario_features as wsc\n",
    "import wallet_features.balance_features as wbf\n",
    "import wallet_features.macroeconomic_features as wmac\n",
    "import wallet_features.wallet_features_orchestrator as wfo\n",
    "\n",
    "# Base modeling\n",
    "import base_modeling.base_model as bm\n",
    "import base_modeling.feature_selection as fs\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_training_data_orchestrator as wtdo\n",
    "import wallet_modeling.wallet_epochs_orchestrator as weo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_insights.wallet_model_reporting as wmr\n",
    "import wallet_modeling.wallet_model as wm\n",
    "import wallet_modeling.experiments_manager as wem\n",
    "import wallet_modeling.wallets_config_manager  as wcm\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.model_evaluation as wime\n",
    "import wallet_insights.wallet_experiments_orchestrator as wimo\n",
    "import wallet_insights.wallet_validation_analysis as wiva\n",
    "import wallet_insights.wallet_cluster_analysis as wica\n",
    "\n",
    "# Coin features\n",
    "import coin_wallet_features.coin_features_orchestrator as cfo\n",
    "import coin_wallet_features.wallet_base_metrics as cwbm\n",
    "import coin_wallet_features.wallet_segmentation as cws\n",
    "\n",
    "# Coin modeling\n",
    "import coin_modeling.coin_model_reporting as cmr\n",
    "import coin_modeling.coin_model as cm\n",
    "\n",
    "# Coin insights\n",
    "import coin_insights.coin_validation_analysis as civa\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [\n",
    "    u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp,\n",
    "    wtdo, weo, wtd, wmr, wm, wem, wcm,\n",
    "    wcl, wmc, wmt, wtf, wpf, wts, wsc, wbf, wmac, wfo,\n",
    "    bm, fs,\n",
    "    wime, wimo, wiva, wica,\n",
    "    cfo, cwbm, cws,\n",
    "    cmr, cm,\n",
    "    civa,\n",
    "]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "wallets_config = WalletsConfig.load_from_yaml('../config/wallets_config.yaml')\n",
    "\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_epochs_config = yaml.safe_load(Path('../config/wallets_epochs_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# make parquet dirs if they don't already exist\n",
    "Path(wallets_config['training_data']['parquet_folder']).mkdir(parents=True, exist_ok=True)\n",
    "Path(wallets_coin_config['wallet_segments']['parquet_folder']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set the custom error handler\n",
    "ipython = IPython.get_ipython()\n",
    "ipython.set_custom_exc((Exception,), u.notify_on_failure)\n",
    "\n",
    "# configure logger\n",
    "logger = u.setup_notebook_logger('../logs/notebook_logs.log')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# u.export_code(\n",
    "#     code_directories=[\n",
    "#         # 'training_data',\n",
    "#         'wallet_features',\n",
    "#         # 'base_modeling',\n",
    "#         'wallet_modeling',\n",
    "#         # 'wallet_insights'\n",
    "#     ],\n",
    "#     # include_config = True,\n",
    "#     # ipynb_notebook = 'DDA-660 multithreading epochs.ipynb'\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "[importlib.reload(module) for module in modules]\n",
    "u.notify('retro')\n",
    "\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wallet Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiwindow Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load complete datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_epochs_config = yaml.safe_load(Path('../config/wallets_epochs_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Initiate orchestrator\n",
    "epochs_orchestrator = weo.MultiEpochOrchestrator(\n",
    "    wallets_config.config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    wallets_epochs_config\n",
    ")\n",
    "\n",
    "epochs_orchestrator.load_complete_raw_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate modeling features (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "parquet_folder = wallets_config['training_data']['parquet_folder']\n",
    "complete_profits_df = pd.read_parquet(f\"{parquet_folder}/complete_profits_df.parquet\")\n",
    "complete_market_data_df = pd.read_parquet(f\"{parquet_folder}/complete_market_data_df.parquet\")\n",
    "complete_macro_trends_df = pd.read_parquet(f\"{parquet_folder}/complete_macro_trends_df.parquet\")\n",
    "\n",
    "# Initiate orchestrator\n",
    "epochs_orchestrator = weo.MultiEpochOrchestrator(\n",
    "    wallets_config.config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    wallets_epochs_config,\n",
    "    complete_profits_df,\n",
    "    complete_market_data_df,\n",
    "    complete_macro_trends_df,\n",
    ")\n",
    "\n",
    "\n",
    "# Generate TRAINING_DATA_DF for all windows\n",
    "wallet_training_data_df, modeling_wallet_features_df = epochs_orchestrator.generate_epochs_training_data()\n",
    "\n",
    "# Save files\n",
    "wallet_training_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_wallet_training_data_df.parquet\",index=True)\n",
    "modeling_wallet_features_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_modeling_wallet_features_df.parquet\",index=True)\n",
    "\n",
    "# sorted(list(wallet_training_data_df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model without validation (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Load modeling files\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_wallet_training_data_df.parquet\")\n",
    "modeling_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_modeling_wallet_features_df.parquet\")\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(\n",
    "    wallet_training_data_df, modeling_wallet_features_df\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in wallet_model_results:\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    model_id, wallet_evaluator, modeling_wallet_scores_df = wmr.generate_and_save_wallet_model_artifacts(\n",
    "        model_results=wallet_model_results,\n",
    "        base_path='../artifacts/wallet_modeling',\n",
    "        configs = {\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "            'wallets_features_config': wallets_features_config\n",
    "        }\n",
    "    )\n",
    "    wallet_evaluator.summary_report()\n",
    "else:\n",
    "    display(wallet_model.generate_search_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate validation features (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_epochs_config = yaml.safe_load(Path('../config/wallets_epochs_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "complete_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_profits_df.parquet\")\n",
    "complete_market_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_market_data_df.parquet\")\n",
    "complete_macro_trends_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_macro_trends_df.parquet\")\n",
    "\n",
    "# Override base offsets\n",
    "validation_epochs_config = copy.deepcopy(wallets_epochs_config)\n",
    "validation_epochs_config['offset_epochs']['offsets'] = validation_epochs_config['offset_epochs']['validation_offsets']\n",
    "\n",
    "# Initiate orchestrator\n",
    "epochs_orchestrator = weo.MultiEpochOrchestrator(\n",
    "    wallets_config.config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    validation_epochs_config,\n",
    "    complete_profits_df,\n",
    "    complete_market_data_df,\n",
    "    complete_macro_trends_df\n",
    ")\n",
    "\n",
    "# Generate TRAINING_DATA_DF for the modeling period offset window\n",
    "validation_training_data_df, validation_wallet_features_df = epochs_orchestrator.generate_epochs_training_data()\n",
    "\n",
    "# Save files\n",
    "validation_training_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_wallet_training_data_df.parquet\",index=True)\n",
    "validation_wallet_features_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_wallet_features_df.parquet\",index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model w validation (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modeling and validation files\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_wallet_training_data_df.parquet\")\n",
    "wallet_training_data_df = u.df_downcast(wallet_training_data_df)\n",
    "modeling_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_modeling_wallet_features_df.parquet\")\n",
    "modeling_wallet_features_df = u.df_downcast(modeling_wallet_features_df)\n",
    "validation_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_wallet_training_data_df.parquet\")\n",
    "validation_training_data_df = u.df_downcast(validation_training_data_df)\n",
    "validation_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_wallet_features_df.parquet\")\n",
    "validation_wallet_features_df = u.df_downcast(validation_wallet_features_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(\n",
    "    # sampled_train_df, sampled_modeling_df,\n",
    "    wallet_training_data_df, modeling_wallet_features_df,\n",
    "    validation_training_data_df, validation_wallet_features_df\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in wallet_model_results:\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    model_id, wallet_evaluator, modeling_wallet_scores_df = wmr.generate_and_save_wallet_model_artifacts(\n",
    "        model_results=wallet_model_results,\n",
    "        base_path='../artifacts/wallet_modeling',\n",
    "        configs = {\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "            'wallets_features_config': wallets_features_config,\n",
    "            'wallets_epochs_config': wallets_epochs_config\n",
    "        }\n",
    "    )\n",
    "    wallet_evaluator.summary_report()\n",
    "else:\n",
    "    display(wallet_model.generate_search_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(\n",
    "    # sampled_train_df, sampled_modeling_df,\n",
    "    wallet_training_data_df, modeling_wallet_features_df,\n",
    "    validation_training_data_df, validation_wallet_features_df\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in wallet_model_results:\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    model_id, wallet_evaluator, modeling_wallet_scores_df = wmr.generate_and_save_wallet_model_artifacts(\n",
    "        model_results=wallet_model_results,\n",
    "        base_path='../artifacts/wallet_modeling',\n",
    "        configs = {\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "            'wallets_features_config': wallets_features_config,\n",
    "            'wallets_epochs_config': wallets_epochs_config\n",
    "        }\n",
    "    )\n",
    "    wallet_evaluator.summary_report()\n",
    "else:\n",
    "    display(wallet_model.generate_search_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Reload evaluator\n",
    "wallet_evaluator = wime.ClassifierEvaluator(wallet_model_results)\n",
    "# Print results\n",
    "logger.info(f\"\\n{wallet_evaluator.summary_report()}\")\n",
    "wallet_evaluator.plot_wallet_evaluation()\n",
    "wallet_evaluator.importance_summary(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assess segment performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "pd.set_option('display.max_colwidth', None)  # Shows full text in columns\n",
    "\n",
    "\n",
    "# Reload evaluator\n",
    "wallet_evaluator = wime.RegressionEvaluator(wallet_model_results)\n",
    "\n",
    "segmentation_features = [\n",
    "    # 'mktcap|portfolio_mcap_mean/market_cap_unadj|all_windows',\n",
    "    'mktcap|volume_wtd_market_cap/market_cap_filled|all_windows',\n",
    "    # 'timing|btc_mvrv_z_score/buy_weighted|all_windows',\n",
    "    # 'timing|btc_mvrv_z_score/sell_weighted|all_windows',\n",
    "    # 'macro|btc_mvrv_z_score_first|all_windows',\n",
    "    # 'macro|btc_mvrv_z_score_last|all_windows',\n",
    "    'trading|crypto_net_gain|all_windows',\n",
    "    'trading|total_volume|all_windows',\n",
    "    'trading|crypto_net_cash_flows|all_windows',\n",
    "    'trading|unique_coins_traded|all_windows',\n",
    "    # 'transfers|first_buy/median_avg_wallet_rank|all_windows',\n",
    "    'trading|max_investment|all_windows'\n",
    "]\n",
    "segmentation_features = [\n",
    "    # 'mktcap|portfolio_mcap_mean/market_cap_unadj|w5',\n",
    "    'mktcap|volume_wtd_market_cap/market_cap_filled|w5',\n",
    "    # 'timing|btc_mvrv_z_score/buy_weighted|w5',\n",
    "    # 'timing|btc_mvrv_z_score/sell_weighted|w5',\n",
    "    # 'macro|btc_mvrv_z_score_first|w5',\n",
    "    # 'macro|btc_mvrv_z_score_last|w5',\n",
    "    'trading|crypto_net_gain|w5',\n",
    "    'trading|total_volume|w5',\n",
    "    'trading|crypto_net_cash_flows|w5',\n",
    "    'trading|unique_coins_traded|w5',\n",
    "    # 'transfers|first_buy/median_avg_wallet_rank|w5',\n",
    "    'trading|max_investment|w5'\n",
    "]\n",
    "\n",
    "\n",
    "# get raw segments\n",
    "segments_df = wallet_evaluator.identify_predictive_populations(\n",
    "    segmentation_features,\n",
    "    min_pop_pct=0.02,\n",
    "    max_segments=25\n",
    ")\n",
    "\n",
    "# coerce the formatted strings to numbers, then sort\n",
    "# segments_df.sort_values('RMSE vs Overall', ascending=True)\n",
    "segments_df.sort_values('R2 vs Overall', ascending=False)\n",
    "# segments_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "pd.set_option('display.max_colwidth', None)  # Shows full text in columns\n",
    "\n",
    "\n",
    "# Reload evaluator\n",
    "wallet_evaluator = wime.RegressionEvaluator(wallet_model_results)\n",
    "\n",
    "segmentation_features = [\n",
    "    # 'mktcap|portfolio_mcap_mean/market_cap_unadj|all_windows',\n",
    "    'mktcap|volume_wtd_market_cap/market_cap_filled|all_windows',\n",
    "    # 'timing|btc_mvrv_z_score/buy_weighted|all_windows',\n",
    "    # 'timing|btc_mvrv_z_score/sell_weighted|all_windows',\n",
    "    # 'macro|btc_mvrv_z_score_first|all_windows',\n",
    "    # 'macro|btc_mvrv_z_score_last|all_windows',\n",
    "    'trading|crypto_net_gain|all_windows',\n",
    "    'trading|total_volume|all_windows',\n",
    "    'trading|crypto_net_cash_flows|all_windows',\n",
    "    'trading|unique_coins_traded|all_windows',\n",
    "    # 'transfers|first_buy/median_avg_wallet_rank|all_windows',\n",
    "    'trading|max_investment|all_windows'\n",
    "]\n",
    "\n",
    "\n",
    "# get raw segments\n",
    "segments_df = wallet_evaluator.identify_predictive_populations(\n",
    "    segmentation_features,\n",
    "    min_pop_pct=0.02,\n",
    "    max_segments=25\n",
    ")\n",
    "\n",
    "# coerce the formatted strings to numbers, then sort\n",
    "# segments_df.sort_values('RMSE vs Overall', ascending=True)\n",
    "segments_df.sort_values('R2 vs Overall', ascending=False)\n",
    "# segments_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_df.sort_values('R2 vs Overall', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_evaluator.importance_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Reload evaluator\n",
    "wallet_evaluator = wime.RegressionEvaluator(wallet_model_results)\n",
    "\n",
    "feature_importances_df = wiva.analyze_wallet_model_importance(wallet_evaluator.metrics['importances'])\n",
    "feature_importances_df = feature_importances_df.copy()\n",
    "\n",
    "feature_categories_filter = [\n",
    "    # 'performance',\n",
    "    'timing',\n",
    "    # 'trading',\n",
    "    # 'transfers',\n",
    "    # 'mktcap',\n",
    "    # 'scenario',\n",
    "    # 'macro',\n",
    "    # 'cluster',\n",
    "]\n",
    "\n",
    "feature_names_filter = [\n",
    "    'price_sma_2',\n",
    "    # 'price_rsi_5',\n",
    "    # 'volume_sma_5',\n",
    "    # 'market_cap_filled',\n",
    "    # 'mktcap',\n",
    "    # 'cluster',\n",
    "    # 'btc_mvrv_z_score',\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    'feature_category',\n",
    "    'feature_name',\n",
    "    'feature_comparison',\n",
    "    'feature_aggregation',\n",
    "    # 'training_segment',\n",
    "    'feature'\n",
    "]\n",
    "\n",
    "(feature_importances_df\n",
    " [feature_importances_df['feature_category'].isin(feature_categories_filter)]\n",
    " [feature_importances_df['feature_name'].isin(feature_names_filter)]\n",
    " .fillna('None').groupby(groups)\n",
    " .sum('importance')\n",
    " .sort_values(by='importance',ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modeling multi window r2 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = sorted(list(modeling_wallet_scores_df.index.get_level_values('epoch_start_date').unique()))\n",
    "\n",
    "for epoch in epochs:\n",
    "    epoch_mask = modeling_wallet_scores_df.index.get_level_values('epoch_start_date') == epoch\n",
    "    # Add cohort filter\n",
    "    cohort_mask = modeling_wallet_scores_df['in_modeling_cohort'] == True\n",
    "    combined_mask = epoch_mask & cohort_mask\n",
    "\n",
    "    y_true = modeling_wallet_scores_df[combined_mask]['actual']\n",
    "    y_pred = modeling_wallet_scores_df[combined_mask]['score']\n",
    "\n",
    "    # Skip epochs with no actual values\n",
    "    if y_true.isna().all():\n",
    "        continue\n",
    "\n",
    "    metrics = wiva.evaluate_predictions(y_true, y_pred)\n",
    "    print(f\"Epoch {epoch}: R² = {metrics['r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dda 695 coin prices vs hybrid features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Source Data\n",
    "parquet_folder = wallets_config['training_data']['parquet_folder']\n",
    "complete_profits_df = pd.read_parquet(f\"{parquet_folder}/complete_profits_df.parquet\")\n",
    "complete_market_data_df = pd.read_parquet(f\"{parquet_folder}/complete_market_data_df.parquet\")\n",
    "complete_macro_trends_df = pd.read_parquet(f\"{parquet_folder}/complete_macro_trends_df.parquet\")\n",
    "\n",
    "# Initiate orchestrator\n",
    "epochs_orchestrator = weo.MultiEpochOrchestrator(\n",
    "    wallets_config.config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    wallets_epochs_config,\n",
    "    complete_profits_df,\n",
    "    complete_market_data_df,\n",
    "    complete_macro_trends_df,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_wallet_training_data_df.parquet\")\n",
    "wallet_training_data_df = u.df_downcast(wallet_training_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_training_data_df['hybrid_cw_id'] = wallet_training_data_df.index.get_level_values('wallet_address')\n",
    "coin_training_data_df = wallet_training_data_df.merge(epochs_orchestrator.complete_hybrid_cw_id_df, how='inner', on='hybrid_cw_id')\n",
    "coin_training_data_df = coin_training_data_df.set_index('coin_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_coin_features(coin_training_data_df):\n",
    "    \"\"\"\n",
    "    Aggregate features by coin_id, computing sum, count, mean, and median for all columns.\n",
    "\n",
    "    Params:\n",
    "    - coin_training_data_df (DataFrame): Coin-wallet level feature data\n",
    "\n",
    "    Returns:\n",
    "    - coin_features_df (DataFrame): Coin-level aggregated features\n",
    "    \"\"\"\n",
    "    # Reset index to make coin_id a column for proper groupby\n",
    "    df = coin_training_data_df.reset_index()\n",
    "\n",
    "    # Define aggregations to apply to all numeric columns\n",
    "    aggregations = ['sum', 'count', 'mean', 'median']\n",
    "\n",
    "    # Group by coin_id and apply aggregations\n",
    "    # Exclude non-numeric columns that shouldn't be aggregated\n",
    "    exclude_cols = ['hybrid_cw_id', 'wallet_address']\n",
    "    numeric_cols = [col for col in df.columns if col not in exclude_cols and col != 'coin_id']\n",
    "\n",
    "    # Perform groupby and aggregation\n",
    "    coin_features_df = df.groupby('coin_id', observed=True)[numeric_cols].agg(aggregations)\n",
    "\n",
    "    # Flatten the multi-level columns\n",
    "    coin_features_df.columns = [f\"{col[0]}_{col[1]}\" for col in coin_features_df.columns]\n",
    "\n",
    "    return coin_features_df\n",
    "\n",
    "coin_features_df = aggregate_coin_features(coin_training_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_price_changes(complete_market_data_df, period_start, period_end):\n",
    "    \"\"\"\n",
    "    Calculate percentage price change between period_start and period_end for each coin.\n",
    "\n",
    "    Params:\n",
    "    - complete_market_data_df (DataFrame): Market data with multiindex (coin_id, date)\n",
    "    - period_start (datetime): Start date for calculation\n",
    "    - period_end (datetime): End date for calculation\n",
    "\n",
    "    Returns:\n",
    "    - price_change_df (DataFrame): DataFrame with coin_id index and price_change column\n",
    "    \"\"\"\n",
    "    # Reset index to access coin_id and date as columns\n",
    "    df = complete_market_data_df.reset_index()\n",
    "\n",
    "    # Get prices at period_start\n",
    "    start_prices = df[df['date'] == period_start].set_index('coin_id')['price']\n",
    "\n",
    "    # Get prices at period_end\n",
    "    end_prices = df[df['date'] == period_end].set_index('coin_id')['price']\n",
    "\n",
    "    # Calculate percentage change\n",
    "    price_change = ((end_prices - start_prices) / start_prices)\n",
    "\n",
    "    # Create result dataframe\n",
    "    result_df = pd.DataFrame(price_change)\n",
    "    result_df.columns = ['price_change']\n",
    "\n",
    "    return result_df\n",
    "\n",
    "period_start = wallets_config['training_data']['modeling_starting_balance_date']\n",
    "period_end = wallets_config['training_data']['modeling_period_end']\n",
    "complete_market_data_df.head()\n",
    "\n",
    "price_changes_df = calculate_price_changes(complete_market_data_df, period_start, period_end)\n",
    "price_changes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_price_change_by_quartiles(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze relationship between features and price_change using quartile analysis.\n",
    "\n",
    "    Params:\n",
    "    - df (DataFrame): input dataframe with features and price_change column\n",
    "\n",
    "    Returns:\n",
    "    - quartile_df (DataFrame): metrics about feature quartiles and corresponding price_change values\n",
    "    \"\"\"\n",
    "    # 1. Drop columns with zero variance\n",
    "    variance = df.var(numeric_only=True)\n",
    "    zero_var_cols = variance[variance == 0].index.tolist()\n",
    "    df = df.drop(columns=zero_var_cols)\n",
    "\n",
    "    # Make a copy of price_change as our target\n",
    "    target = df['price_change'].copy()\n",
    "\n",
    "    # Initialize lists to store results\n",
    "    metrics = []\n",
    "    correlations = []\n",
    "    counts = []\n",
    "    q1_feature_avgs = []\n",
    "    q2_feature_avgs = []\n",
    "    q3_feature_avgs = []\n",
    "    q4_feature_avgs = []\n",
    "    q1_price_avgs = []\n",
    "    q2_price_avgs = []\n",
    "    q3_price_avgs = []\n",
    "    q4_price_avgs = []\n",
    "\n",
    "    # Calculate stats for each column\n",
    "    for col in df.columns:\n",
    "        if col == 'price_change':\n",
    "            continue\n",
    "\n",
    "        # Skip columns that are entirely NaN\n",
    "        if df[col].isna().all():\n",
    "            continue\n",
    "\n",
    "        # Get valid data (non-NaN pairs)\n",
    "        valid_mask = (~df[col].isna()) & (~target.isna())\n",
    "        feature_valid = df.loc[valid_mask, col]\n",
    "        target_valid = target.loc[valid_mask]\n",
    "\n",
    "        # Skip if not enough valid data points\n",
    "        if len(feature_valid) < 20:  # Minimum needed for meaningful quartiles\n",
    "            continue\n",
    "\n",
    "        # Calculate correlation for sorting\n",
    "        corr = feature_valid.corr(target_valid, method='pearson', min_periods=5)\n",
    "\n",
    "        # Calculate quartile boundaries\n",
    "        quartiles = feature_valid.quantile([0.25, 0.5, 0.75])\n",
    "        q1_bound, q2_bound, q3_bound = quartiles.iloc[0], quartiles.iloc[1], quartiles.iloc[2]\n",
    "\n",
    "        # Create quartile masks\n",
    "        q1_mask = feature_valid <= q1_bound\n",
    "        q2_mask = (feature_valid > q1_bound) & (feature_valid <= q2_bound)\n",
    "        q3_mask = (feature_valid > q2_bound) & (feature_valid <= q3_bound)\n",
    "        q4_mask = feature_valid > q3_bound\n",
    "\n",
    "        # Calculate average feature values in each quartile\n",
    "        q1_feat_avg = feature_valid[q1_mask].mean()\n",
    "        q2_feat_avg = feature_valid[q2_mask].mean()\n",
    "        q3_feat_avg = feature_valid[q3_mask].mean()\n",
    "        q4_feat_avg = feature_valid[q4_mask].mean()\n",
    "\n",
    "        # Calculate average price_change in each feature quartile\n",
    "        q1_price_avg = target_valid[q1_mask].mean()\n",
    "        q2_price_avg = target_valid[q2_mask].mean()\n",
    "        q3_price_avg = target_valid[q3_mask].mean()\n",
    "        q4_price_avg = target_valid[q4_mask].mean()\n",
    "\n",
    "        # Store results\n",
    "        metrics.append(col)\n",
    "        correlations.append(corr)\n",
    "        counts.append(len(feature_valid))\n",
    "        q1_feature_avgs.append(q1_feat_avg)\n",
    "        q2_feature_avgs.append(q2_feat_avg)\n",
    "        q3_feature_avgs.append(q3_feat_avg)\n",
    "        q4_feature_avgs.append(q4_feat_avg)\n",
    "        q1_price_avgs.append(q1_price_avg)\n",
    "        q2_price_avgs.append(q2_price_avg)\n",
    "        q3_price_avgs.append(q3_price_avg)\n",
    "        q4_price_avgs.append(q4_price_avg)\n",
    "\n",
    "    # Create result dataframe\n",
    "    result_df = pd.DataFrame({\n",
    "        'metric': metrics,\n",
    "        'count': counts,\n",
    "        'correlation': correlations,\n",
    "        'q1_feature_avg': q1_feature_avgs,\n",
    "        'q2_feature_avg': q2_feature_avgs,\n",
    "        'q3_feature_avg': q3_feature_avgs,\n",
    "        'q4_feature_avg': q4_feature_avgs,\n",
    "        'q1_price_avg': q1_price_avgs,\n",
    "        'q2_price_avg': q2_price_avgs,\n",
    "        'q3_price_avg': q3_price_avgs,\n",
    "        'q4_price_avg': q4_price_avgs\n",
    "    })\n",
    "\n",
    "    # Calculate monotonicity (how consistently price changes across quartiles)\n",
    "    result_df['monotonic_score'] = (\n",
    "        ((result_df['q2_price_avg'] > result_df['q1_price_avg']).astype(int) +\n",
    "        (result_df['q3_price_avg'] > result_df['q2_price_avg']).astype(int) +\n",
    "        (result_df['q4_price_avg'] > result_df['q3_price_avg']).astype(int)) -\n",
    "        ((result_df['q2_price_avg'] < result_df['q1_price_avg']).astype(int) +\n",
    "        (result_df['q3_price_avg'] < result_df['q2_price_avg']).astype(int) +\n",
    "        (result_df['q4_price_avg'] < result_df['q3_price_avg']).astype(int))\n",
    "    )\n",
    "\n",
    "    # Sort by absolute correlation values (descending)\n",
    "    result_df['abs_correlation'] = result_df['correlation'].abs()\n",
    "    result_df = result_df.sort_values('abs_correlation', ascending=False).drop('abs_correlation', axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = coin_features_df.join(price_changes_df)\n",
    "analysis_df = analyze_price_change_by_quartiles(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "features = analysis_df[abs(analysis_df['correlation'])>0.005]['metric']\n",
    "\n",
    "X = merged_df[features]\n",
    "y = u.winsorize(merged_df['price_change'],0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_top_n_percent(values: pd.Series, threshold_percent: float) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Creates a boolean mask identifying values in the top n percent.\n",
    "\n",
    "    Params:\n",
    "    - values (Series): Series of numeric values to evaluate\n",
    "    - threshold_percent (float): Percentage threshold (0-100)\n",
    "\n",
    "    Returns:\n",
    "    - Series: Boolean mask of same length as input, True for values in top n percent\n",
    "    \"\"\"\n",
    "    # Calculate the threshold value at the specified percentile\n",
    "    percentile_threshold = np.percentile(values, 100 - threshold_percent)\n",
    "\n",
    "    # Return boolean series where True indicates values in top n percent\n",
    "    return values >= percentile_threshold\n",
    "\n",
    "y = mark_top_n_percent(merged_df['price_change'], 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First drop NaN values from the target\n",
    "mask = ~y.isna()\n",
    "X_filtered = X[mask]\n",
    "y_filtered = y[mask]\n",
    "\n",
    "# Handle NaN values in features\n",
    "X_filtered = X_filtered.fillna(X_filtered.mean())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train XGBoost classification model\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_prob = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate ROC AUC (handling multiclass if needed)\n",
    "if len(np.unique(y_test)) > 2:\n",
    "    # One-vs-rest ROC AUC for multiclass\n",
    "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
    "else:\n",
    "    # Binary classification ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Plot ROC curve (for binary classification)\n",
    "if len(np.unique(y_test)) == 2:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Get feature importance\n",
    "importance = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_idx = np.argsort(importance)[::-1]\n",
    "top_features = [(feature_names[i], importance[i]) for i in sorted_idx[:10]]\n",
    "\n",
    "# Print top 10 features\n",
    "print(\"\\nTop 10 features:\")\n",
    "for name, imp in top_features:\n",
    "    print(f\"{name}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First drop NaN values from the target\n",
    "mask = ~y.isna()\n",
    "X_filtered = X[mask]\n",
    "y_filtered = y[mask]\n",
    "\n",
    "# Handle NaN values in features\n",
    "X_filtered = X_filtered.fillna(X_filtered.mean())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train XGBoost classification model\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_prob = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate ROC AUC (handling multiclass if needed)\n",
    "if len(np.unique(y_test)) > 2:\n",
    "    # One-vs-rest ROC AUC for multiclass\n",
    "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
    "else:\n",
    "    # Binary classification ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Plot ROC curve (for binary classification)\n",
    "if len(np.unique(y_test)) == 2:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Get feature importance\n",
    "importance = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_idx = np.argsort(importance)[::-1]\n",
    "top_features = [(feature_names[i], importance[i]) for i in sorted_idx[:10]]\n",
    "\n",
    "# Print top 10 features\n",
    "print(\"\\nTop 10 features:\")\n",
    "for name, imp in top_features:\n",
    "    print(f\"{name}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# First drop NaN values from the target\n",
    "mask = ~y.isna()\n",
    "X_filtered = X[mask]\n",
    "y_filtered = y[mask]\n",
    "\n",
    "# Handle NaN values in features\n",
    "X_filtered = X_filtered.fillna(X_filtered.mean())\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train XGBoost model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# Get feature importance\n",
    "importance = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_idx = np.argsort(importance)[::-1]\n",
    "top_features = [(feature_names[i], importance[i]) for i in sorted_idx[:10]]\n",
    "\n",
    "# Print top 10 features\n",
    "print(\"\\nTop 10 features:\")\n",
    "for name, imp in top_features:\n",
    "    print(f\"{name}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation period predictions with wallet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate validation period training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_epochs_config = yaml.safe_load(Path('../config/wallets_epochs_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "complete_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_profits_df.parquet\")\n",
    "complete_market_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_market_data_df.parquet\")\n",
    "complete_macro_trends_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_macro_trends_df.parquet\")\n",
    "\n",
    "# Identify offset needed to generate training data up to the validation period start\n",
    "# modeling_offset = (datetime.strptime(wallets_config['training_data']['modeling_period_end'], '%Y-%m-%d') - datetime.strptime(wallets_config['training_data']['training_period_end'], '%Y-%m-%d')).days\n",
    "validation_epochs_config = copy.deepcopy(wallets_epochs_config)\n",
    "validation_epochs_config['offset_epochs']['offsets'] = validation_epochs_config['offset_epochs']['validation_offsets']\n",
    "\n",
    "# Initiate orchestrator\n",
    "epochs_orchestrator = weo.MultiEpochOrchestrator(\n",
    "    wallets_config.config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    validation_epochs_config,\n",
    "    complete_profits_df,\n",
    "    complete_market_data_df,\n",
    "    complete_macro_trends_df\n",
    ")\n",
    "\n",
    "# Generate TRAINING_DATA_DF for the modeling period offset window\n",
    "validation_training_data_df, validation_wallet_features_df = epochs_orchestrator.generate_epochs_training_data()\n",
    "\n",
    "# Save files\n",
    "validation_training_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_wallet_training_data_df.parquet\",index=True)\n",
    "validation_wallet_features_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_wallet_features_df.parquet\",index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Override model_id from model generation if necessary\n",
    "# model_id = 'da541721-627d-4991-affd-b7822a80c67f'\n",
    "\n",
    "# Load files\n",
    "validation_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_wallet_training_data_df.parquet\")\n",
    "validation_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_wallet_features_df.parquet\")\n",
    "\n",
    "# y_true generation\n",
    "validation_y_true_full=validation_wallet_features_df[wallets_config['modeling']['target_variable']]\n",
    "validation_y_true_modeling=validation_wallet_features_df[validation_wallet_features_df['in_modeling_cohort']==1][wallets_config['modeling']['target_variable']]\n",
    "validation_y_true_nonmodeling=validation_wallet_features_df[validation_wallet_features_df['in_modeling_cohort']==0][wallets_config['modeling']['target_variable']]\n",
    "\n",
    "# y_pred generation\n",
    "base_path = wallets_config['training_data']['model_artifacts_folder']\n",
    "validation_y_pred = wiva.load_and_predict(model_id,validation_training_data_df,base_path)\n",
    "\n",
    "wiva.evaluate_predictions(validation_y_true_modeling,validation_y_pred)\n",
    "wiva.evaluate_predictions(validation_y_true_full,validation_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation multi window r2 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_cohort = validation_y_true_full\n",
    "\n",
    "# Consolidate scores for all validation epochs\n",
    "validation_wallet_scores_df = pd.merge(\n",
    "    y_true_cohort.reset_index(),\n",
    "    validation_y_pred.reset_index(),\n",
    "    on=['wallet_address', 'epoch_start_date'],\n",
    "    how='inner',\n",
    "    suffixes=('_true', '_pred')\n",
    ")\n",
    "validation_wallet_scores_df = validation_wallet_scores_df.set_index(['wallet_address','epoch_start_date'])\n",
    "validation_wallet_scores_df.columns = ['actual','score']\n",
    "\n",
    "\n",
    "# Generate metrics for all validation epochs\n",
    "epochs = sorted(list(validation_wallet_scores_df.index.get_level_values('epoch_start_date').unique()))\n",
    "for epoch in epochs:\n",
    "    epoch_mask = validation_wallet_scores_df.index.get_level_values('epoch_start_date') == epoch\n",
    "    y_true = validation_wallet_scores_df[epoch_mask]['actual']\n",
    "    y_pred = validation_wallet_scores_df[epoch_mask]['score']\n",
    "\n",
    "    # Skip epochs with no actual values\n",
    "    if y_true.isna().all():\n",
    "        continue\n",
    "\n",
    "    metrics = wiva.evaluate_predictions(y_true, y_pred)\n",
    "    print(f\"epoch {epoch}: R² = {metrics['r2']:.3f}\")\n",
    "\n",
    "u.notify(34)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Single Window Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training Data Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load orchestrator\n",
    "training_data_orchestrator = wtdo.WalletTrainingDataOrchestrator(\n",
    "    copy.deepcopy(wallets_config.config),\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data\n",
    "_,_,_,_ = training_data_orchestrator.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['training_period_start'],\n",
    "    wallets_config['training_data']['training_period_end'],\n",
    "    parquet_prefix='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select cohort and prepare training data\n",
    "parquet_folder = wallets_config['training_data']['parquet_folder']\n",
    "training_profits_df_full = pd.read_parquet(f\"{parquet_folder}/training_profits_df_full.parquet\")\n",
    "training_market_data_df_full = pd.read_parquet(f\"{parquet_folder}/training_market_data_df_full.parquet\")\n",
    "training_macro_trends_df_full = pd.read_parquet(f\"{parquet_folder}/training_macro_trends_df_full.parquet\")\n",
    "\n",
    "\n",
    "_ = training_data_orchestrator.prepare_training_data(\n",
    "    training_profits_df_full,\n",
    "    training_market_data_df_full,\n",
    "    training_macro_trends_df_full\n",
    ")\n",
    "\n",
    "# Store hybrid ID map\n",
    "if wallets_config['training_data']['hybridize_wallet_ids']:\n",
    "    pd.to_pickle(training_data_orchestrator.hybrid_cw_id_map, f\"{parquet_folder}/hybrid_cw_id_map.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training features\n",
    "parquet_folder = wallets_config['training_data']['parquet_folder']\n",
    "training_profits_df = pd.read_parquet(f\"{parquet_folder}/training_profits_df.parquet\")\n",
    "training_market_indicators_df = pd.read_parquet(f\"{parquet_folder}/training_market_indicators_data_df.parquet\")\n",
    "training_macro_indicators_df = pd.read_parquet(f\"{parquet_folder}/training_macro_indicators_df.parquet\")\n",
    "training_transfers_df = pd.read_parquet(f\"{parquet_folder}/training_transfers_sequencing_df.parquet\")\n",
    "\n",
    "training_data_orchestrator.generate_training_features(\n",
    "    training_profits_df,\n",
    "    training_market_indicators_df,\n",
    "    training_macro_indicators_df,\n",
    "    training_transfers_df\n",
    ")\n",
    "\n",
    "u.notify(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet Model Target Variable and Wallet Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modeling datasets\n",
    "training_coin_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_market_indicators_data_df.parquet\",\n",
    "                                       columns=['coin_id'])['coin_id'].unique()\n",
    "_,_,_,_ = training_data_orchestrator.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['modeling_period_start'],\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    training_coin_cohort,\n",
    "    parquet_prefix='modeling'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "training_wallet_cohort = pd.read_parquet(\n",
    "    f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\",\n",
    "    columns=[]\n",
    ").index.values\n",
    "\n",
    "# Load orchestrator\n",
    "training_data_orchestrator = wtdo.WalletTrainingDataOrchestrator(\n",
    "    copy.deepcopy(wallets_config.config),\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    training_wallet_cohort\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare modeling features for target variables\n",
    "modeling_profits_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_profits_df_full.parquet\")\n",
    "hybrid_cw_id_map = None\n",
    "if wallets_config['training_data']['hybridize_wallet_ids']:\n",
    "    hybrid_cw_id_map = pd.read_pickle(f\"{wallets_config['training_data']['parquet_folder']}/hybrid_cw_id_map.pkl\")\n",
    "\n",
    "_ = training_data_orchestrator.prepare_modeling_features(\n",
    "    modeling_profits_df_full,\n",
    "    hybrid_cw_id_map\n",
    ")\n",
    "\n",
    "u.notify(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet Model Construction and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select target variable (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create MODELING_DF and Construct Wallet Model\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "modeling_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_wallet_features_df.parquet\")\n",
    "\n",
    "# Filter training data to only the modeling cohort through inner join to target variable\n",
    "modeling_cohort_target_var_df = modeling_wallet_features_df[['in_modeling_cohort', wallets_config['modeling']['target_variable']]].copy()\n",
    "\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\")\n",
    "logger.info(\"Training data df shape: %s\", wallet_training_data_df.shape)\n",
    "# sorted(list(wallet_training_data_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build wallet model or run search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\")\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "\n",
    "# Validate indices match\n",
    "if not all(\n",
    "    wallet_training_data_df.sort_index().index.get_level_values(level).equals(\n",
    "        modeling_cohort_target_var_df.sort_index().index.get_level_values(level)\n",
    "    ) for level in wallet_training_data_df.index.names\n",
    "):\n",
    "    raise ValueError(\"Merged training and modeling DataFrames have mismatched indices.\")\n",
    "\n",
    "\n",
    "wallet_model_results = wallet_model.construct_wallet_model(wallet_training_data_df,modeling_cohort_target_var_df)\n",
    "del wallet_training_data_df\n",
    "gc.collect()\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in wallet_model_results:\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    model_id, wallet_evaluator, modeling_wallet_scores_df = wmr.generate_and_save_wallet_model_artifacts(\n",
    "        model_results=wallet_model_results,\n",
    "        base_path='../artifacts/wallet_modeling',\n",
    "        configs = {\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "            'wallets_features_config': wallets_features_config\n",
    "        },\n",
    "        save_scores=False\n",
    "    )\n",
    "    print(wallet_evaluator.summary_report())\n",
    "else:\n",
    "    display(wallet_model.generate_search_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assess wallet model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Reload evaluator\n",
    "wallet_evaluator = wime.RegressionEvaluator(\n",
    "    y_train=wallet_model_results['y_train'],\n",
    "    y_test=wallet_model_results['y_test'],\n",
    "    y_pred=wallet_model_results['y_pred'],\n",
    "    training_cohort_pred=wallet_model_results['training_cohort_pred'],\n",
    "    training_cohort_actuals=wallet_model_results['training_cohort_actuals'],\n",
    "    model=wallet_model_results['pipeline'].named_steps['regressor'],\n",
    "    feature_names=wallet_model_results['pipeline'][:-1].transform(wallet_model_results['X_train']).columns.tolist()\n",
    ")\n",
    "print(len(wallet_model_results['pipeline'][:-1].transform(wallet_model_results['X_train']).columns.tolist()))\n",
    "# Print results\n",
    "print(wallet_evaluator.summary_report())\n",
    "wallet_evaluator.plot_wallet_evaluation()\n",
    "wallet_evaluator.importance_summary(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(wallet_model_results['pipeline'][:-1].transform(wallet_model_results['X_train']).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_evaluator.importance_summary(0)\n",
    "# wallet_evaluator.importance_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Reload evaluator\n",
    "wallet_evaluator = wime.RegressionEvaluator(\n",
    "    y_train=wallet_model_results['y_train'],\n",
    "    y_test=wallet_model_results['y_test'],\n",
    "    y_pred=wallet_model_results['y_pred'],\n",
    "    training_cohort_pred=wallet_model_results['training_cohort_pred'],\n",
    "    training_cohort_actuals=wallet_model_results['training_cohort_actuals'],\n",
    "    model=wallet_model_results['pipeline'].named_steps['regressor'],\n",
    "    feature_names=wallet_model_results['pipeline'][:-1].transform(wallet_model_results['X_train']).columns.tolist()\n",
    ")\n",
    "\n",
    "feature_importances_df = wiva.analyze_wallet_model_importance(wallet_evaluator.metrics['importances'])\n",
    "feature_importances_df = feature_importances_df.copy()\n",
    "\n",
    "feature_categories_filter = [\n",
    "    # 'performance',\n",
    "    # 'timing',\n",
    "    # 'trading',\n",
    "    # 'transfers',\n",
    "    'mktcap',\n",
    "    # 'scenario',\n",
    "    # 'cluster',\n",
    "]\n",
    "\n",
    "feature_names_filter = [\n",
    "    # 'price_sma_5',\n",
    "    # 'price_rsi_5',\n",
    "    # 'volume_sma_5',\n",
    "    # 'market_cap_filled',\n",
    "    # 'mktcap',\n",
    "    # 'cluster',\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    # 'record_type',\n",
    "    'feature_category',\n",
    "    'feature_name',\n",
    "    'feature_comparison',\n",
    "    'feature_aggregation',\n",
    "    # 'training_segment',\n",
    "]\n",
    "\n",
    "(feature_importances_df\n",
    " [feature_importances_df['feature_category'].isin(feature_categories_filter)]\n",
    "#  [feature_importances_df['feature_name'].isin(feature_names_filter)]\n",
    " .fillna('None').groupby(groups)\n",
    " .sum('importance')\n",
    " .sort_values(by='importance',ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scores for coin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_name = 'net_gain_max_investment_winsorized_base'\n",
    "# score_name = 'x'\n",
    "\n",
    "# Special save score for use in the coin model\n",
    "\n",
    "# Create wallet scores DataFrame with both cohorts\n",
    "modeling_wallet_scores_df = pd.DataFrame({\n",
    "    f'score|{score_name}': wallet_model_results['training_cohort_pred'],\n",
    "    f'actual|{score_name}': wallet_model_results['training_cohort_actuals'],\n",
    "    'in_modeling_cohort': wallet_model_results['training_cohort_pred'].index.isin(wallet_model_results['y_test'].index)\n",
    "})\n",
    "\n",
    "modeling_wallet_scores_df.head()\n",
    "\n",
    "\n",
    "# scores_df.head()\n",
    "modeling_wallet_scores_df.to_parquet(f\"temp/wallet_modeling_score_dfs/{score_name}.parquet\",index=True)\n",
    "\n",
    "u.notify(2)\n",
    "# u.notify(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orchestrate experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [importlib.reload(module) for module in modules]\n",
    "# wallets_config.reload()\n",
    "\n",
    "# # Load experiments config\n",
    "# wallets_config_experiment = yaml.safe_load(Path('../config/wallets_config_experiment.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# # Initialize orchestrator with both configs\n",
    "# orchestrator = wimo.WalletExperimentsOrchestrator(\n",
    "#     config_base=wallets_config.config,         # your base config dict\n",
    "#     config_experiment=wallets_config_experiment  # your experiment config dict\n",
    "# )\n",
    "\n",
    "# # Run experiment\n",
    "# results = orchestrator.orchestrate_wallet_experiment(\n",
    "#     training_data_df=wallet_training_data_df,\n",
    "#     modeling_wallet_features_df=modeling_wallet_features_df\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Load parquet\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\")\n",
    "\n",
    "\n",
    "# List of the x features with the highest importance in the model\n",
    "x_features = 6\n",
    "top_feature_metrics = list((pd.DataFrame(wallet_evaluator.metrics['importances'])\n",
    "                      .sort_values(by='importance',ascending=False)\n",
    "                      .head(x_features)['feature']))\n",
    "comparison_metrics = list(set(top_feature_metrics))\n",
    "\n",
    "\n",
    "\n",
    "# Cluster numbers\n",
    "n_clusters=4\n",
    "\n",
    "styled_df,cluster_results_df = wica.create_cluster_report(wallet_training_data_df, wallet_model_results, n_clusters, comparison_metrics, 'median')\n",
    "\n",
    "del(wallet_training_data_df)\n",
    "gc.collect()\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_df = wallet_training_data_df.copy()\n",
    "\n",
    "base_metrics = [\n",
    "    'trading|max_investment|all_windows',\n",
    "    'trading|crypto_net_gain|all_windows',\n",
    "    'mktcap|end_portfolio_wtd_market_cap|all_windows',\n",
    "    'performance|crypto_net_gain/max_investment/base|all_windows',\n",
    "]\n",
    "cluster_cols = [col for col in modeling_df.columns if col.startswith('cluster|')]\n",
    "cluster_analysis_df = modeling_df[list(set(cluster_cols + base_metrics + comparison_metrics))].copy()\n",
    "\n",
    "\n",
    "# Assign wallets to categorical clusters based on the distance values\n",
    "cluster_assignments_df = wcl.assign_clusters_from_distances(cluster_analysis_df,\n",
    "                                                        wallets_config['features']['clustering_n_clusters'])\n",
    "# cluster_analysis_df = cluster_analysis_df.join(cluster_assignments_df,how='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cluster_analysis_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Period Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-wallet coin model feature generation (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "wallets_config.reload()\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Confirm period boundaries align\n",
    "if not ((config['training_data']['modeling_period_start'] == wallets_config['training_data']['validation_period_start'])\n",
    "        & (config['training_data']['modeling_period_end'] == wallets_config['training_data']['validation_period_end'])):\n",
    "    raise ValueError(\"Coin features modeling period must align with wallet features validation period.\")\n",
    "\n",
    "# Generate features based on the coin config files\n",
    "coin_features_training_data_df, _, _ = tw.generate_all_time_windows_model_inputs(config,metrics_config,modeling_config)\n",
    "\n",
    "# Remove time window index since we aren't using that for now\n",
    "coin_features_training_data_df = coin_features_training_data_df.reset_index(level='time_window', drop=True)\n",
    "\n",
    "# Save to parquet\n",
    "coin_features_training_data_df.to_parquet(\"temp/coin_modeling_dfs/coin_non_wallet_features_training_data_df.parquet\",index=True)\n",
    "\n",
    "u.notify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modeling dataset files (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load coin cohort (currently carried through training/modeling/validation periods)\n",
    "training_coin_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_market_indicators_data_df.parquet\",\n",
    "                                       columns=['coin_id'])['coin_id'].unique()\n",
    "\n",
    "# Load modeling period scores and data\n",
    "modeling_market_data_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_market_data_df_full.parquet\")\n",
    "modeling_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_profits_df.parquet\")\n",
    "\n",
    "# Filter historical records\n",
    "modeling_market_data_df = modeling_market_data_df_full[\n",
    "    modeling_market_data_df_full['date'] >= wallets_config['training_data']['modeling_starting_balance_date']\n",
    "]\n",
    "\n",
    "u.assert_period(modeling_market_data_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n",
    "u.assert_period(modeling_profits_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n",
    "\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coin Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare coin_training_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign wallets to segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Create base df with all wallet addresses and scores\n",
    "wallet_scores_df = cfo.load_wallet_scores(wallets_coin_config['wallet_segments']['wallet_scores'],\n",
    "                                            wallets_coin_config['wallet_segments']['wallet_scores_path'])\n",
    "wallet_segmentation_df = wallet_scores_df\n",
    "\n",
    "# Add \"all\" segment for full population level aggregations\n",
    "wallet_segmentation_df['all_wallets|all'] = 'all'\n",
    "wallet_segmentation_df['all_wallets|all'] = wallet_segmentation_df['all_wallets|all'].astype('category')\n",
    "\n",
    "\n",
    "# Add score quantile assignments\n",
    "wallet_segmentation_df = cws.assign_wallet_score_quantiles(\n",
    "    wallet_segmentation_df,\n",
    "    wallets_coin_config['wallet_segments']['wallet_scores'],\n",
    "    wallets_coin_config['wallet_segments']['score_segment_quantiles']\n",
    ")\n",
    "\n",
    "# Add training period-based cluster labels if configured\n",
    "if wallets_coin_config['wallet_segments'].get('training_period_cluster_groups'):\n",
    "    training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\")\n",
    "    wallet_clusters_df = cws.assign_cluster_labels(\n",
    "        training_data_df,\n",
    "        wallets_coin_config['wallet_segments']['training_period_cluster_groups']\n",
    "    )\n",
    "    del(training_data_df)\n",
    "    gc.collect\n",
    "\n",
    "    # Join together and ensure no rows were dropped\n",
    "    orig_len = len(wallet_segmentation_df)\n",
    "    wallet_segmentation_df = wallet_segmentation_df.join(wallet_clusters_df,how='inner')\n",
    "    joined_len = len(wallet_segmentation_df)\n",
    "    if joined_len < orig_len:\n",
    "        raise ValueError(f\"Join dropped {orig_len - joined_len} rows from original {orig_len} rows\")\n",
    "\n",
    "\n",
    "u.obj_mem()\n",
    "\n",
    "list(wallet_segmentation_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate metrics for coin-wallet pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Create base df with all coin-wallet pairs\n",
    "cw_metrics_df = pd.DataFrame(\n",
    "    index=modeling_profits_df[['coin_id', 'wallet_address']]\n",
    "    .drop_duplicates()\n",
    "    .set_index(['coin_id', 'wallet_address'])\n",
    "    .index\n",
    ")\n",
    "\n",
    "# Only modeling period boundaries work until date imputation logic is added\n",
    "valid_dates = [\n",
    "   wallets_config['training_data']['modeling_starting_balance_date'],\n",
    "   wallets_config['training_data']['modeling_period_end']\n",
    "]\n",
    "assert all(date in valid_dates for date in wallets_coin_config['wallet_features']['wallet_balance_dates']), \\\n",
    "   f\"Balance dates must be one of {valid_dates}\"\n",
    "\n",
    "# Generate balance metric\n",
    "cw_balances_df = cwbm.calculate_coin_wallet_balances(\n",
    "   modeling_profits_df,\n",
    "   wallets_coin_config['wallet_features']['wallet_balance_dates']\n",
    ")\n",
    "cw_balances_df = cw_balances_df.add_prefix('balances/')\n",
    "cw_metrics_df = cw_metrics_df.join(cw_balances_df,how='left')\\\n",
    "        .fillna({col: 0 for col in cw_balances_df.columns})\n",
    "\n",
    "\n",
    "# Generate trading metrics\n",
    "cw_trading_features_df = cwbm.calculate_coin_wallet_trading_metrics(modeling_profits_df,\n",
    "                                                                    wallets_config['training_data']['modeling_period_start'],\n",
    "                                                                    wallets_config['training_data']['modeling_period_end'],\n",
    "                                                                    wallets_coin_config['wallet_features']['drop_trading_metrics'])\n",
    "cw_trading_features_df = cw_trading_features_df.add_prefix('trading/')\n",
    "cw_metrics_df = cw_metrics_df.join(cw_trading_features_df,how='left')\\\n",
    "        .fillna({col: 0 for col in cw_trading_features_df.columns})\n",
    "\n",
    "cw_metrics_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatten cw_metrics into single values for each coin-segment pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Define complete coin list and initialize df with\n",
    "coin_wallet_features_df = pd.DataFrame(index=training_coin_cohort)\n",
    "coin_wallet_features_df.index.name = 'coin_id'\n",
    "\n",
    "\n",
    "# Loop through all metrics and segmentations to generate features\n",
    "segmentation_families = wallet_segmentation_df.columns[~wallet_segmentation_df.columns.str.startswith('scores|')]\n",
    "metric_columns = cw_metrics_df.columns\n",
    "\n",
    "# Calculate all features for each metric column\n",
    "i = 0\n",
    "logger.info(\"Calculating segment features for each metric column...\")\n",
    "for metric_column in metric_columns:\n",
    "\n",
    "    # Calculate metric column features for each segment family\n",
    "    for segment_family in segmentation_families:\n",
    "\n",
    "        # Generate coin-level features based on modeling period end wallet scores and balances\n",
    "        coin_segment_family_features_df = cfo.flatten_cw_to_coin_features(\n",
    "            cw_metrics_df,\n",
    "            metric_column,\n",
    "            wallet_segmentation_df,\n",
    "            segment_family,\n",
    "            training_coin_cohort\n",
    "        )\n",
    "        coin_wallet_features_df = coin_wallet_features_df.join(coin_segment_family_features_df, how='inner')\n",
    "\n",
    "    i+=1\n",
    "    logger.info(\"Completed metric %s/%s: %s...\",\n",
    "                i, len(metric_columns), metric_column)\n",
    "\n",
    "logger.info(\"Calculated all metric-segment-aggregation features. Final output shape: %s\",\n",
    "            coin_wallet_features_df.shape )\n",
    "\n",
    "del cw_metrics_df,cw_trading_features_df,cw_balances_df,wallet_scores_df#,wallet_segmentation_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()\n",
    "\n",
    "# save to parquet if next step won't be joined\n",
    "coin_wallet_features_df.to_parquet(\"temp/coin_modeling_dfs/coin_training_data_df_full.parquet\",index=True)\n",
    "\n",
    "coin_wallet_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge to non_wallet_features (if generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_non_wallet_features_training_data_df = pd.read_parquet(\"temp/coin_modeling_dfs/coin_non_wallet_features_training_data_df.parquet\")\n",
    "list(coin_non_wallet_features_training_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_wallet_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_non_wallet_features_training_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from coin features pipeline\n",
    "coin_non_wallet_features_training_data_df = pd.read_parquet(\"temp/coin_modeling_dfs/coin_non_wallet_features_training_data_df.parquet\")\n",
    "\n",
    "# Confirm overlap\n",
    "coin_features_ids = coin_features_training_data_df.index\n",
    "coin_wallet_features_ids = coin_wallet_features_df.index\n",
    "wallet_features_only_ids = set(coin_wallet_features_ids) - set(coin_features_ids)\n",
    "\n",
    "if len(wallet_features_only_ids) == 0:\n",
    "    logger.info(\"All %s coins with wallet features were found in the non wallet coin features set.\",\n",
    "                len(coin_wallet_features_ids))\n",
    "\n",
    "else:\n",
    "    logger.warning(f\"Wallet features contain {len(wallet_features_only_ids)} coins not in the non wallet coin features\")\n",
    "\n",
    "\n",
    "# Join together\n",
    "coin_training_data_df_full = coin_wallet_features_df.join(coin_non_wallet_features_training_data_df,how='inner')\n",
    "logger.info(\"Final features shape: %s\",coin_training_data_df_full.shape)\n",
    "\n",
    "# Save to parquet and delete\n",
    "coin_training_data_df_full.to_parquet(\"temp/coin_modeling_dfs/coin_training_data_df_full.parquet\",index=True)\n",
    "del coin_training_data_df_full,coin_wallet_features_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_training_data_df_full = pd.read_parquet(\"temp/coin_modeling_dfs/coin_training_data_df_full.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(coin_training_data_df_full.columns)\n",
    "df.columns = ['feature']\n",
    "\n",
    "# Split on pipe delimiters\n",
    "split_df = df['feature'].str.split('|', expand=True)\n",
    "split_df.columns = ['segment_category','segment_family','metric','transformation']\n",
    "\n",
    "# Split nested components\n",
    "segment_families = split_df['segment_family'].str.split('/', expand=True)\n",
    "segment_families.columns = ['segment_family', 'segment_value']\n",
    "\n",
    "metrics = split_df['metric'].str.split('/', expand=True)\n",
    "metrics.columns = ['metric', 'metric_detail']\n",
    "\n",
    "transformations = split_df['transformation'].str.split('/', expand=True)\n",
    "transformations.columns = ['transformation', 'transformation_method']\n",
    "\n",
    "# Combine all components\n",
    "feature_details_df = pd.concat([\n",
    "    split_df['segment_category'],\n",
    "    segment_families,\n",
    "    metrics,\n",
    "    transformations,\n",
    "], axis=1)\n",
    "\n",
    "feature_details_df['feature_full'] = df['feature']\n",
    "feature_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_category_filter = [\n",
    "    # 'all_wallets',\n",
    "    # 'score_quantile',\n",
    "    # 'training_clusters',\n",
    "    'time_series',\n",
    "    'wallet_cohorts',\n",
    "]\n",
    "segment_family_filter = [\n",
    "    # 'all_wallets',\n",
    "    'net_gain_winsorized_dda619_grid_score',\n",
    "    # 'time_series',\n",
    "    # 'wallet_cohorts',\n",
    "]\n",
    "metric_filter = [\n",
    "    'trading',\n",
    "    'balances',\n",
    "]\n",
    "metric_detail_filter = [\n",
    "    'crypto_net_gain',\n",
    "    'usd_balance_241031',\n",
    "]\n",
    "transformation_filter = [\n",
    "    # 'aggregations',\n",
    "    # 'score_wtd',\n",
    "    'score_dist',\n",
    "]\n",
    "transformation_method_filter = [\n",
    "    'count',\n",
    "    'sum',\n",
    "    # 'net_gain_winsorized_dda619_grid_score'\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    'segment_category',\n",
    "    'segment_family',\n",
    "    # 'segment_value',\n",
    "    'metric',\n",
    "    # 'metric_detail',\n",
    "    # 'transformation',\n",
    "    # 'transformation_method',\n",
    "    'feature_full',\n",
    "\n",
    "]\n",
    "\n",
    "pd.DataFrame(feature_details_df\n",
    " [\n",
    " (feature_details_df['segment_category'].isin(segment_category_filter))\n",
    "#  & (feature_details_df['segment_family'].isin(segment_family_filter))\n",
    "#  & (feature_details_df['metric'].isin(metric_filter))\n",
    "# #  & (feature_details_df['metric_detail'].isin(metric_detail_filter))\n",
    "#  & (feature_details_df['transformation'].isin(transformation_filter))\n",
    "# #  & (feature_details_df['transformation_method'].isin(transformation_method_filter))\n",
    "    ]\n",
    " .fillna('None').groupby(groups)\n",
    " .size()\n",
    "# ).columns\n",
    ").sort_values(by=0,ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare coin_modeling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve Validation Profits and Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve full historical through validation period datasets\n",
    "\n",
    "# Retrieve training coin cohort to ensure all training period coins are reflected\n",
    "training_coin_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_market_indicators_data_df.parquet\",\n",
    "                                       columns=['coin_id'])['coin_id'].unique()\n",
    "_,_,_ = wtdo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['validation_period_start'],\n",
    "    wallets_config['training_data']['validation_period_end'],\n",
    "    training_coin_cohort,\n",
    "    parquet_prefix = 'validation'\n",
    "\n",
    ")\n",
    "\n",
    "del _\n",
    "gc.collect\n",
    "u.obj_mem()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load parquet\n",
    "validation_market_data_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_market_data_df_full.parquet\")\n",
    "validation_profits_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_profits_df_full.parquet\")\n",
    "\n",
    "\n",
    "# Remove pre-validation period prices\n",
    "validation_market_data_df = validation_market_data_df_full[validation_market_data_df_full['date']\n",
    "                                                       >=wallets_config['training_data']['validation_starting_balance_date']]\n",
    "del validation_market_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Handle hybridization if configured\n",
    "if wallets_config['training_data']['hybridize_wallet_ids'] is True:\n",
    "    hybrid_cw_id_map = pd.read_pickle(f\"{wallets_config['training_data']['parquet_folder']}/hybrid_cw_id_map.pkl\")\n",
    "\n",
    "    logger.info(\"Applying wallet-coin hybridization...\")\n",
    "    validation_profits_df_full, _ = wtdo.hybridize_wallet_address(\n",
    "        validation_profits_df_full,\n",
    "        hybrid_cw_id_map\n",
    "    )\n",
    "\n",
    "# Filter to only training wallet cohort\n",
    "training_wallet_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\", columns=[]).index.values\n",
    "validation_profits_df = validation_profits_df_full[validation_profits_df_full['wallet_address'].isin(training_wallet_cohort)]\n",
    "del validation_profits_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Assert period, save files, remove from memory\n",
    "u.assert_period(validation_market_data_df,\n",
    "                wallets_config['training_data']['validation_period_start'],\n",
    "                wallets_config['training_data']['validation_period_end'])\n",
    "u.assert_period(validation_profits_df,\n",
    "                wallets_config['training_data']['validation_period_start'],\n",
    "                wallets_config['training_data']['validation_period_end'])\n",
    "validation_profits_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_profits_df.parquet\",index=False)\n",
    "validation_market_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_market_data_df.parquet\",index=False)\n",
    "# del validation_profits_df,validation_market_data_df\n",
    "gc.collect()\n",
    "u.obj_mem()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply coin filters (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load parquet\n",
    "coin_training_data_df_full = pd.read_parquet(\"temp/coin_modeling_dfs/coin_training_data_df_full.parquet\")\n",
    "logger.info(\"Starting coins: %s\", len(coin_training_data_df_full))\n",
    "\n",
    "# Filter based on holdings\n",
    "min_cohort_wallets = wallets_coin_config['coin_modeling']['min_cohort_wallets']\n",
    "min_cohort_balance = wallets_coin_config['coin_modeling']['min_cohort_balance']\n",
    "\n",
    "coin_training_data_df = coin_training_data_df_full[\n",
    "    (coin_training_data_df_full['all_wallets|all/all|balances/usd_balance_241031|aggregations/count'] >= min_cohort_wallets)\n",
    "    & (coin_training_data_df_full['all_wallets|all/all|balances/usd_balance_241031|aggregations/sum'] >= min_cohort_balance)\n",
    "]\n",
    "logger.info(\"Coins after balance filters: %s\", len(coin_training_data_df))\n",
    "# del coin_training_data_df_full\n",
    "# gc.collect()\n",
    "\n",
    "# Filter based on market cap\n",
    "min_market_cap = wallets_coin_config['coin_modeling']['min_market_cap']\n",
    "max_market_cap = wallets_coin_config['coin_modeling']['max_market_cap']\n",
    "\n",
    "coin_training_data_df = coin_training_data_df[\n",
    "    (coin_training_data_df['time_series|market_data|market_cap_last'].isna())\n",
    "    | (\n",
    "        (coin_training_data_df['time_series|market_data|market_cap_last'] >= min_market_cap)\n",
    "        & (coin_training_data_df['time_series|market_data|market_cap_last'] <= max_market_cap)\n",
    "    )\n",
    "]\n",
    "logger.info(\"Coins after market cap filters: %s\", len(coin_training_data_df))\n",
    "\n",
    "# Save to parquet and delete\n",
    "coin_training_data_df.to_parquet(\"temp/coin_modeling_dfs/coin_training_data_df.parquet\",index=True)\n",
    "# del coin_training_data_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare coin model target variable (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load market data\n",
    "validation_market_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_market_data_df.parquet\")\n",
    "coin_training_data_df = pd.read_parquet(\"temp/coin_modeling_dfs/coin_training_data_df.parquet\")\n",
    "\n",
    "\n",
    "# Target variable calculations\n",
    "# ----------------------------\n",
    "# Calculate coin return performance during validation period\n",
    "validation_coin_performance_df = civa.calculate_coin_performance(\n",
    "    validation_market_data_df,\n",
    "    wallets_config['training_data']['validation_period_start'],\n",
    "    wallets_config['training_data']['validation_period_end']\n",
    ")\n",
    "\n",
    "# Drop columns with np.nan coin_return values, which indicate a 0 starting price\n",
    "validation_coin_performance_df = validation_coin_performance_df.dropna()\n",
    "\n",
    "# Add winsorized return\n",
    "validation_coin_performance_df['coin_return_winsorized'] = u.winsorize(\n",
    "        validation_coin_performance_df['coin_return'],\n",
    "        wallets_coin_config['coin_modeling']['returns_winsorization'])\n",
    "\n",
    "\n",
    "# Add full percentile (meaning it's a percentile of all coins prior to any population filtering)\n",
    "validation_coin_performance_df['coin_return_pctile_full'] = validation_coin_performance_df['coin_return'].rank(pct=True,ascending=True)\n",
    "\n",
    "\n",
    "# Validation: check if any coin_ids missing from final features\n",
    "missing_coins = set(coin_training_data_df.index) - set(validation_coin_performance_df.index)\n",
    "if missing_coins:\n",
    "    raise ValueError(f\"Found {len(missing_coins)} coin_ids in training_data_df without validation period target variables.\")\n",
    "\n",
    "\n",
    "# Target variable attachment\n",
    "# --------------------------\n",
    "# Identify target variable column\n",
    "target_var_column = wallets_coin_config['coin_modeling']['target_variable']\n",
    "\n",
    "# Calculate the percentile among the coin_training_data_df coins\n",
    "if target_var_column == 'coin_return_pctile':\n",
    "    coin_modeling_df = coin_training_data_df.join(validation_coin_performance_df[['coin_return']])\n",
    "    coin_modeling_df['coin_return_pctile'] = coin_modeling_df['coin_return'].rank(pct=True,ascending=True)\n",
    "    coin_modeling_df = coin_modeling_df.drop('coin_return',axis=1)\n",
    "else:\n",
    "    coin_modeling_df = coin_training_data_df.join(validation_coin_performance_df[[target_var_column]])\n",
    "# del coin_training_data_df,validation_coin_performance_df\n",
    "gc.collect\n",
    "\n",
    "\n",
    "# Convert the index to string to avoid serialization/export categorical series issues\n",
    "coin_modeling_df.index = coin_modeling_df.index.astype(str)\n",
    "\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build coin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Initialize and run model\n",
    "coin_model = cm.CoinModel(modeling_config=wallets_coin_config['coin_modeling'])\n",
    "coin_model_results = coin_model.construct_coin_model(feature_df=coin_modeling_df)\n",
    "# del coin_modeling_df\n",
    "gc.collect()\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in coin_model_results:\n",
    "\n",
    "\n",
    "# # Extract the trained model\n",
    "# coin_model = coin_model_results['pipeline'].named_steps['regressor']\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    coin_model_id, coin_evaluator, coin_scores_df = cmr.generate_and_save_coin_model_artifacts(\n",
    "        model_results=coin_model_results,\n",
    "        base_path='../artifacts/coin_modeling',\n",
    "        configs = {\n",
    "            'wallets_coin_config': wallets_coin_config,\n",
    "            'wallets_config': wallets_config.config\n",
    "        }\n",
    "    )\n",
    "    print(coin_evaluator.summary_report())\n",
    "else:\n",
    "    display(coin_model.generate_search_report())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Initialize evaluator\n",
    "coin_evaluator = wime.RegressionEvaluator(\n",
    "    y_train=coin_model_results['y_train'],\n",
    "    y_test=coin_model_results['y_test'],\n",
    "    y_pred=coin_model_results['y_pred'],\n",
    "    model=coin_model_results['pipeline'].named_steps['regressor'],\n",
    "    feature_names=coin_model_results['pipeline'][:-1].transform(coin_model_results['X_train']).columns.tolist()\n",
    ")\n",
    "\n",
    "print(coin_evaluator.summary_report())\n",
    "coin_evaluator.plot_coin_evaluation()\n",
    "coin_evaluator.importance_summary(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "feature_details_df = civa.analyze_coin_model_importance(coin_evaluator.metrics['importances'])\n",
    "\n",
    "segment_category_filter = [\n",
    "    # 'all_wallets',\n",
    "    'score_quantile',\n",
    "    # 'time_series',\n",
    "    # 'wallet_cohorts',\n",
    "    # 'training_clusters',\n",
    "]\n",
    "segment_family_filter = [\n",
    "    'all_wallets',\n",
    "    'net_gain_winsorized_dda619_grid_score',\n",
    "    # 'time_series',\n",
    "    # 'wallet_cohorts',\n",
    "]\n",
    "metric_filter = [\n",
    "    # 'trading',\n",
    "    'balances',\n",
    "]\n",
    "metric_detail_filter = [\n",
    "    'crypto_net_gain',\n",
    "    'usd_balance_241031',\n",
    "]\n",
    "transformation_filter = [\n",
    "    # 'aggregations',\n",
    "    # 'score_wtd',\n",
    "]\n",
    "transformation_method_filter = [\n",
    "    'net_gain_winsorized_dda619_grid_residual_p10',\n",
    "    # 'sum',\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    'segment_category',\n",
    "    # 'segment_family',\n",
    "    # 'segment_value',\n",
    "    'metric',\n",
    "    'metric_detail',\n",
    "    'transformation',\n",
    "    'transformation_method',\n",
    "    # 'feature_full',\n",
    "\n",
    "]\n",
    "\n",
    "pd.DataFrame(feature_details_df\n",
    " [\n",
    " (feature_details_df['segment_category'].isin(segment_category_filter))\n",
    "#  & (feature_details_df['segment_family'].isin(segment_family_filter))\n",
    "#  & (feature_details_df['metric'].isin(metric_filter))\n",
    "#  & (feature_details_df['metric_detail'].isin(metric_detail_filter))\n",
    "#  & (feature_details_df['transformation'].isin(transformation_filter))\n",
    "#  & (feature_details_df['transformation_method'].isin(transformation_method_filter))\n",
    "    ]\n",
    " .fillna('None').groupby(groups)\n",
    " .sum('importance')\n",
    "# ).columns\n",
    ").sort_values(by='importance',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load importances\n",
    "feature_importance_df = pd.DataFrame(coin_evaluator.metrics['importances'])\n",
    "\n",
    "# Split on pipe delimiters\n",
    "split_df = feature_importance_df['feature'].str.split('|', expand=True)\n",
    "split_df.columns = ['segment_category','segment_family','metric','transformation']\n",
    "\n",
    "# Split nested components\n",
    "segment_families = split_df['segment_family'].str.split('/', expand=True)\n",
    "segment_families.columns = ['segment_family', 'segment_value']\n",
    "\n",
    "metrics = split_df['metric'].str.split('/', expand=True)\n",
    "metrics.columns = ['metric', 'metric_detail']\n",
    "\n",
    "transformations = split_df['transformation'].str.split('/', expand=True)\n",
    "transformations.columns = ['transformation', 'transformation_method']\n",
    "\n",
    "# Combine all components\n",
    "feature_details_df = pd.concat([\n",
    "    split_df['segment_category'],\n",
    "    segment_families,\n",
    "    metrics,\n",
    "    transformations,\n",
    "    feature_importance_df['importance']\n",
    "], axis=1)\n",
    "\n",
    "feature_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(feature_importance_df['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    'segment_category',\n",
    "    'segment_family',\n",
    "    # 'segment_value',\n",
    "    'metric',\n",
    "    'metric_detail',\n",
    "    # 'transformation',\n",
    "    # 'transformation_method',\n",
    "]\n",
    "\n",
    "feature_details_df.groupby(groups).sum('importance').sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named `df`\n",
    "# Calculate correlations\n",
    "correlation_matrix = coin_modeling_df.corr()\n",
    "\n",
    "# Extract correlations with the target variable\n",
    "target_correlations = correlation_matrix[target_var_column].sort_values(ascending=False)\n",
    "\n",
    "# Display the top features correlated with the target\n",
    "target_correlations[:15]\n",
    "# target_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "\n",
    "# # Wallet metrics to analyze\n",
    "# wallet_metrics = [\n",
    "# ]\n",
    "\n",
    "wallet_metrics = coin_modeling_df.columns\n",
    "wallet_metrics = target_correlations[:15].index.values\n",
    "\n",
    "# number of score buckets\n",
    "n_quantiles = 5\n",
    "\n",
    "analyze_df = civa.analyze_metric_segments(\n",
    "    coin_modeling_df,\n",
    "    wallet_metrics,\n",
    "    n_quantiles,\n",
    "    target_var_column,\n",
    ")\n",
    "civa.style_metric_segments(analyze_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Coin Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet aggregated analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate validation wallet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Create a DataFrame with all wallets that should exist\n",
    "validation_wallet_features_df = pd.DataFrame(index=training_wallet_cohort)\n",
    "validation_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "\n",
    "# Calculate modeling period wallet metrics\n",
    "validation_trading_features_df = wtf.calculate_wallet_trading_features(validation_profits_df,\n",
    "                                                            wallets_config['training_data']['validation_period_start'],\n",
    "                                                            wallets_config['training_data']['validation_period_end'],\n",
    "                                                            include_twb_metrics=False)\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(validation_trading_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in validation_trading_features_df.columns})\n",
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features_df = wpf.calculate_performance_features(validation_wallet_features_df,include_twb_metrics=False)\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(performance_features_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_wallet_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wallet validation period trading/performance by score quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base df with all wallet addresses and scores\n",
    "modeling_wallet_scores_df = cfo.load_wallet_scores(wallets_coin_config['wallet_segments']['wallet_scores'],\n",
    "                                            wallets_coin_config['wallet_segments']['wallet_scores_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create analysis by prediction bands\n",
    "metrics = [\n",
    "    'crypto_net_gain/max_investment/winsorized',\n",
    "    'crypto_net_gain/max_investment/base',\n",
    "    'crypto_net_gain/max_investment/ntile_rank',\n",
    "    'crypto_net_gain/active_twb/winsorized',\n",
    "    'crypto_net_gain/active_twb/base',\n",
    "    'max_investment',\n",
    "    'crypto_net_gain',\n",
    "    'crypto_net_flows',\n",
    "    'total_volume',\n",
    "]\n",
    "\n",
    "min_wallet_volume_usd = 0\n",
    "num_quantiles = 5\n",
    "\n",
    "wiva.create_quantile_report(\n",
    "    validation_wallet_features_df,\n",
    "    modeling_wallet_scores_df[wallets_config['modeling']['score_name']],\n",
    "    metrics,  # Your existing metrics list\n",
    "    num_quantiles,  # Split into ntiles\n",
    "    min_wallet_volume_usd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create analysis by prediction bands\n",
    "metrics = [\n",
    "    'crypto_net_gain/max_investment/winsorized',\n",
    "    'crypto_net_gain/max_investment/base',\n",
    "    'crypto_net_gain/max_investment/ntile_rank',\n",
    "    'crypto_net_gain/active_twb/winsorized',\n",
    "    'crypto_net_gain/active_twb/base',\n",
    "    'max_investment',\n",
    "    'crypto_net_gain',\n",
    "    'crypto_net_flows',\n",
    "    'total_volume',\n",
    "]\n",
    "\n",
    "min_wallet_volume_usd = 0\n",
    "num_quantiles = 5\n",
    "\n",
    "wiva.create_quantile_report(\n",
    "    validation_wallet_features_df,\n",
    "    modeling_wallet_scores_df[wallets_config['modeling']['score_name']],\n",
    "    metrics,  # Your existing metrics list\n",
    "    num_quantiles,  # Split into ntiles\n",
    "    min_wallet_volume_usd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Wallet metrics to analyze\n",
    "wallet_metrics = [\n",
    "    'top_100pct/balance_wtd_mean_score',\n",
    "    'top_10pct/count',\n",
    "    'top_25pct/count',\n",
    "    'top_50pct/count',\n",
    "    'top_100pct/count',\n",
    "    'top_10pct/count_pct',\n",
    "    'top_10pct/balance_pct',\n",
    "    'top_25pct/count_pct',\n",
    "    'top_25pct/balance_pct',\n",
    "    'top_50pct/count_pct',\n",
    "    'top_50pct/balance_pct',\n",
    "]\n",
    "# wallet_metrics = list(validation_coin_wallet_features_df.columns)\n",
    "\n",
    "# Create styled performance analysis\n",
    "civa.create_top_coins_wallet_metrics_report(validation_coin_wallet_features_df,percentile=90,wallet_metrics=wallet_metrics,method='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = civa.analyze_market_cap_segments(\n",
    "    coin_wallet_features_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "civa.plot_segment_heatmap(summary_df)\n",
    "civa.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_validation_analysis']['top_n']\n",
    "max_market_cap = wallets_config['coin_validation_analysis']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_validation_analysis']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = civa.validate_coin_performance(coin_wallet_features_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "civa.print_performance_analysis(coin_wallet_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
