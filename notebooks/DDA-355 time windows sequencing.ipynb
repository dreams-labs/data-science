{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Custom format function for displaying numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import feature_engineering as fe\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.model_input_flows as mif\n",
    "import utils as u\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [dr, pri, fe, cwm, ind, m, ia, mif, u]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Modeling sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "# 1. Data Retrieval, Cleaning, Indicator Calculation\n",
    "# --------------------------------------------------\n",
    "# Macro trends: retrieve, clean, and add indicators\n",
    "macro_trends_df = dr.retrieve_macro_trends_data()\n",
    "macro_trends_df = dr.clean_macro_trends(macro_trends_df, config)\n",
    "macro_trends_df = ind.generate_time_series_indicators(macro_trends_df.reset_index(),\n",
    "                                                      metrics_config['macro_trends'],\n",
    "                                                      None)\n",
    "\n",
    "# Profits: retrieve and clean precalculated profits data from BigQuery\n",
    "profits_df = dr.retrieve_profits_data(config['training_data']['earliest_window_start'],\n",
    "                                      config['training_data']['modeling_period_end'],\n",
    "                                      config['data_cleaning']['minimum_wallet_inflows'])\n",
    "profits_df, _ = dr.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n",
    "# Market data: retrieve, clean, and add indicators\n",
    "market_data_df = dr.retrieve_market_data()\n",
    "market_data_df = dr.clean_market_data(market_data_df, config)\n",
    "market_data_df = ind.generate_time_series_indicators(market_data_df,\n",
    "                                                     metrics_config['time_series']['market_data'],\n",
    "                                                     'coin_id')\n",
    "\n",
    "\n",
    "\n",
    "# 2. Filtering based on dataset overlap\n",
    "# -------------------------------------\n",
    "# Filter market_data to only coins with transfers data if configured to\n",
    "if config['data_cleaning']['exclude_coins_without_transfers']:\n",
    "    market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n",
    "# Create prices_df: lightweight reference for other functions\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "# Filter profits_df to remove records for any coins that were removed in data cleaning\n",
    "profits_df = profits_df[profits_df['coin_id'].isin(market_data_df['coin_id'])]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored Model Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mif.generate_time_windows(config)\n",
    "n = 0\n",
    "time_window = time_windows[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "# Prepare time window config files\n",
    "config, metrics_config, modeling_config = mif.prepare_configs(modeling_config['modeling']['config_folder'], time_window)\n",
    "\n",
    "\n",
    "# Market data\n",
    "window_market_data_df = cwm.split_dataframe_by_coverage(market_data_df,\n",
    "                                                        config['training_data']['training_period_start'],\n",
    "                                                        config['training_data']['modeling_period_end'],\n",
    "                                                        id_column='coin_id',\n",
    "                                                        drop_outside_date_range=True)\n",
    "\n",
    "# Macro trends\n",
    "window_macro_trends_df = cwm.split_dataframe_by_coverage(macro_trends_df,\n",
    "                                                        config['training_data']['training_period_start'],\n",
    "                                                        config['training_data']['modeling_period_end'],\n",
    "                                                        id_column=None,\n",
    "                                                        drop_outside_date_range=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "profits_df\n",
    "1. identify all dates needed\n",
    "    all cohort lookback window starts\n",
    "    training_period_start\n",
    "    training_period_end\n",
    "    modeling_period_start\n",
    "    modeling_period_end\n",
    "2. impute them\n",
    "3. filter df to only dates between earliest and latest dates\n",
    "4. wallet cohorts and buysell metrics\n",
    "5. indicators\n",
    "6. filter to window\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mif.generate_time_windows(config)\n",
    "n = 0\n",
    "time_window = time_windows[n]\n",
    "\n",
    "# Prepare time window config files\n",
    "config, metrics_config, modeling_config = mif.prepare_configs(modeling_config['modeling']['config_folder'], time_window)\n",
    "\n",
    "# Identify all required imputation dates\n",
    "imputation_dates = mif.identify_imputation_dates(config)\n",
    "\n",
    "# Impute all required dates\n",
    "window_profits_df = pri.impute_profits_for_multiple_dates(profits_df, prices_df, imputation_dates, n_threads=24)\n",
    "window_profits_df = (window_profits_df[(window_profits_df['date'] >= pd.to_datetime(min(imputation_dates))) &\n",
    "                                       (window_profits_df['date'] <= pd.to_datetime(max(imputation_dates)))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.df_mem(profits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IN WINDOW FUNCTIONS\n",
    "\n",
    "market_data_df: just filter to window\n",
    "macro_trends_df: just filter to window\n",
    "\n",
    "profits_df\n",
    "1. identify all dates needed\n",
    "    all cohort lookback window starts\n",
    "    training_period_start\n",
    "    training_period_end\n",
    "    modeling_period_start\n",
    "    modeling_period_end\n",
    "2. impute them\n",
    "3. filter df to only dates between earliest and latest dates\n",
    "4. wallet cohorts and buysell metrics\n",
    "5. indicators\n",
    "6. filter to window\n",
    "\"\"\"\n",
    "\n",
    "# def build_time_window_model_input(n, window, config, metrics_config, modeling_config):\n",
    "#     \"\"\"\n",
    "#     Generates training data for each of the config.training_data.additional_windows.\n",
    "\n",
    "#     Params:\n",
    "#         n (int): The lookback number of the time window (e.g 0,1,2)\n",
    "#         window (Dict): The config override dict with the window's modeling_period_start\n",
    "#         config: config.yaml\n",
    "#         metrics_config: metrics_config.yaml\n",
    "#         modeling_config: modeling_config.yaml\n",
    "\n",
    "#     Returns:\n",
    "#         model_data (Dict): Dictionary containing all of the modeling features and variables:\n",
    "#             X_train, X_test (DataFrame): Model training features\n",
    "#             y_train, y_test (pd.Series): Model target variables\n",
    "#             returns_test (DataFrame): The actual returns of each coin_id in each time_window.\n",
    "#                 - coin_id: Index (str)\n",
    "#                 - time_window: Index (int)\n",
    "#                 - returns: value column (float)\n",
    "#     \"\"\"\n",
    "\n",
    "# Prepare the full configuration by applying overrides from the current trial config\n",
    "config, metrics_config, modeling_config = prepare_configs(modeling_config['modeling']['config_folder'], window)\n",
    "\n",
    "# Define window start and end dates\n",
    "start_date = config['training_data']['training_period_start']\n",
    "end_date = config['training_data']['modeling_period_end']\n",
    "\n",
    "# Rebuild market data\n",
    "market_data_df = dr.retrieve_market_data()\n",
    "market_data_df, _ = cwm.split_dataframe_by_coverage(market_data_df, start_date, end_date, id_column='coin_id')\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "# Retrieve macro trends data\n",
    "macro_trends_df = dr.retrieve_macro_trends_data()\n",
    "macro_trends_df = cwm.generate_macro_trends_features(macro_trends_df, config)\n",
    "\n",
    "# Rebuild profits_df\n",
    "if 'profits_df' not in locals():\n",
    "    profits_df = None\n",
    "profits_df = rebuild_profits_df_if_necessary(config, prices_df, profits_df)\n",
    "\n",
    "# Build the configured model input data for the nth window\n",
    "X_train, X_test, y_train, y_test, returns_test = build_configured_model_input(\n",
    "                                    profits_df,\n",
    "                                    market_data_df,\n",
    "                                    macro_trends_df,\n",
    "                                    config,\n",
    "                                    metrics_config,\n",
    "                                    modeling_config)\n",
    "\n",
    "# Add time window indices to dfs with coin_ids\n",
    "X_train['time_window'] = n\n",
    "X_train.set_index('time_window', append=True, inplace=True)\n",
    "X_test['time_window'] = n\n",
    "X_test.set_index('time_window', append=True, inplace=True)\n",
    "returns_test['time_window'] = n\n",
    "returns_test.set_index('time_window', append=True, inplace=True)\n",
    "\n",
    "model_data = {\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'returns_test': returns_test\n",
    "}\n",
    "\n",
    "# return model_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mif.generate_time_windows(config)\n",
    "\n",
    "# Initialize empty lists to hold concatenated data\n",
    "X_train_list, X_test_list = [], []\n",
    "y_train_list, y_test_list = [], []\n",
    "returns_test_list = []\n",
    "\n",
    "for n, window in enumerate(time_windows):\n",
    "\n",
    "    model_data = mif.build_time_window_model_input(n, window, config, metrics_config, modeling_config)\n",
    "\n",
    "    # Append the current window's data to the lists\n",
    "    X_train_list.append(model_data['X_train'])\n",
    "    X_test_list.append(model_data['X_test'])\n",
    "    y_train_list.append(model_data['y_train'])\n",
    "    y_test_list.append(model_data['y_test'])\n",
    "    returns_test_list.append(model_data['returns_test'])\n",
    "\n",
    "\n",
    "# Concatenate all the data for each part\n",
    "X_train = pd.concat(X_train_list, axis=0)\n",
    "X_test = pd.concat(X_test_list, axis=0)\n",
    "y_train = pd.concat(y_train_list, axis=0)\n",
    "y_test = pd.concat(y_test_list, axis=0)\n",
    "returns_test = pd.concat(returns_test_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "model, model_id = m.train_model(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    modeling_config)\n",
    "\n",
    "# 3.5 Evaluate and save the model performance on the test set to a CSV\n",
    "metrics_dict, y_pred, y_pred_prob = m.evaluate_model(model, X_test, y_test, model_id, returns_test, modeling_config)\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "features = X_train.columns  # Feature names\n",
    "\n",
    "# Create a DataFrame with feature names and importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for module in modules:\n",
    "    importlib.reload(module)\n",
    "\n",
    "\n",
    "# Select y_pred_prob from the classifier, or y_pred from a regressor\n",
    "predictions = y_pred_prob or y_pred\n",
    "returns = returns_test['returns']\n",
    "winsorization_cutoff = modeling_config[\"evaluation\"][\"winsorization_cutoff\"]\n",
    "\n",
    "\n",
    "ia.generate_profitability_curves(predictions, returns, winsorization_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Window Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking profits_df downcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = config['training_data']['earliest_window_start']\n",
    "end_date = config['training_data']['modeling_period_end']\n",
    "minimum_wallet_inflows = config['data_cleaning']['minimum_wallet_inflows']\n",
    "\n",
    "# SQL query to retrieve profits data\n",
    "query_sql = f\"\"\"\n",
    "    -- STEP 1: retrieve profits data and apply USD inflows filter\n",
    "    -------------------------------------------------------------\n",
    "    with profits_base as (\n",
    "        select coin_id\n",
    "        ,date\n",
    "        ,wallet_address\n",
    "        ,profits_cumulative\n",
    "        ,usd_balance\n",
    "        ,usd_net_transfers\n",
    "        ,usd_inflows\n",
    "        ,usd_inflows_cumulative\n",
    "        from core.coin_wallet_profits\n",
    "        where date <= '{end_date}'\n",
    "    ),\n",
    "\n",
    "    usd_inflows_filter as (\n",
    "        select coin_id\n",
    "        ,wallet_address\n",
    "        ,max(usd_inflows_cumulative) as total_usd_inflows\n",
    "        from profits_base\n",
    "        -- we don't need to include coin-wallet pairs that have no transactions between\n",
    "        -- the start and end dates\n",
    "        group by 1,2\n",
    "    ),\n",
    "\n",
    "    profits_base_filtered as (\n",
    "        select pb.*\n",
    "        from profits_base pb\n",
    "        join usd_inflows_filter f on f.coin_id = pb.coin_id\n",
    "            and f.wallet_address = pb.wallet_address\n",
    "        where f.total_usd_inflows >= {minimum_wallet_inflows}\n",
    "    ),\n",
    "\n",
    "\n",
    "    -- STEP 2: create new records for all coin-wallet pairs as of the training_period_start\n",
    "    ---------------------------------------------------------------------------------------\n",
    "    -- compute the starting profits and balances as of the training_period_start\n",
    "    training_start_existing_rows as (\n",
    "        -- identify coin-wallet pairs that already have a balance as of the period end\n",
    "        select *\n",
    "        from profits_base_filtered\n",
    "        where date = '{start_date}'\n",
    "    ),\n",
    "    training_start_needs_rows as (\n",
    "        -- for coin-wallet pairs that don't have existing records, identify the row closest to the period end date\n",
    "        select t.*\n",
    "        ,cmd_previous.price as price_previous\n",
    "        ,cmd_training.price as price_current\n",
    "        ,row_number() over (partition by t.coin_id,t.wallet_address order by t.date desc) as rn\n",
    "        from profits_base_filtered t\n",
    "        left join training_start_existing_rows e on e.coin_id = t.coin_id\n",
    "            and e.wallet_address = t.wallet_address\n",
    "\n",
    "        -- obtain the last price used to compute the balance and profits data\n",
    "        join core.coin_market_data cmd_previous on cmd_previous.coin_id = t.coin_id and cmd_previous.date = t.date\n",
    "\n",
    "        -- obtain the training_period_start price so we can update the calculations\n",
    "        join core.coin_market_data cmd_training on cmd_training.coin_id = t.coin_id and cmd_training.date = '{start_date}'\n",
    "        where t.date < '{start_date}'\n",
    "        and e.coin_id is null\n",
    "    ),\n",
    "    training_start_new_rows as (\n",
    "        -- create a new row for the period end date by carrying the balance from the closest existing record\n",
    "        select t.coin_id\n",
    "        ,cast('{start_date}' as datetime) as date\n",
    "        ,t.wallet_address\n",
    "        -- profits_cumulative is the previous profits_cumulative + the change in profits up to the start_date\n",
    "        ,((t.price_current / t.price_previous) - 1) * t.usd_balance + t.profits_cumulative as profits_cumulative\n",
    "        -- usd_balance is previous balance * (1 + % change in price)\n",
    "        ,(t.price_current / t.price_previous) * t.usd_balance as usd_balance\n",
    "        -- there were no transfers\n",
    "        ,0 as usd_net_transfers\n",
    "        -- there were no inflows\n",
    "        ,0 as usd_inflows\n",
    "        -- no change since there were no inflows\n",
    "        ,usd_inflows_cumulative as usd_inflows_cumulative\n",
    "\n",
    "        from training_start_needs_rows t\n",
    "        where rn=1\n",
    "\n",
    "    ),\n",
    "\n",
    "    -- STEP 3: merge all records together\n",
    "    -------------------------------------\n",
    "    profits_merged as (\n",
    "        select * from profits_base_filtered\n",
    "        -- transfers prior to the training period are summarized in training_start_new_rows\n",
    "        where date >= '{start_date}'\n",
    "\n",
    "        union all\n",
    "\n",
    "        select * from training_start_new_rows\n",
    "    )\n",
    "\n",
    "    select coin_id\n",
    "    ,date\n",
    "\n",
    "    -- replace the memory-intensive address strings with integers\n",
    "    ,DENSE_RANK() OVER (ORDER BY wallet_address) as wallet_address\n",
    "\n",
    "    ,profits_cumulative\n",
    "    ,usd_balance\n",
    "    ,usd_net_transfers\n",
    "    ,usd_inflows\n",
    "    -- set a floor of $0.01 to avoid divide by 0 errors caused by rounding\n",
    "    ,greatest(0.01,usd_inflows_cumulative) as usd_inflows_cumulative\n",
    "    from profits_merged\n",
    "\"\"\"\n",
    "\n",
    "# Run the SQL query using dgc's run_sql method\n",
    "profits_df = dgc().run_sql(query_sql)\n",
    "\n",
    "logger.info('Converting columns to memory-optimized formats...')\n",
    "\n",
    "# Convert coin_id to categorical and date to date\n",
    "profits_df['coin_id'] = profits_df['coin_id'].astype('category')\n",
    "profits_df['date'] = pd.to_datetime(profits_df['date'])\n",
    "\n",
    "# Add total_return column\n",
    "profits_df['total_return'] = (profits_df['profits_cumulative']\n",
    "                                / profits_df['usd_inflows_cumulative'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = safe_downcast(profits_df, 'wallet_address', 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.can_cast(market_data_df['market_cap'].dtype, 'int32', casting='safe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df = safe_downcast(market_data_df, 'volume', 'int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Data resequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mif.generate_time_windows(config)\n",
    "n = 0\n",
    "window = time_windows[n]\n",
    "\n",
    "# Prepare the full configuration by applying overrides from the current trial config\n",
    "config, metrics_config, modeling_config = mif.prepare_configs(modeling_config['modeling']['config_folder'], window)\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mif.generate_time_windows(config)\n",
    "n = 0\n",
    "window = time_windows[n]\n",
    "\n",
    "\n",
    "# market_data_df, _ = cwm.split_dataframe_by_coverage(market_data_df, start_date, end_date, id_column='coin_id')\n",
    "# prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "market_data_df_full = market_data_df.copy()\n",
    "market_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "market_data_df = market_data_df_full.copy()\n",
    "print(market_data_df.columns)\n",
    "market_data_df = ind.generate_time_series_indicators('market_data', market_data_df, metrics_config)\n",
    "print(market_data_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(time_series_df.index, pd.RangeIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "market_data_df = market_data_df_full.copy()\n",
    "value_column = 'price'\n",
    "value_column_indicators_config = metrics_config['time_series']['market_data'][value_column]['indicators']\n",
    "id_column = 'coin_id'\n",
    "market_data_df = ind.generate_column_time_series_indicators(\n",
    "    market_data_df,\n",
    "    value_column,\n",
    "    value_column_indicators_config,\n",
    "    id_column\n",
    ")\n",
    "\n",
    "market_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = None\n",
    "if not id_column:\n",
    "    print('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df = time_series_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "# time_series_df = market_data_df[['date','coin_id','price']].copy()\n",
    "time_series_df = market_data_df_full.copy()\n",
    "config = config\n",
    "value_column_indicators_config = metrics_config['time_series']['market_data']['price']['indicators']\n",
    "value_column = 'price'\n",
    "id_column='coin_id'\n",
    "\n",
    "time_series_df = time_series_df.set_index(['coin_id','date'])\n",
    "\n",
    "# Data Quality Checks and Formatting\n",
    "if value_column not in time_series_df.columns:\n",
    "    raise KeyError(f\"Input DataFrame does not include column '{value_column}'.\")\n",
    "\n",
    "if time_series_df[value_column].isnull().any():\n",
    "    raise ValueError(f\"The '{value_column}' column contains null values, which are not allowed.\")\n",
    "\n",
    "# Indicator Calculations\n",
    "# ----------------------\n",
    "# If there is an id_column, group on it\n",
    "if id_column:\n",
    "    groupby_column = id_column\n",
    "# If there isn't, create a dummy_column for grouping and remove it later\n",
    "else:\n",
    "    time_series_df['dummy_group'] = 1\n",
    "    groupby_column = 'dummy_group'\n",
    "\n",
    "# For each indicator, loop through all options and add the appropriate column\n",
    "for indicator, indicator_config in value_column_indicators_config.items():\n",
    "    if indicator == 'sma':\n",
    "        windows = indicator_config['parameters']['window']\n",
    "        for w in windows:\n",
    "            ind_series = time_series_df.groupby(level=groupby_column, observed=True)[value_column].transform(\n",
    "                lambda x: ind.calculate_sma(x, w))\n",
    "            time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "    elif indicator == 'ema':\n",
    "        windows = indicator_config['parameters']['window']\n",
    "        for w in windows:\n",
    "            ind_series = time_series_df.groupby(level=groupby_column, observed=True)[value_column].transform(\n",
    "                lambda x: ind.calculate_ema(x, w))\n",
    "            time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "    # elif indicator == 'rsi':\n",
    "    #     windows = indicator_config['parameters']['window']\n",
    "    #     for w in windows:\n",
    "    #         ind_series = time_series_df.groupby(level=groupby_column, observed=True)['price'].transform(\n",
    "    #             lambda x: calculate_rsi(x, w))\n",
    "    #         time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "    # elif indicator == 'bollinger_bands_upper':\n",
    "    #     windows = indicator_config['parameters']['window']\n",
    "    #     num_std = indicator_config['parameters'].get('num_std', None)\n",
    "    #     for w in windows:\n",
    "    #         ind_series = time_series_df.groupby(level=groupby_column, observed=True)['price'].transform(\n",
    "    #             lambda x: calculate_bollinger_bands(x, 'upper', w, num_std))\n",
    "    #         time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "    # elif indicator == 'bollinger_bands_lower':\n",
    "    #     windows = indicator_config['parameters']['window']\n",
    "    #     num_std = indicator_config['parameters'].get('num_std', None)\n",
    "    #     for w in windows:\n",
    "    #         ind_series = time_series_df.groupby(level=groupby_column, observed=True)['price'].transform(\n",
    "    #             lambda x: calculate_bollinger_bands(x, 'lower', w, num_std))\n",
    "    #         time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "# Remove the dummy column if it was created\n",
    "if groupby_column == 'dummy_group':\n",
    "    time_series_df = time_series_df.drop('dummy_group', axis=1)\n",
    "\n",
    "logger.info(\"Generated indicators for column '%s' :%s\",\n",
    "            value_column,\n",
    "            list(value_column_indicators_config.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(value_column_indicators_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"%s\",value_column_indicators_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.xs('9d6619f4-b44b-4ff4-9f68-1f563f57e060',level='coin_id').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = indicator_config['parameters'].get('num_std', None)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.groupby(level='coin_id', observed=True)['price'].transform("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indicators implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "df = market_data_df.copy()\n",
    "df = market_data_df.set_index(['coin_id','date'])\n",
    "\n",
    "\n",
    "# Add Relative Strength Index (RSI)\n",
    "df['rsi'] = df.groupby(level='coin_id', observed=True)['price'].transform(\n",
    "    lambda x: ind.calculate_rsi(x, 14))\n",
    "# Add Money Flow Index (MFI)\n",
    "df = ind.add_mfi_column(df)\n",
    "\n",
    "# Calculate MACD with EMAs\n",
    "df['ema_12'] = df.groupby(level='coin_id', observed=True)['price'].transform(lambda x: ind.calculate_ema(x, 12))\n",
    "df['ema_26'] = df.groupby(level='coin_id', observed=True)['price'].transform(lambda x: ind.calculate_ema(x, 26))\n",
    "df = ind.add_crossover_column(df, 'ema_12', 'ema_26', drop_col1=True, drop_col2=True)\n",
    "\n",
    "# Add Bollinger Bands\n",
    "df = ind.add_bollinger_bands(df, include_middle=False)\n",
    "# Add crossover for price and upper band\n",
    "df = ind.add_crossover_column(df, 'price', 'bollinger_band_upper', drop_col1=False, drop_col2=True)\n",
    "# Add crossover for price and lower band\n",
    "df = ind.add_crossover_column(df, 'price', 'bollinger_band_lower', drop_col1=False, drop_col2=True)\n",
    "\n",
    "# Calculate OBV\n",
    "df['obv_price_volume'] = ind.generalized_obv(df['price'],df['volume'])\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Define a function to calculate MFI within each group, similar to the crossovers function\n",
    "def apply_mfi(group):\n",
    "    # Reset index to avoid issues with the multi-index during group operations\n",
    "    group = group.reset_index()\n",
    "    group['mfi'] = ind.calculate_mfi(group['price'], group['volume'])\n",
    "\n",
    "    # Set index back to the original multi-index\n",
    "    return group.set_index(['coin_id', 'date'])\n",
    "\n",
    "# Apply the function within each 'coin_id' group\n",
    "df = df.groupby('coin_id', observed=True, group_keys=False).apply(apply_mfi)\n",
    "\n",
    "# Display the updated DataFrame with the MFI column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "df2 = df[['ema_12','ema_26']].copy()\n",
    "\n",
    "df2 = ind.add_crossover_column(df2, 'ema_12', 'ema_26', drop_col1=True, drop_col2=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_crossovers(series1, series2):\n",
    "    \"\"\"\n",
    "    Identify crossovers between two time series.\n",
    "\n",
    "    This function calculates the points where series1 crosses over series2.\n",
    "    It handles NaN values by converting them to 0.\n",
    "\n",
    "    Parameters:\n",
    "    series1 (array-like): The first time series\n",
    "    series2 (array-like): The second time series\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: An array of the same length as the input series, where:\n",
    "        0 indicates no crossover\n",
    "        1 indicates an upward crossover (series1 crosses above series2)\n",
    "        -1 indicates a downward crossover (series1 crosses below series2)\n",
    "    \"\"\"\n",
    "    diff = series1 - series2\n",
    "\n",
    "    # Handle NaN values\n",
    "    diff = np.nan_to_num(diff, nan=0.0)\n",
    "\n",
    "    # Initialize crossovers array\n",
    "    crossovers = np.zeros(len(series1))\n",
    "\n",
    "    # Identify crossovers\n",
    "    signs = np.sign(diff)\n",
    "    sign_changes = signs[1:] != signs[:-1]\n",
    "    crossover_indices = np.where(sign_changes)[0] + 1\n",
    "\n",
    "    # Assign 1 for upward crossovers, -1 for downward crossovers\n",
    "    crossovers[crossover_indices] = np.where(signs[crossover_indices] > 0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ema_12','ema_26']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming `df` is your DataFrame with multi-index (coin_id, date) and ema_12, ema_26 columns\n",
    "\n",
    "# Define a function that applies identify_crossovers to a group\n",
    "def apply_crossovers(group):\n",
    "    group['crossovers'] = identify_crossovers(group['ema_12'], group['ema_26'])\n",
    "    return group\n",
    "\n",
    "# Apply the function within each 'coin_id' group\n",
    "df = df.groupby('coin_id', group_keys=False).apply(apply_crossovers)\n",
    "\n",
    "# Display the resulting DataFrame with the new 'crossovers' column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame with the new 'crossovers' column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "\n",
    "def sample_data():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample DataFrame for testing.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with sample data for testing indicators.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'BTC', 'BTC', 'ETH', 'ETH', 'ETH'],\n",
    "        'date': pd.date_range(start='2023-01-01', periods=6),\n",
    "        'price': [100, 110, 105, 200, 220, 210]\n",
    "    })\n",
    "sample_data=sample_data()\n",
    "\n",
    "def sample_config():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample configuration for testing.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A configuration dictionary for testing all supported indicators.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'time_series': {\n",
    "            'market_data': {\n",
    "                'price': {\n",
    "                    'indicators': {\n",
    "                        'sma': {'parameters': {'window': [2]}},\n",
    "                        'ema': {'parameters': {'window': [2]}},\n",
    "                        'rsi': {'parameters': {'window': [2]}},\n",
    "                        'bollinger_bands_upper': {'parameters': {'window': [2], 'num_std': 2}},\n",
    "                        'bollinger_bands_lower': {'parameters': {'window': [2], 'num_std': 2}}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "sample_config=sample_config()\n",
    "# @pytest.mark.unit\n",
    "# def test_all_supported_indicators(sample_data, sample_config):\n",
    "\"\"\"\n",
    "Test that all supported indicators are correctly calculated and added to the DataFrame.\n",
    "\n",
    "This test checks the calculation of SMA, EMA, RSI, and Bollinger Bands for the given sample data.\n",
    "\"\"\"\n",
    "result = ind.generate_time_series_indicators('market_data', sample_data, sample_config)\n",
    "\n",
    "# Calculate expected values\n",
    "# SMA (2-day)\n",
    "# For BTC: [None, 105, 107.5]\n",
    "# For ETH: [None, 210, 215]\n",
    "\n",
    "# EMA (2-day)\n",
    "# For BTC: [None, 106.67, 105.56]\n",
    "# For ETH: [None, 213.33, 211.11]\n",
    "# EMA = (Current * (2 / (1 + 2))) + (Previous EMA * (1 - (2 / (1 + 2))))\n",
    "\n",
    "# RSI (2-day)\n",
    "# For BTC: [None, 100, 33.33]\n",
    "# For ETH: [None, 100, 33.33]\n",
    "# RSI = 100 - (100 / (1 + (Average Gain / Average Loss)))\n",
    "\n",
    "# Bollinger Bands (2-day, 2 std dev)\n",
    "# Upper Band = SMA + (2 * std dev)\n",
    "# Lower Band = SMA - (2 * std dev)\n",
    "# For BTC: [None, 115, 112.5], [None, 95, 102.5]\n",
    "# For ETH: [None, 230, 225], [None, 190, 205]\n",
    "\n",
    "expected_columns = [\n",
    "    'coin_id', 'date', 'price',\n",
    "    'price_sma_2', 'price_ema_2', 'price_rsi_2',\n",
    "    'price_bollinger_bands_upper_2', 'price_bollinger_bands_lower_2'\n",
    "]\n",
    "\n",
    "assert list(result.columns) == expected_columns\n",
    "\n",
    "# Check SMA values\n",
    "expected_sma = [np.nan, 105, 107.5, np.nan, 210, 215]\n",
    "assert all(np.isclose(a, b, equal_nan=True) for a, b in zip(result['price_sma_2'], expected_sma))\n",
    "\n",
    "# Check EMA values\n",
    "expected_ema = [np.nan, 106.67, 105.56, np.nan, 213.33, 211.11]\n",
    "assert all(np.isclose(a, b, equal_nan=True, rtol=1e-2) for a, b in zip(result['price_ema_2'], expected_ema))\n",
    "\n",
    "# Check RSI values\n",
    "expected_rsi = [np.nan, 1.0, 0.6667, np.nan, 1.0, 0.6667]\n",
    "assert all(np.isclose(a, b, equal_nan=True, rtol=1e-2) for a, b in zip(result['price_rsi_2'], expected_rsi))\n",
    "\n",
    "# Check Bollinger Bands values\n",
    "expected_bb_upper = [np.nan, 115, 112.5, np.nan, 230, 225]\n",
    "expected_bb_lower = [np.nan, 95, 102.5, np.nan, 190, 205]\n",
    "assert all(np.isclose(a, b, equal_nan=True) for a, b in zip(result['price_bollinger_bands_upper_2'], expected_bb_upper))\n",
    "assert all(np.isclose(a, b, equal_nan=True) for a, b in zip(result['price_bollinger_bands_lower_2'], expected_bb_lower))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['price_bollinger_bands_upper_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'price': [100, 110, 105, 200, 220, 210]\n",
    "})\n",
    "\n",
    "upper_band = ind.calculate_bollinger_bands(sample_data['price'], 'upper', window=2, num_std=2)\n",
    "print(upper_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['price_rsi_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result['price_rsi_2'], expected_rsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result_df.loc[result_df['coin_id'] == 'coin1', 'price_sma_2'].values) == list(expected_sma_2_coin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(expected_sma_2_coin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_rsi.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
