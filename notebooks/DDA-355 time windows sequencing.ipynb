{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Custom format function for displaying numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as ri\n",
    "import feature_engineering as fe\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.model_input_flows as mf\n",
    "import utils as u\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [dr, ri, fe, cwm, ind, m, ia, mf, u]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Initialize empty lists to hold concatenated data\n",
    "X_train_list, X_test_list = [], []\n",
    "y_train_list, y_test_list = [], []\n",
    "returns_test_list = []\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mf.generate_time_windows(config)\n",
    "\n",
    "for n, window in enumerate(time_windows):\n",
    "\n",
    "    model_data = mf.build_time_window_model_input(n, window, config, metrics_config, modeling_config)\n",
    "\n",
    "    # Append the current window's data to the lists\n",
    "    X_train_list.append(model_data['X_train'])\n",
    "    X_test_list.append(model_data['X_test'])\n",
    "    y_train_list.append(model_data['y_train'])\n",
    "    y_test_list.append(model_data['y_test'])\n",
    "    returns_test_list.append(model_data['returns_test'])\n",
    "\n",
    "\n",
    "# Concatenate all the data for each part\n",
    "X_train = pd.concat(X_train_list, axis=0)\n",
    "X_test = pd.concat(X_test_list, axis=0)\n",
    "y_train = pd.concat(y_train_list, axis=0)\n",
    "y_test = pd.concat(y_test_list, axis=0)\n",
    "returns_test = pd.concat(returns_test_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "model, model_id = m.train_model(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    modeling_config)\n",
    "\n",
    "# 3.5 Evaluate and save the model performance on the test set to a CSV\n",
    "metrics_dict, y_pred, y_pred_prob = m.evaluate_model(model, X_test, y_test, model_id, returns_test, modeling_config)\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "features = X_train.columns  # Feature names\n",
    "\n",
    "# Create a DataFrame with feature names and importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    importlib.reload(module)\n",
    "\n",
    "\n",
    "# Select y_pred_prob from the classifier, or y_pred from a regressor\n",
    "predictions = y_pred_prob or y_pred\n",
    "returns = returns_test['returns']\n",
    "winsorization_cutoff = modeling_config[\"evaluation\"][\"winsorization_cutoff\"]\n",
    "\n",
    "\n",
    "ia.generate_profitability_curves(predictions, returns, winsorization_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    importlib.reload(module)\n",
    "\n",
    "\n",
    "# Select y_pred_prob from the classifier, or y_pred from a regressor\n",
    "predictions = y_pred_prob or y_pred\n",
    "returns = returns_test['returns']\n",
    "winsorization_cutoff = modeling_config[\"evaluation\"][\"winsorization_cutoff\"]\n",
    "\n",
    "\n",
    "ia.generate_profitability_curves(predictions, returns, winsorization_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### global_market_data from coingecko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/jeremymeadow/DreamsData/Local/datasets/macro_trends/CoinGecko-GlobalCryptoMktCap-2024-10-04.csv\")\n",
    "df['date'] = pd.to_datetime(df['snapped_at'], unit='ms')\n",
    "df = df.drop(columns='snapped_at')\n",
    "df = df[['date','market_cap','total_volume']]\n",
    "\n",
    "df.to_csv(\"/Users/jeremymeadow/DreamsData/Local/datasets/macro_trends/formatted/crypto_global_market.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bitcoin indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_process_bitcoin_data(directory_path):\n",
    "    # List to store individual dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate through CSV files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Convert 'DateTime' column to datetime type\n",
    "            df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "            # Set 'DateTime' as the index\n",
    "            df.set_index('DateTime', inplace=True)\n",
    "\n",
    "            # Append to the list of dataframes\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Join all dataframes\n",
    "    combined_df = pd.concat(dfs, axis=1, join='outer')\n",
    "\n",
    "    # Remove duplicate 'BTC price' columns\n",
    "    combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]\n",
    "\n",
    "    # Define a dictionary for column renaming\n",
    "    rename_dict = {\n",
    "        'BTC price': 'btc_price',\n",
    "        'CDD Terminal Ajusted 90dma': 'cdd_terminal_adjusted_90dma',\n",
    "        'Fear and Greed': 'fear_and_greed',\n",
    "        'MVRV Z-Score': 'mvrv_z_score',\n",
    "        'VDD Multiple': 'vdd_multiple'\n",
    "    }\n",
    "\n",
    "    # Rename columns using the dictionary\n",
    "    combined_df = combined_df.rename(columns=rename_dict)\n",
    "\n",
    "    # Rename the index (DateTime column)\n",
    "    combined_df.index.name = 'date'\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Example usage:\n",
    "# df = load_and_process_bitcoin_data('/path/to/csv/directory')\n",
    "# print(df.head())\n",
    "\n",
    "df = load_and_process_bitcoin_data('/Users/jeremymeadow/DreamsData/Local/datasets/macro_trends/bitcoin_macro_indicators')\n",
    "\n",
    "# remove partial recent records\n",
    "df = df.loc[:'2024-10-02']\n",
    "df.to_csv(\"/Users/jeremymeadow/DreamsData/Local/datasets/macro_trends/formatted/bitcoin_indicators.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Window Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Initialize empty lists to hold concatenated data\n",
    "X_train_list, X_test_list = [], []\n",
    "y_train_list, y_test_list = [], []\n",
    "returns_test_list = []\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mf.generate_time_windows(config)\n",
    "\n",
    "# for n, window in enumerate(time_windows):\n",
    "\n",
    "#     model_data = mf.build_time_window_model_input(n, window, config, metrics_config, modeling_config)\n",
    "\n",
    "n = 0\n",
    "window = time_windows[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Market Data resequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Prepare the full configuration by applying overrides from the current trial config\n",
    "config, metrics_config, modeling_config = mf.prepare_configs(modeling_config['modeling']['config_folder'], window)\n",
    "\n",
    "# Calculate overall start and end dates\n",
    "end_date = pd.to_datetime(config['training_data']['modeling_period_end'])\n",
    "\n",
    "window_duration = config['training_data']['modeling_period_duration'] + config['training_data']['training_period_duration']\n",
    "window_count = config['training_data']['additional_windows'] + 1\n",
    "total_days = window_duration * window_count\n",
    "start_date = pd.to_datetime(end_date) - timedelta(days=total_days)\n",
    "\n",
    "\n",
    "# Retrieve market data\n",
    "market_data_df = dr.retrieve_market_data()\n",
    "# market_data_df, _ = cwm.split_dataframe_by_coverage(market_data_df, start_date, end_date, id_column='coin_id')\n",
    "# prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "market_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "df = market_data_df.copy()\n",
    "df = market_data_df.set_index(['coin_id','date'])\n",
    "\n",
    "\n",
    "# Add Relative Strength Index (RSI)\n",
    "df['rsi'] = df.groupby(level='coin_id', observed=True)['price'].transform(\n",
    "    lambda x: ind.calculate_rsi(x, 14))\n",
    "# Add Money Flow Index (MFI)\n",
    "df = ind.add_mfi_column(df)\n",
    "\n",
    "# Calculate MACD with EMAs\n",
    "df['ema_12'] = df.groupby(level='coin_id', observed=True)['price'].transform(lambda x: ind.calculate_ema(x, 12))\n",
    "df['ema_26'] = df.groupby(level='coin_id', observed=True)['price'].transform(lambda x: ind.calculate_ema(x, 26))\n",
    "df = ind.add_crossover_column(df, 'ema_12', 'ema_26', drop_col1=True, drop_col2=True)\n",
    "\n",
    "# Add Bollinger Bands\n",
    "df = ind.add_bollinger_bands(df, include_middle=False)\n",
    "# Add crossover for price and upper band\n",
    "df = ind.add_crossover_column(df, 'price', 'bollinger_band_upper', drop_col1=False, drop_col2=True)\n",
    "# Add crossover for price and lower band\n",
    "df = ind.add_crossover_column(df, 'price', 'bollinger_band_lower', drop_col1=False, drop_col2=True)\n",
    "\n",
    "# Calculate OBV\n",
    "df['obv_price_volume'] = ind.generalized_obv(df['price'],df['volume'])\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_middle=False\n",
    "if not include_middle:\n",
    "    print('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "df = ind.add_bollinger_bands(df)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Define a function to calculate MFI within each group, similar to the crossovers function\n",
    "def apply_mfi(group):\n",
    "    # Reset index to avoid issues with the multi-index during group operations\n",
    "    group = group.reset_index()\n",
    "    group['mfi'] = ind.calculate_mfi(group['price'], group['volume'])\n",
    "\n",
    "    # Set index back to the original multi-index\n",
    "    return group.set_index(['coin_id', 'date'])\n",
    "\n",
    "# Apply the function within each 'coin_id' group\n",
    "df = df.groupby('coin_id', observed=True, group_keys=False).apply(apply_mfi)\n",
    "\n",
    "# Display the updated DataFrame with the MFI column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "df2 = df[['ema_12','ema_26']].copy()\n",
    "\n",
    "df2 = ind.add_crossover_column(df2, 'ema_12', 'ema_26', drop_col1=True, drop_col2=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_crossovers(series1, series2):\n",
    "    \"\"\"\n",
    "    Identify crossovers between two time series.\n",
    "\n",
    "    This function calculates the points where series1 crosses over series2.\n",
    "    It handles NaN values by converting them to 0.\n",
    "\n",
    "    Parameters:\n",
    "    series1 (array-like): The first time series\n",
    "    series2 (array-like): The second time series\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: An array of the same length as the input series, where:\n",
    "        0 indicates no crossover\n",
    "        1 indicates an upward crossover (series1 crosses above series2)\n",
    "        -1 indicates a downward crossover (series1 crosses below series2)\n",
    "    \"\"\"\n",
    "    diff = series1 - series2\n",
    "\n",
    "    # Handle NaN values\n",
    "    diff = np.nan_to_num(diff, nan=0.0)\n",
    "\n",
    "    # Initialize crossovers array\n",
    "    crossovers = np.zeros(len(series1))\n",
    "\n",
    "    # Identify crossovers\n",
    "    signs = np.sign(diff)\n",
    "    sign_changes = signs[1:] != signs[:-1]\n",
    "    crossover_indices = np.where(sign_changes)[0] + 1\n",
    "\n",
    "    # Assign 1 for upward crossovers, -1 for downward crossovers\n",
    "    crossovers[crossover_indices] = np.where(signs[crossover_indices] > 0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ema_12','ema_26']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming `df` is your DataFrame with multi-index (coin_id, date) and ema_12, ema_26 columns\n",
    "\n",
    "# Define a function that applies identify_crossovers to a group\n",
    "def apply_crossovers(group):\n",
    "    group['crossovers'] = identify_crossovers(group['ema_12'], group['ema_26'])\n",
    "    return group\n",
    "\n",
    "# Apply the function within each 'coin_id' group\n",
    "df = df.groupby('coin_id', group_keys=False).apply(apply_crossovers)\n",
    "\n",
    "# Display the resulting DataFrame with the new 'crossovers' column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame with the new 'crossovers' column\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
