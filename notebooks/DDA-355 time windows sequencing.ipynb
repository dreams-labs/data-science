{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Custom format function for displaying numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as ri\n",
    "import feature_engineering as fe\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.model_input_flows as mf\n",
    "import utils as u\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [dr, ri, fe, cwm, ind, m, ia, mf, u]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Initialize empty lists to hold concatenated data\n",
    "X_train_list, X_test_list = [], []\n",
    "y_train_list, y_test_list = [], []\n",
    "returns_test_list = []\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mf.generate_time_windows(config)\n",
    "\n",
    "for n, window in enumerate(time_windows):\n",
    "\n",
    "    model_data = mf.build_time_window_model_input(n, window, config, metrics_config, modeling_config)\n",
    "\n",
    "    # Append the current window's data to the lists\n",
    "    X_train_list.append(model_data['X_train'])\n",
    "    X_test_list.append(model_data['X_test'])\n",
    "    y_train_list.append(model_data['y_train'])\n",
    "    y_test_list.append(model_data['y_test'])\n",
    "    returns_test_list.append(model_data['returns_test'])\n",
    "\n",
    "\n",
    "# Concatenate all the data for each part\n",
    "X_train = pd.concat(X_train_list, axis=0)\n",
    "X_test = pd.concat(X_test_list, axis=0)\n",
    "y_train = pd.concat(y_train_list, axis=0)\n",
    "y_test = pd.concat(y_test_list, axis=0)\n",
    "returns_test = pd.concat(returns_test_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "model, model_id = m.train_model(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    modeling_config)\n",
    "\n",
    "# 3.5 Evaluate and save the model performance on the test set to a CSV\n",
    "metrics_dict, y_pred, y_pred_prob = m.evaluate_model(model, X_test, y_test, model_id, returns_test, modeling_config)\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "features = X_train.columns  # Feature names\n",
    "\n",
    "# Create a DataFrame with feature names and importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    importlib.reload(module)\n",
    "\n",
    "\n",
    "# Select y_pred_prob from the classifier, or y_pred from a regressor\n",
    "predictions = y_pred_prob or y_pred\n",
    "returns = returns_test['returns']\n",
    "winsorization_cutoff = modeling_config[\"evaluation\"][\"winsorization_cutoff\"]\n",
    "\n",
    "\n",
    "ia.generate_profitability_curves(predictions, returns, winsorization_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    importlib.reload(module)\n",
    "\n",
    "\n",
    "# Select y_pred_prob from the classifier, or y_pred from a regressor\n",
    "predictions = y_pred_prob or y_pred\n",
    "returns = returns_test['returns']\n",
    "winsorization_cutoff = modeling_config[\"evaluation\"][\"winsorization_cutoff\"]\n",
    "\n",
    "\n",
    "ia.generate_profitability_curves(predictions, returns, winsorization_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### global_market_data from coingecko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/jeremymeadow/DreamsData/Local/datasets/macro_trends/CoinGecko-GlobalCryptoMktCap-2024-10-04.csv\")\n",
    "df['date'] = pd.to_datetime(df['snapped_at'], unit='ms')\n",
    "df = df.drop(columns='snapped_at')\n",
    "df = df[['date','market_cap','total_volume']]\n",
    "\n",
    "df.to_csv(\"/Users/jeremymeadow/DreamsData/Local/datasets/macro_trends/formatted/crypto_global_market.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bitcoin indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_process_bitcoin_data(directory_path):\n",
    "    # List to store individual dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate through CSV files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Convert 'DateTime' column to datetime type\n",
    "            df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "            # Set 'DateTime' as the index\n",
    "            df.set_index('DateTime', inplace=True)\n",
    "\n",
    "            # Append to the list of dataframes\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Join all dataframes\n",
    "    combined_df = pd.concat(dfs, axis=1, join='outer')\n",
    "\n",
    "    # Remove duplicate 'BTC price' columns\n",
    "    combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]\n",
    "\n",
    "    # Define a dictionary for column renaming\n",
    "    rename_dict = {\n",
    "        'BTC price': 'btc_price',\n",
    "        'CDD Terminal Ajusted 90dma': 'cdd_terminal_adjusted_90dma',\n",
    "        'Fear and Greed': 'fear_and_greed',\n",
    "        'MVRV Z-Score': 'mvrv_z_score',\n",
    "        'VDD Multiple': 'vdd_multiple'\n",
    "    }\n",
    "\n",
    "    # Rename columns using the dictionary\n",
    "    combined_df = combined_df.rename(columns=rename_dict)\n",
    "\n",
    "    # Rename the index (DateTime column)\n",
    "    combined_df.index.name = 'date'\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Example usage:\n",
    "# df = load_and_process_bitcoin_data('/path/to/csv/directory')\n",
    "# print(df.head())\n",
    "\n",
    "df = load_and_process_bitcoin_data('/Users/jeremymeadow/DreamsData/Local/datasets/macro_trends/bitcoin_macro_indicators')\n",
    "\n",
    "# remove partial recent records\n",
    "df = df.loc[:'2024-10-02']\n",
    "df.to_csv(\"/Users/jeremymeadow/DreamsData/Local/datasets/macro_trends/formatted/bitcoin_indicators.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Window Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# # Calculate overall start and end dates\n",
    "# end_date = pd.to_datetime(config['training_data']['modeling_period_end'])\n",
    "\n",
    "# window_duration = config['training_data']['modeling_period_duration'] + config['training_data']['training_period_duration']\n",
    "# window_count = config['training_data']['additional_windows'] + 1\n",
    "# total_days = window_duration * window_count\n",
    "# start_date = pd.to_datetime(end_date) - timedelta(days=total_days)\n",
    "\n",
    "# Initialize empty lists to hold concatenated data\n",
    "X_train_list, X_test_list = [], []\n",
    "y_train_list, y_test_list = [], []\n",
    "returns_test_list = []\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mf.generate_time_windows(config)\n",
    "\n",
    "# for n, window in enumerate(time_windows):\n",
    "\n",
    "#     model_data = mf.build_time_window_model_input(n, window, config, metrics_config, modeling_config)\n",
    "\n",
    "n = 0\n",
    "window = time_windows[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Market Data resequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mf.generate_time_windows(config)\n",
    "n = 0\n",
    "window = time_windows[n]\n",
    "\n",
    "# Prepare the full configuration by applying overrides from the current trial config\n",
    "config, metrics_config, modeling_config = mf.prepare_configs(modeling_config['modeling']['config_folder'], window)\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mf.generate_time_windows(config)\n",
    "n = 0\n",
    "window = time_windows[n]\n",
    "\n",
    "# Retrieve market data\n",
    "market_data_df = dr.retrieve_market_data()\n",
    "market_data_df = dr.clean_market_data(market_data_df, config)\n",
    "# market_data_df, _ = cwm.split_dataframe_by_coverage(market_data_df, start_date, end_date, id_column='coin_id')\n",
    "# prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "market_data_df_full = market_data_df.copy()\n",
    "market_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "\n",
    "market_data_df = market_data_df_full.copy()\n",
    "value_column = 'price'\n",
    "value_column_indicators_config = metrics_config['time_series']['market_data'][value_column]['indicators']\n",
    "id_column = 'coin_id'\n",
    "market_data_df = ind.generate_time_series_indicators(\n",
    "    market_data_df,\n",
    "    value_column,\n",
    "    value_column_indicators_config,\n",
    "    id_column\n",
    ")\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = None\n",
    "if not id_column:\n",
    "    print('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df = time_series_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "# time_series_df = market_data_df[['date','coin_id','price']].copy()\n",
    "time_series_df = market_data_df_full.copy()\n",
    "config = config\n",
    "value_column_indicators_config = metrics_config['time_series']['market_data']['price']['indicators']\n",
    "value_column = 'price'\n",
    "id_column='coin_id'\n",
    "\n",
    "time_series_df = time_series_df.set_index(['coin_id','date'])\n",
    "\n",
    "# Data Quality Checks and Formatting\n",
    "if value_column not in time_series_df.columns:\n",
    "    raise KeyError(f\"Input DataFrame does not include column '{value_column}'.\")\n",
    "\n",
    "if time_series_df[value_column].isnull().any():\n",
    "    raise ValueError(f\"The '{value_column}' column contains null values, which are not allowed.\")\n",
    "\n",
    "# Indicator Calculations\n",
    "# ----------------------\n",
    "# If there is an id_column, group on it\n",
    "if id_column:\n",
    "    groupby_column = id_column\n",
    "# If there isn't, create a dummy_column for grouping and remove it later\n",
    "else:\n",
    "    time_series_df['dummy_group'] = 1\n",
    "    groupby_column = 'dummy_group'\n",
    "\n",
    "# For each indicator, loop through all options and add the appropriate column\n",
    "for indicator, indicator_config in value_column_indicators_config.items():\n",
    "    if indicator == 'sma':\n",
    "        windows = indicator_config['parameters']['window']\n",
    "        for w in windows:\n",
    "            ind_series = time_series_df.groupby(level=groupby_column, observed=True)[value_column].transform(\n",
    "                lambda x: ind.calculate_sma(x, w))\n",
    "            time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "    elif indicator == 'ema':\n",
    "        windows = indicator_config['parameters']['window']\n",
    "        for w in windows:\n",
    "            ind_series = time_series_df.groupby(level=groupby_column, observed=True)[value_column].transform(\n",
    "                lambda x: ind.calculate_ema(x, w))\n",
    "            time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "    # elif indicator == 'rsi':\n",
    "    #     windows = indicator_config['parameters']['window']\n",
    "    #     for w in windows:\n",
    "    #         ind_series = time_series_df.groupby(level=groupby_column, observed=True)['price'].transform(\n",
    "    #             lambda x: calculate_rsi(x, w))\n",
    "    #         time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "    # elif indicator == 'bollinger_bands_upper':\n",
    "    #     windows = indicator_config['parameters']['window']\n",
    "    #     num_std = indicator_config['parameters'].get('num_std', None)\n",
    "    #     for w in windows:\n",
    "    #         ind_series = time_series_df.groupby(level=groupby_column, observed=True)['price'].transform(\n",
    "    #             lambda x: calculate_bollinger_bands(x, 'upper', w, num_std))\n",
    "    #         time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "    # elif indicator == 'bollinger_bands_lower':\n",
    "    #     windows = indicator_config['parameters']['window']\n",
    "    #     num_std = indicator_config['parameters'].get('num_std', None)\n",
    "    #     for w in windows:\n",
    "    #         ind_series = time_series_df.groupby(level=groupby_column, observed=True)['price'].transform(\n",
    "    #             lambda x: calculate_bollinger_bands(x, 'lower', w, num_std))\n",
    "    #         time_series_df[f\"{value_column}_{indicator}_{w}\"] = ind_series\n",
    "\n",
    "# Remove the dummy column if it was created\n",
    "if groupby_column == 'dummy_group':\n",
    "    time_series_df = time_series_df.drop('dummy_group', axis=1)\n",
    "\n",
    "logger.info(\"Generated indicators for column '%s' :%s\",\n",
    "            value_column,\n",
    "            list(value_column_indicators_config.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(value_column_indicators_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"%s\",value_column_indicators_config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.xs('9d6619f4-b44b-4ff4-9f68-1f563f57e060',level='coin_id').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = indicator_config['parameters'].get('num_std', None)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.groupby(level='coin_id', observed=True)['price'].transform("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indicators implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "df = market_data_df.copy()\n",
    "df = market_data_df.set_index(['coin_id','date'])\n",
    "\n",
    "\n",
    "# Add Relative Strength Index (RSI)\n",
    "df['rsi'] = df.groupby(level='coin_id', observed=True)['price'].transform(\n",
    "    lambda x: ind.calculate_rsi(x, 14))\n",
    "# Add Money Flow Index (MFI)\n",
    "df = ind.add_mfi_column(df)\n",
    "\n",
    "# Calculate MACD with EMAs\n",
    "df['ema_12'] = df.groupby(level='coin_id', observed=True)['price'].transform(lambda x: ind.calculate_ema(x, 12))\n",
    "df['ema_26'] = df.groupby(level='coin_id', observed=True)['price'].transform(lambda x: ind.calculate_ema(x, 26))\n",
    "df = ind.add_crossover_column(df, 'ema_12', 'ema_26', drop_col1=True, drop_col2=True)\n",
    "\n",
    "# Add Bollinger Bands\n",
    "df = ind.add_bollinger_bands(df, include_middle=False)\n",
    "# Add crossover for price and upper band\n",
    "df = ind.add_crossover_column(df, 'price', 'bollinger_band_upper', drop_col1=False, drop_col2=True)\n",
    "# Add crossover for price and lower band\n",
    "df = ind.add_crossover_column(df, 'price', 'bollinger_band_lower', drop_col1=False, drop_col2=True)\n",
    "\n",
    "# Calculate OBV\n",
    "df['obv_price_volume'] = ind.generalized_obv(df['price'],df['volume'])\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Define a function to calculate MFI within each group, similar to the crossovers function\n",
    "def apply_mfi(group):\n",
    "    # Reset index to avoid issues with the multi-index during group operations\n",
    "    group = group.reset_index()\n",
    "    group['mfi'] = ind.calculate_mfi(group['price'], group['volume'])\n",
    "\n",
    "    # Set index back to the original multi-index\n",
    "    return group.set_index(['coin_id', 'date'])\n",
    "\n",
    "# Apply the function within each 'coin_id' group\n",
    "df = df.groupby('coin_id', observed=True, group_keys=False).apply(apply_mfi)\n",
    "\n",
    "# Display the updated DataFrame with the MFI column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "df2 = df[['ema_12','ema_26']].copy()\n",
    "\n",
    "df2 = ind.add_crossover_column(df2, 'ema_12', 'ema_26', drop_col1=True, drop_col2=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_crossovers(series1, series2):\n",
    "    \"\"\"\n",
    "    Identify crossovers between two time series.\n",
    "\n",
    "    This function calculates the points where series1 crosses over series2.\n",
    "    It handles NaN values by converting them to 0.\n",
    "\n",
    "    Parameters:\n",
    "    series1 (array-like): The first time series\n",
    "    series2 (array-like): The second time series\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: An array of the same length as the input series, where:\n",
    "        0 indicates no crossover\n",
    "        1 indicates an upward crossover (series1 crosses above series2)\n",
    "        -1 indicates a downward crossover (series1 crosses below series2)\n",
    "    \"\"\"\n",
    "    diff = series1 - series2\n",
    "\n",
    "    # Handle NaN values\n",
    "    diff = np.nan_to_num(diff, nan=0.0)\n",
    "\n",
    "    # Initialize crossovers array\n",
    "    crossovers = np.zeros(len(series1))\n",
    "\n",
    "    # Identify crossovers\n",
    "    signs = np.sign(diff)\n",
    "    sign_changes = signs[1:] != signs[:-1]\n",
    "    crossover_indices = np.where(sign_changes)[0] + 1\n",
    "\n",
    "    # Assign 1 for upward crossovers, -1 for downward crossovers\n",
    "    crossovers[crossover_indices] = np.where(signs[crossover_indices] > 0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ema_12','ema_26']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming `df` is your DataFrame with multi-index (coin_id, date) and ema_12, ema_26 columns\n",
    "\n",
    "# Define a function that applies identify_crossovers to a group\n",
    "def apply_crossovers(group):\n",
    "    group['crossovers'] = identify_crossovers(group['ema_12'], group['ema_26'])\n",
    "    return group\n",
    "\n",
    "# Apply the function within each 'coin_id' group\n",
    "df = df.groupby('coin_id', group_keys=False).apply(apply_crossovers)\n",
    "\n",
    "# Display the resulting DataFrame with the new 'crossovers' column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame with the new 'crossovers' column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "def multi_series_df():\n",
    "    \"\"\"\n",
    "    Fixture to generate a sample multi-series DataFrame with 'coin_id', 'date', and 'price' columns.\n",
    "    The data simulates two different coins with daily prices over 5 days each.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'coin_id': ['coin1', 'coin1', 'coin1', 'coin1', 'coin1', 'coin2', 'coin2', 'coin2', 'coin2', 'coin2'],\n",
    "        'date': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05',\n",
    "                 '2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05'],\n",
    "        'price': [100, 105, 102, 108, 110, 200, 198, 202, 205, 210]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "multi_series_df=multi_series_df()\n",
    "def sma_ema_config():\n",
    "    \"\"\"\n",
    "    Fixture to provide a sample indicator configuration with both SMA and EMA.\n",
    "    This configuration specifies two window sizes for each indicator.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'sma': {\n",
    "            'parameters': {\n",
    "                'window': [2, 3]\n",
    "            }\n",
    "        },\n",
    "        'ema': {\n",
    "            'parameters': {\n",
    "                'window': [2, 3]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "sma_ema_config = sma_ema_config()\n",
    "\n",
    "# def test_generate_time_series_indicators_multi_series(multi_series_df, sma_ema_config):\n",
    "\"\"\"\n",
    "Test case for generate_time_series_indicators to verify that SMA and EMA are calculated\n",
    "separately for each coin_id and not mixed together.\n",
    "\n",
    "Steps:\n",
    "1. Group by 'coin_id', calculate SMA and EMA for 'price' with windows of 2 and 3.\n",
    "2. Verify the correctness of each SMA and EMA calculation, ensuring proper grouping by coin_id.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Run the function\n",
    "result_df = ind.generate_time_series_indicators(\n",
    "    time_series_df=multi_series_df,\n",
    "    value_column='price',\n",
    "    value_column_indicators_config=sma_ema_config,\n",
    "    id_column='coin_id'\n",
    ")\n",
    "\n",
    "# 2. Expected SMA for coin1 (window=2):\n",
    "# SMA for 2024-01-02: (100+105)/2 = 102.5\n",
    "# SMA for 2024-01-03: (105+102)/2 = 103.5\n",
    "# SMA for 2024-01-04: (102+108)/2 = 105\n",
    "# SMA for 2024-01-05: (108+110)/2 = 109\n",
    "expected_sma_2_coin1 = [np.nan, 102.5, 103.5, 105, 109]\n",
    "\n",
    "# 3. Expected SMA for coin2 (window=2):\n",
    "# SMA for 2024-01-02: (200+198)/2 = 199\n",
    "# SMA for 2024-01-03: (198+202)/2 = 200\n",
    "# SMA for 2024-01-04: (202+205)/2 = 203.5\n",
    "# SMA for 2024-01-05: (205+210)/2 = 207.5\n",
    "expected_sma_2_coin2 = [np.nan, 199, 200, 203.5, 207.5]\n",
    "\n",
    "# 4. Expected EMA for coin1 and coin2 (window=2):\n",
    "# Use a simple approximate EMA formula for these values and compare\n",
    "# For EMA calculations, manual results can vary due to smoothing,\n",
    "# but let's assume the results here are mocked for the test.\n",
    "\n",
    "# 5. Assert the values are correct for both coins (coin1 and coin2)\n",
    "assert np.allclose(\n",
    "    list(result_df.loc[result_df['coin_id'] == 'coin1', 'price_sma_2'].values),\n",
    "    expected_sma_2_coin1,\n",
    "    equal_nan=True\n",
    "), \"SMA (window=2) for coin1 is incorrect.\"\n",
    "\n",
    "assert np.allclose(\n",
    "    list(result_df.loc[result_df['coin_id'] == 'coin2', 'price_sma_2'].values),\n",
    "    expected_sma_2_coin2,\n",
    "    equal_nan=True\n",
    "), \"SMA (window=2) for coin2 is incorrect.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result_df.loc[result_df['coin_id'] == 'coin1', 'price_sma_2'].values) == list(expected_sma_2_coin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(expected_sma_2_coin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_rsi.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
