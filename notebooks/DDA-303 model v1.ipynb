{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingModuleSource=false\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "import progressbar\n",
    "\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# import local files if necessary\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df, create_progress_bar\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "import utils as u\n",
    "importlib.reload(u)\n",
    "\n",
    "# load configs\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "# retreive market data\n",
    "market_data_df = td.retrieve_market_data()\n",
    "market_data_df,_ = td.fill_market_data_gaps(market_data_df,config['data_cleaning']['max_gap_days'])\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = td.prepare_profits_data(transfers_df, market_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "# initial steps for this model\n",
    "filtered_market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n",
    "\n",
    "training_data_tuples = []\n",
    "training_data_dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "# dataset variables\n",
    "dataset_category = 'time_series'\n",
    "dataset_name = 'market_data'\n",
    "dataset_df = filtered_market_data_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "# declare dataset configs based on variables\n",
    "dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "dataset_metrics_config = metrics_config[dataset_category][dataset_name]\n",
    "\n",
    "# calculate metrics for each value column\n",
    "for value_column in list(dataset_metrics_config.keys()):\n",
    "\n",
    "    # a value_column-specific df will be used for feature generation\n",
    "    value_column_config = config['datasets'][dataset_category][dataset_name][value_column]\n",
    "    value_column_metrics_config = metrics_config[dataset_category][dataset_name][value_column]\n",
    "    value_column_df = dataset_df[['date','coin_id',value_column]].copy()\n",
    "\n",
    "    # check if there are any time series metrics to add, e.g. sma, ema, etc\n",
    "    if 'metrics' in value_column_metrics_config:\n",
    "\n",
    "        # calculate and merge all metrics in the config\n",
    "        all_metrics = []\n",
    "\n",
    "        # generate metrics\n",
    "        metric_df, _ = cwm.generate_time_series_metrics(\n",
    "            metric_df,\n",
    "            config,\n",
    "            value_column_metrics_config['metrics'],\n",
    "            value_column,\n",
    "            id_column='coin_id'\n",
    "        )\n",
    "\n",
    "        all_metrics.append(metric_df)\n",
    "\n",
    "        # join all generated metrics for the value_column together\n",
    "        value_column_metrics_df = all_metrics[0]\n",
    "        for metrics_df in all_metrics[1:]:\n",
    "            value_column_metrics_df = pd.merge(value_column_metrics_df, metrics_df, on='date', how='outer')\n",
    "\n",
    "    else:\n",
    "        # if no additional metrics are needed, pass through coins in the original df that have values for all dates\n",
    "        value_column_metrics_df, _, _ = cwm.split_dataframe_by_coverage(\n",
    "            value_column_df,\n",
    "            config['training_data']['training_period_start'],\n",
    "            config['training_data']['training_period_end'],\n",
    "            id_column='coin_id'\n",
    "        )\n",
    "\n",
    "    # generate features from the metrics\n",
    "    value_column_features_df, value_column_tuple = fe.convert_coin_date_metrics_to_features(\n",
    "        value_column_metrics_df,\n",
    "        value_column_config,\n",
    "        dataset_metrics_config,\n",
    "        config,\n",
    "        modeling_config\n",
    "    )\n",
    "\n",
    "    logger.info('Generated features for %s.%s.%s',\n",
    "                dataset_category, dataset_name, value_column)\n",
    "\n",
    "    training_data_tuples.append(value_column_tuple)\n",
    "    training_data_dfs.append(value_column_features_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'market_cap' in market_data_df.columns:\n",
    "    print('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# dataset variables\n",
    "dataset_category = 'wallet_cohorts'\n",
    "\n",
    "\n",
    "for cohort_name in metrics_config[dataset_category]:\n",
    "\n",
    "    # load configs\n",
    "    dataset_metrics_config = metrics_config[dataset_category][cohort_name]\n",
    "    dataset_config = config['datasets'][dataset_category][cohort_name]\n",
    "    cohort_description = dataset_config['description']\n",
    "\n",
    "    # identify wallets in the cohort\n",
    "    cohort_summary_df = cwm.classify_wallet_cohort(profits_df, dataset_config)\n",
    "    cohort_wallets = cohort_summary_df[cohort_summary_df['in_cohort']==True]['wallet_address']\n",
    "\n",
    "    # If no cohort members were identified, continue\n",
    "    if len(cohort_wallets) == 0:\n",
    "        logger.info(\"No wallets identified as members of cohort '%s'\", cohort_name)\n",
    "        continue\n",
    "\n",
    "    # generate cohort buysell_metrics\n",
    "    cohort_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets)\n",
    "\n",
    "    # generate features from the metrics\n",
    "    dataset_features_df, dataset_tuple = fe.convert_coin_date_metrics_to_features(\n",
    "        cohort_metrics_df,\n",
    "        dataset_config,\n",
    "        dataset_metrics_config,\n",
    "        config,\n",
    "        modeling_config\n",
    "    )\n",
    "\n",
    "    logger.info('Generated features for %s.%s',\n",
    "                dataset_category, cohort_name)\n",
    "\n",
    "    training_data_tuples.append(dataset_tuple)\n",
    "    training_data_dfs.append(dataset_features_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "\n",
    "# merge training data\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "training_data_df, merge_logs_df = fe.create_training_data_df(modeling_folder, training_data_tuples)\n",
    "\n",
    "# create the target variable df\n",
    "target_variable_df,_ = fe.create_target_variables_mooncrater(filtered_market_data_df, config['training_data'], modeling_config)\n",
    "\n",
    "# merge the two into the final model input df\n",
    "model_input_df = fe.prepare_model_input_df(training_data_df, target_variable_df, modeling_config['modeling']['target_column'])\n",
    "\n",
    "# split the df into train and test sets\n",
    "X_train, X_test, y_train, y_test = m.split_model_input(\n",
    "    model_input_df,\n",
    "    modeling_config['modeling']['target_column'],\n",
    "    modeling_config['modeling']['train_test_split'],\n",
    "    modeling_config['modeling']['random_state']\n",
    ")\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "model, model_id = m.train_model(X_train, y_train, modeling_folder, modeling_config['modeling']['model_params'])\n",
    "\n",
    "# 3.5 Evaluate the model's performance on the test set\n",
    "metrics = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
    "\n",
    "# 3.6 Log the experiment results for this configuration\n",
    "m.log_trial_results(modeling_folder, model_id)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `model` is your trained model and `feature_names` is a list of your feature names\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X_train.columns  # Replace with the correct source of your feature names if different\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance (optional)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importance\n",
    "feature_importance_df.sort_values('importance',ascending=False)\n",
    "# feature_importance_df.sort_values('feature',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for testing\n",
    "sample_df = pd.DataFrame({\n",
    "    'date': [\n",
    "        pd.Timestamp('2024-01-01'),\n",
    "        pd.Timestamp('2024-01-02'),\n",
    "        pd.Timestamp('2024-01-03'),\n",
    "        pd.Timestamp('2024-01-01'),\n",
    "        pd.Timestamp('2024-01-02'),\n",
    "        pd.Timestamp('2024-01-03')\n",
    "        ],\n",
    "    'coin_id': [1, 1, 1, 2, 2, 2],\n",
    "    'buyers_new': [10, 20, 30, 40, 50, 60],\n",
    "    'sellers_new': [5, 10, 15, 20, 25, 30]\n",
    "})\n",
    "\n",
    "# Sample configuration for metrics\n",
    "df_metrics_config = {\n",
    "    'buyers_new': {\n",
    "        'aggregations': {\n",
    "            'sum': {'scaling': 'none'},\n",
    "            'mean': {'scaling': 'none'},\n",
    "            'max': {'scaling': 'none'},\n",
    "            'min': {'scaling': 'none'},\n",
    "            'median': {'scaling': 'none'},\n",
    "            'std': {'scaling': 'none'}\n",
    "        }\n",
    "    },\n",
    "    'sellers_new': {\n",
    "        'aggregations': {\n",
    "            'sum': {'scaling': 'none'},\n",
    "            'mean': {'scaling': 'none'},\n",
    "            'max': {'scaling': 'none'}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# demo\n",
    "training_period_end = '2024-01-03'\n",
    "\n",
    "# Test Case 1: Basic functionality with multiple coins\n",
    "result = fe.flatten_coin_date_df(sample_df, df_metrics_config, training_period_end)\n",
    "\n",
    "# Check that there are two coins in the output\n",
    "assert len(result['coin_id'].unique()) == 2\n",
    "assert sorted(result['coin_id'].unique()) == [1, 2]\n",
    "\n",
    "# Check that all expected columns exist for both coins\n",
    "expected_columns = [\n",
    "    'coin_id', 'buyers_new_sum', 'buyers_new_mean', 'buyers_new_max', 'buyers_new_min',\n",
    "    'buyers_new_median', 'buyers_new_std', 'sellers_new_sum', 'sellers_new_mean', 'sellers_new_max'\n",
    "]\n",
    "assert all(col in result.columns for col in expected_columns)\n",
    "\n",
    "# Test Case 2: One coin with missing metric data (buyers_new should raise ValueError)\n",
    "df_missing_metric = pd.DataFrame({\n",
    "    'date': [pd.Timestamp('2024-01-01'), pd.Timestamp('2024-01-02'), pd.Timestamp('2024-01-03')],\n",
    "    'coin_id': [1, 1, 1],\n",
    "    'sellers_new': [5, 10, 15]\n",
    "})\n",
    "\n",
    "# with pytest.raises(ValueError, match=\"Metric 'buyers_new' is missing from the input DataFrame.\"):\n",
    "df = fe.flatten_coin_date_df(df_missing_metric, df_metrics_config, training_period_end)\n",
    "df\n",
    "\n",
    "# # Test Case 3: Empty DataFrame (should raise ValueError)\n",
    "# df_empty = pd.DataFrame(columns=['coin_id', 'buyers_new', 'sellers_new'])\n",
    "# with pytest.raises(ValueError, match=\"Input DataFrame is empty\"):\n",
    "#     fe.flatten_coin_date_df(df_empty, df_metrics_config, training_period_end)\n",
    "\n",
    "# # Test Case 4: One coin in the dataset\n",
    "# df_one_coin = pd.DataFrame({\n",
    "#     'date': [pd.Timestamp('2024-01-01'), pd.Timestamp('2024-01-02'), pd.Timestamp('2024-01-03')],\n",
    "#     'coin_id': [1, 1, 1],\n",
    "#     'buyers_new': [10, 20, 30],\n",
    "#     'sellers_new': [5, 10, 15]\n",
    "# })\n",
    "# result_one_coin = fe.flatten_coin_date_df(df_one_coin, df_metrics_config, training_period_end)\n",
    "\n",
    "# # Check that the single coin is processed correctly and the columns are as expected\n",
    "# assert len(result_one_coin['coin_id'].unique()) == 1\n",
    "# assert 'buyers_new_sum' in result_one_coin.columns\n",
    "# assert result_one_coin['buyers_new_sum'].iloc[0] == 60  # Sum of buyers_new for coin 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, config in metrics_config.items():\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_config = metrics_config\n",
    "time_series_df =sample_coin_df\n",
    "\n",
    "flat_features = {}\n",
    "matched_columns = False\n",
    "\n",
    "# Apply global stats calculations for each metric\n",
    "for metric, config in df_metrics_config.items():\n",
    "    print(config)\n",
    "    if metric not in time_series_df.columns:\n",
    "        continue\n",
    "\n",
    "    matched_columns = True\n",
    "    ts = time_series_df[metric].copy()  # Get the time series for this metric\n",
    "\n",
    "    # Standard aggregations\n",
    "    if 'aggregations' in config:\n",
    "        print(config)\n",
    "        for agg, agg_config in config['aggregations'].items():\n",
    "            agg_value = calculate_stat(ts, agg)\n",
    "\n",
    "            # Generate bucket columns if buckets are specified in the config\n",
    "            if 'buckets' in agg_config:\n",
    "                bucket_category = bucketize_value(agg_value, agg_config['buckets'])\n",
    "                flat_features[f'{metric}_{agg}_bucket'] = bucket_category\n",
    "\n",
    "            # Return the aggregate metric if it is not bucketized\n",
    "            else:\n",
    "                flat_features[f'{metric}_{agg}'] = agg_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['aggregations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_config_real = load_config('../config/metrics_config.yaml')\n",
    "metrics_config_real['time_series']['market_data']['volume']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
