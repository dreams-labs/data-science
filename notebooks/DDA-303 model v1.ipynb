{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingModuleSource=false\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "import progressbar\n",
    "\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# import local files if necessary\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df, create_progress_bar\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "import utils as u\n",
    "importlib.reload(u)\n",
    "\n",
    "# load configs\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "# retreive market data\n",
    "market_data_df = td.retrieve_market_data()\n",
    "market_data_df,_ = td.fill_market_data_gaps(market_data_df,config['data_cleaning']['max_gap_days'])\n",
    "\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, market_data_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "# initial steps for this model\n",
    "filtered_market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n",
    "\n",
    "training_data_tuples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "training_data_tuples = []\n",
    "\n",
    "# dataset variables\n",
    "dataset_category = 'time_series'\n",
    "dataset_name = 'market_data'\n",
    "dataset_df = filtered_market_data_df.copy()\n",
    "\n",
    "# declare dataset configs based on variables\n",
    "dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "dataset_metrics_config = metrics_config[dataset_category][dataset_name]\n",
    "\n",
    "# calculate metrics for each value column\n",
    "# for value_column in list(dataset_metrics_config.keys()):\n",
    "for value_column in list(dataset_metrics_config.keys()):\n",
    "\n",
    "\n",
    "    print(value_column)\n",
    "\n",
    "    # a value_column-specific df will be used for feature generation\n",
    "    value_column_config = config['datasets'][dataset_category][dataset_name][value_column]\n",
    "    value_column_metrics_config = metrics_config[dataset_category][dataset_name][value_column]\n",
    "    value_column_df = dataset_df[['date','coin_id',value_column]].copy()\n",
    "\n",
    "    # check if there are any time series metrics to add, e.g. sma, ema, etc\n",
    "    if 'metrics' in value_column_metrics_config:\n",
    "\n",
    "        # calculate and merge all metrics in the config\n",
    "        all_metrics = []\n",
    "\n",
    "        # generate metrics\n",
    "        metric_df, _ = cwm.generate_time_series_metrics(\n",
    "            metric_df,\n",
    "            config,\n",
    "            value_column_metrics_config['metrics'],\n",
    "            value_column,\n",
    "            id_column='coin_id'\n",
    "        )\n",
    "\n",
    "        all_metrics.append(metric_df)\n",
    "\n",
    "        # join all generated metrics for the value_column together\n",
    "        value_column_metrics_df = all_metrics[0]\n",
    "        for metrics_df in all_metrics[1:]:\n",
    "            value_column_metrics_df = pd.merge(value_column_metrics_df, metrics_df, on='date', how='outer')\n",
    "\n",
    "    else:\n",
    "        # if no additional metrics are needed, pass through coins in the original df that have values for all dates\n",
    "        value_column_metrics_df, _, _ = cwm.split_dataframe_by_coverage(\n",
    "            value_column_df,\n",
    "            config['training_data']['training_period_start'],\n",
    "            config['training_data']['training_period_end'],\n",
    "            id_column='coin_id'\n",
    "        )\n",
    "\n",
    "    # generate features from the metrics\n",
    "    value_column_features_df, value_column_tuple = fe.convert_to_features(\n",
    "        value_column_metrics_df,\n",
    "        value_column_config,\n",
    "        dataset_metrics_config,\n",
    "        config,\n",
    "        modeling_config\n",
    "    )\n",
    "\n",
    "    logger.info('Generated features for %s.%s.%s',\n",
    "                dataset_category, dataset_name, value_column)\n",
    "\n",
    "    training_data_tuples.append(value_column_tuple)\n",
    "\n",
    "training_data_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_category = 'wallet_cohorts'\n",
    "cohort_tuples = []\n",
    "\n",
    "for cohort_name in metrics_config[dataset_category]:\n",
    "\n",
    "    # load configs\n",
    "    dataset_metrics_config = metrics_config[dataset_category][cohort_name]\n",
    "    dataset_config = config['datasets'][dataset_category][cohort_name]\n",
    "    cohort_description = dataset_config['description']\n",
    "\n",
    "    # identify wallets in the cohort\n",
    "    cohort_summary_df = cwm.classify_wallet_cohort(profits_df, dataset_config)\n",
    "    cohort_wallets = cohort_summary_df[cohort_summary_df['in_cohort']==True]['wallet_address']\n",
    "\n",
    "    # generate cohort buysell_metrics\n",
    "    cohort_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets)\n",
    "\n",
    "    # generate features from the metrics\n",
    "    dataset_features_df, dataset_tuple = fe.convert_to_features(\n",
    "        cohort_metrics_df,\n",
    "        dataset_config,\n",
    "        dataset_metrics_config,\n",
    "        config,\n",
    "        modeling_config\n",
    "    )\n",
    "\n",
    "    logger.info('Generated features for %s.%s',\n",
    "                dataset_category, cohort_name)\n",
    "\n",
    "    training_data_tuples.append(dataset_tuple)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge training data\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "training_data_df, merge_logs_df = fe.create_training_data_df(modeling_folder, training_data_tuples)\n",
    "\n",
    "# create the target variable df\n",
    "target_variable_df,_ = fe.create_target_variables_mooncrater(filtered_market_data_df, config['training_data'], modeling_config)\n",
    "\n",
    "# merge the two into the final model input df\n",
    "model_input_df = fe.prepare_model_input_df(training_data_df, target_variable_df, modeling_config['modeling']['target_column'])\n",
    "\n",
    "# split the df into train and test sets\n",
    "X_train, X_test, y_train, y_test = m.split_model_input(\n",
    "    model_input_df,\n",
    "    modeling_config['modeling']['target_column'],\n",
    "    modeling_config['modeling']['train_test_split'],\n",
    "    modeling_config['modeling']['random_state']\n",
    ")\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "model, model_id = m.train_model(X_train, y_train, modeling_folder, modeling_config['modeling']['model_params'])\n",
    "\n",
    "# 3.5 Evaluate the model's performance on the test set\n",
    "metrics = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
    "\n",
    "# 3.6 Log the experiment results for this configuration\n",
    "m.log_trial_results(modeling_folder, model_id)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test fixes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_preprocessed_output(dataset_category, dataset_name, config, metrics_config, modeling_config):\n",
    "    # Load configs\n",
    "    dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "    dataset_metrics_config = metrics_config.get(dataset_category, {}).get(dataset_name, None)\n",
    "\n",
    "    # Generate features/metrics based on dataset_category\n",
    "    if dataset_category == 'coin_facts':\n",
    "        df = td.retrieve_metadata_data()\n",
    "        features_df = td.generate_coin_metadata_features(df, config)\n",
    "    elif dataset_category == 'time_series':\n",
    "        df = td.get_time_series_data()  # Assuming a function that retrieves the appropriate time series\n",
    "        features_df, _ = cwm.generate_time_series_metrics(df, config, metrics_config, dataset_key=dataset_name, value_column=dataset_config['value_column'])\n",
    "    elif dataset_category == 'wallet_cohorts':\n",
    "        cohort_summary_df = cwm.classify_wallet_cohort(profits_df, dataset_config)\n",
    "        cohort_wallets = cohort_summary_df[cohort_summary_df['in_cohort']==True]['wallet_address']\n",
    "        df = profits_df  # Or other relevant DataFrame\n",
    "        features_df = cwm.generate_buysell_metrics_df(df, config['training_data']['training_period_end'], cohort_wallets)\n",
    "\n",
    "    # Flatten, save, and preprocess the DataFrame\n",
    "    flattened_output_directory = os.path.join(modeling_config['modeling']['modeling_folder'], 'outputs/flattened_outputs')\n",
    "    flattened_df, flattened_filepath = fe.save_flattened_outputs(features_df, flattened_output_directory, dataset_config['description'], config['training_data']['modeling_period_start'])\n",
    "    preprocessed_df, preprocessed_filepath = fe.preprocess_coin_df(flattened_filepath, modeling_config, dataset_config, dataset_metrics_config)\n",
    "\n",
    "    return preprocessed_df, preprocessed_filepath\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_category = 'wallet_cohorts'\n",
    "dataset_name = 'sharks'\n",
    "\n",
    "preprocessed_df, preprocessed_filepath = generate_preprocessed_output(dataset_category, dataset_name, config, metrics_config, modeling_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
