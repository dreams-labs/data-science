{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['ALERT_SOUND_FILEPATH']=\"../../../Local/assets/sounds/mixkit-alert-bells-echo-765.wav\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_orchestrator as wo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_modeling.wallet_modeling as wm\n",
    "import wallet_modeling.model_reporting as wmr\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.wallet_features as wf\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.wallet_model_evaluation as wime\n",
    "import wallet_insights.validation_analysis as wiv\n",
    "import wallet_insights.coin_forecasting as wicf\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp,\n",
    "           wo, wtd, wm, wmr, wmc, wmt, wtf, wts, wf, wime, wiv, wicf]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "wallets_config = WalletsConfig.load_from_yaml('../config/wallets_config.yaml')\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training Data Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve datasets\n",
    "profits_df,market_data_df = wo.retrieve_datasets()\n",
    "\n",
    "# Define wallet cohort after cleaning\n",
    "training_wallet_metrics_df,wallet_cohort = wo.define_wallet_cohort(profits_df,market_data_df)\n",
    "\n",
    "# Generate profits_df for all training windows and the modeling period\n",
    "training_profits_df, training_windows_profits_dfs, modeling_profits_df, validation_profits_df = wo.split_profits_df(profits_df,\n",
    "                                                                               market_data_df,wallet_cohort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Market data: add indicators\n",
    "market_indicators_data_df = ind.generate_time_series_indicators(market_data_df,\n",
    "                                                        wallets_metrics_config['time_series']['market_data'],\n",
    "                                                        'coin_id')\n",
    "\n",
    "\n",
    "# Transfers data retrieval for the wallet_ids in temp.wallet_modeling_cohort\n",
    "transfers_sequencing_df = wts.retrieve_transfers_sequencing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate features for the full training dataset\n",
    "training_wallet_features_df = wf.calculate_wallet_features(training_profits_df, market_indicators_data_df,\n",
    "                                                           transfers_sequencing_df, wallet_cohort)\n",
    "\n",
    "# Define the full feature set by appending a suffix for each window\n",
    "training_data_df = training_wallet_features_df.add_suffix(\"_all_windows\")\n",
    "\n",
    "# Generate features for each window\n",
    "for i, window_profits_df in enumerate(training_windows_profits_dfs, 1):\n",
    "    # Generate the features\n",
    "    window_wallet_features_df = wf.calculate_wallet_features(window_profits_df, market_indicators_data_df,\n",
    "                                                             transfers_sequencing_df, wallet_cohort)\n",
    "\n",
    "    # Add column suffix and join to training_data_df\n",
    "    window_wallet_features_df = window_wallet_features_df.add_suffix(f'_w{i}')\n",
    "    training_data_df = training_data_df.join(window_wallet_features_df, how='left')\n",
    "\n",
    "\n",
    "training_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join target variable to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Clean inactive wallets from modeling period data\n",
    "modeling_wallets_df = wo.filter_modeling_period_wallets(modeling_profits_df)\n",
    "\n",
    "# Generate target variables\n",
    "target_vars_df = wm.generate_target_variables(modeling_wallets_df)\n",
    "\n",
    "# Merge training data and target variables?\n",
    "modeling_df = training_data_df.join(target_vars_df[wallets_config['modeling']['target_variable']],\n",
    "                                    how='inner')\n",
    "\n",
    "modeling_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDA-409 Codespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "transfers_df = wts.retrieve_transfers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers_df_full = transfers_df.reset_index().copy()\n",
    "print(transfers_df_full.shape)\n",
    "transfers_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_dates = wtd.generate_imputation_dates()\n",
    "\n",
    "training_end = wallets_config['training_data']['training_period_end']\n",
    "training_dates = [date for date in imputation_dates\n",
    "                    if datetime.strptime(date, '%Y-%m-%d') <= datetime.strptime(training_end, '%Y-%m-%d')]\n",
    "\n",
    "\n",
    "training_dates\n",
    "training_dates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dates\n",
    "target_date = training_dates[0]\n",
    "target_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers_df = transfers_df_full.copy().round().replace(-0,0)\n",
    "transfers_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = training_dates[0]\n",
    "transfers_df = transfers_df_full.copy().round().replace(-0,0)\n",
    "\n",
    "\n",
    "# Convert dates and set a multi-index\n",
    "target_date = pd.to_datetime(target_date)\n",
    "transfers_df['date'] = pd.to_datetime(transfers_df['date'])\n",
    "transfers_df = transfers_df.set_index(['coin_id', 'wallet_address', 'date']).sort_index()\n",
    "\n",
    "# 1. Split into before/including target_date and after\n",
    "df_before = transfers_df.xs(slice(None, target_date), level='date', drop_level=False)\n",
    "\n",
    "# # 2. Identify pairs needing new rows\n",
    "# pairs_with_target = df_before.index[df_before.index.get_level_values('date') == target_date].droplevel('date')\n",
    "# all_pairs_before = df_before.index.droplevel('date').drop_duplicates()\n",
    "# pairs_need_impute = all_pairs_before.difference(pairs_with_target)\n",
    "# if len(pairs_need_impute) == 0:\n",
    "#     # No new rows needed\n",
    "#     return pd.DataFrame(columns=transfers_df.reset_index().columns)\n",
    "\n",
    "# df_before = df_before[df_before.index.droplevel('date').isin(pairs_need_impute)]\n",
    "\n",
    "# # 3. Find the last date for each pair before target_date\n",
    "# shifted_index = df_before.index.to_frame().shift(-1)\n",
    "# is_last_date = (\n",
    "#     (df_before.index.get_level_values('coin_id') != shifted_index['coin_id']) |\n",
    "#     (df_before.index.get_level_values('wallet_address') != shifted_index['wallet_address'])\n",
    "# )\n",
    "# df_last_dates = df_before[is_last_date]\n",
    "\n",
    "# # 4. Create new rows for the target_date\n",
    "# new_rows = df_last_dates.index.to_frame()\n",
    "# new_rows['date'] = target_date\n",
    "# new_rows = new_rows.set_index(['coin_id', 'wallet_address', 'date'])\n",
    "# new_rows['net_transfers'] = 0\n",
    "# new_rows['balance'] = df_last_dates['balance']\n",
    "\n",
    "df_before.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_transfers_rows_for_date(transfers_df, target_date):\n",
    "    \"\"\"\n",
    "    Impute rows for all coin-wallet pairs in transfers_df on the target date.\n",
    "\n",
    "    This function:\n",
    "    1. Splits transfers_df into records before/including the target date and after\n",
    "    2. Identifies pairs that need new rows on the target date\n",
    "    3. Finds the last known date for each such pair\n",
    "    4. Creates new rows at the target date with net_transfers=0 and forward-filled balance\n",
    "    5. Returns only these newly created rows\n",
    "\n",
    "    Args:\n",
    "        transfers_df (pd.DataFrame): DataFrame containing transfer information\n",
    "        target_date (str or datetime): The date for which to impute rows\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of newly imputed rows\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert dates and set a multi-index\n",
    "    target_date = pd.to_datetime(target_date)\n",
    "    transfers_df['date'] = pd.to_datetime(transfers_df['date'])\n",
    "    transfers_df = transfers_df.set_index(['coin_id', 'wallet_address', 'date']).sort_index()\n",
    "\n",
    "    # 1. Split into before/including target_date and after\n",
    "    df_after = transfers_df.xs(slice(target_date + pd.Timedelta('1 day'), None), level='date', drop_level=False)\n",
    "    df_before = transfers_df.xs(slice(None, target_date), level='date', drop_level=False)\n",
    "\n",
    "    # 2. Identify pairs needing new rows\n",
    "    pairs_with_target = df_before.index[df_before.index.get_level_values('date') == target_date].droplevel('date')\n",
    "    all_pairs_before = df_before.index.droplevel('date').drop_duplicates()\n",
    "    pairs_need_impute = all_pairs_before.difference(pairs_with_target)\n",
    "    if len(pairs_need_impute) == 0:\n",
    "        # No new rows needed\n",
    "        return pd.DataFrame(columns=transfers_df.reset_index().columns)\n",
    "\n",
    "    df_before = df_before[df_before.index.droplevel('date').isin(pairs_need_impute)]\n",
    "\n",
    "    # 3. Find the last date for each pair before target_date\n",
    "    shifted_index = df_before.index.to_frame().shift(-1)\n",
    "    is_last_date = (\n",
    "        (df_before.index.get_level_values('coin_id') != shifted_index['coin_id']) |\n",
    "        (df_before.index.get_level_values('wallet_address') != shifted_index['wallet_address'])\n",
    "    )\n",
    "    df_last_dates = df_before[is_last_date]\n",
    "\n",
    "    # 4. Create new rows for the target_date\n",
    "    new_rows = df_last_dates.index.to_frame()\n",
    "    new_rows['date'] = target_date\n",
    "    new_rows = new_rows.set_index(['coin_id', 'wallet_address', 'date'])\n",
    "    new_rows['net_transfers'] = 0\n",
    "    new_rows['balance'] = df_last_dates['balance']\n",
    "\n",
    "    # 5. Return only the newly imputed rows\n",
    "    return new_rows.reset_index()\n",
    "\n",
    "\n",
    "def impute_transfers_for_all_dates(transfers_df, training_dates):\n",
    "    \"\"\"\n",
    "    Impute rows for all coin-wallet pairs in transfers_df on each date in training_dates.\n",
    "\n",
    "    This function:\n",
    "    1. Sorts training_dates and iterates through them\n",
    "    2. For each date, calls impute_transfers_rows_for_date to generate new rows\n",
    "    3. Appends these new rows to transfers_df\n",
    "    4. Returns the updated transfers_df with all imputed rows\n",
    "\n",
    "    Args:\n",
    "        transfers_df (pd.DataFrame): DataFrame containing transfer information\n",
    "        training_dates (list of str or datetime): Dates for which to impute rows\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with imputed rows for all given dates\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure training_dates are sorted\n",
    "    training_dates = sorted(pd.to_datetime(training_dates))\n",
    "\n",
    "    # Iterate through each date and impute rows\n",
    "    for dt in training_dates:\n",
    "        new_rows = impute_transfers_rows_for_date(transfers_df, dt)\n",
    "        if not new_rows.empty:\n",
    "            # Append new_rows to the original DataFrame\n",
    "            transfers_df = pd.concat([transfers_df, new_rows], ignore_index=True, sort=False)\n",
    "\n",
    "    return transfers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = training_dates[0]\n",
    "\n",
    "result = impute_transfers_rows_for_date(transfers_df_full.copy(), target_date)\n",
    "result.shape\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = impute_transfers_for_all_dates(transfers_df_full.copy(), training_dates)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'coin_id': ['BTC'] * 7,\n",
    "    'wallet_address': ['wallet1'] * 7,\n",
    "    'date': ['2024-01-01', '2024-01-05', '2024-01-10', '2024-01-15', '2024-01-20', '2024-01-29', '2024-01-30'],\n",
    "    'net_transfers': [100, -50, 75, -25, 0, 0, -100]  # Buy, sell, buy, sell\n",
    "})\n",
    "df['balance'] = df['net_transfers'].cumsum()\n",
    "df_base = df\n",
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wts.calculate_average_holding_period(df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "df = pd.DataFrame({\n",
    "    'coin_id': ['BTC'] * 7,\n",
    "    'wallet_address': ['wallet1'] * 7,\n",
    "    'date': ['2024-01-01', '2024-01-05', '2024-01-10', '2024-01-15', '2024-01-20', '2024-01-29', '2024-01-30'],\n",
    "    'net_transfers': [100, -50, 75, -25, 0, 0, -100]  # Buy, sell, buy, sell\n",
    "})\n",
    "df['balance'] = df['net_transfers'].cumsum()\n",
    "df_base = df\n",
    "\n",
    "# result = wts.calculate_days_since_last_buy(df)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_base.copy()\n",
    "days_since_buy_df = wts.calculate_days_since_last_buy(df)\n",
    "days_since_buy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_base.copy()\n",
    "avg_hold_df = wts.calculate_average_holding_period(df)\n",
    "avg_hold_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Train the model and get results\n",
    "model_results = wm.train_xgb_model(modeling_df)\n",
    "\n",
    "# Get the model object for evaluation\n",
    "model = model_results['pipeline'].named_steps['regressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model artifacts\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, evaluator, wallet_scores_df, coin_validation_df = wmr.generate_and_save_model_artifacts(\n",
    "    model_results=model_results,\n",
    "    validation_profits_df=validation_profits_df,\n",
    "    base_path='../wallet_modeling'\n",
    ")\n",
    "u.play_notification()\n",
    "\n",
    "# # Print results\n",
    "# print(evaluator['summary_report'])\n",
    "# print(f\"R² Score: {evaluation['r2']:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "evaluator = wime.RegressionEvaluator(\n",
    "    y_true=model_results['y_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    model=model,\n",
    "    feature_names=model_results['X'].columns.tolist()\n",
    ")\n",
    "\n",
    "evaluator.get_summary_report()\n",
    "evaluator.plot_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation period assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wallet_performance_df, bucketed_performance_df = wiv.calculate_validation_metrics(\n",
    "    X_test=model_results['X_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    validation_profits_df=validation_profits_df,\n",
    ")\n",
    "\n",
    "bucketed_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coin performance predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create coin_validation_df with metrics and returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Consolidate wallet scores at the coin level\n",
    "wallet_scores_df = pd.DataFrame({'score': model_results['y_pred']}, index=model_results['y_test'].index)\n",
    "coin_wallet_metrics_df = wicf.calculate_coin_metrics_from_wallet_scores(validation_profits_df, wallet_scores_df)\n",
    "\n",
    "# Calculate coin performance during the validation period\n",
    "coin_performance_df = wicf.calculate_coin_performance(market_data_df,\n",
    "                                                     wallets_config['training_data']['validation_period_start'],\n",
    "                                                     wallets_config['training_data']['validation_period_end'])\n",
    "\n",
    "# Join aggregated wallet metrics with actual coin performance\n",
    "coin_validation_df = coin_wallet_metrics_df.join(coin_performance_df, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = wicf.analyze_market_cap_segments(\n",
    "    coin_validation_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "wicf.plot_segment_heatmap(summary_df)\n",
    "# wicf.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_forecasting']['top_n']\n",
    "max_market_cap = wallets_config['coin_forecasting']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_forecasting']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = wicf.validate_coin_performance(coin_validation_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare performance of high vs low score coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wicf.print_performance_analysis(coin_validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "def analyze_coin_metrics(df):\n",
    "    \"\"\"\n",
    "    Analyze relationships between coin metrics and returns\n",
    "    \"\"\"\n",
    "    # Calculate correlations with coin_return\n",
    "    metrics_of_interest = [\n",
    "        'weighted_avg_score',\n",
    "        'composite_score',\n",
    "        'score_confidence',\n",
    "        'top_wallet_balance_pct',\n",
    "        'top_wallet_count_pct',\n",
    "        'total_wallets',\n",
    "        'avg_wallet_balance',\n",
    "        'market_cap'\n",
    "    ]\n",
    "\n",
    "    # Calculate correlations\n",
    "    correlations = {}\n",
    "    for metric in metrics_of_interest:\n",
    "        correlation = df[metric].corr(df['coin_return'])\n",
    "        correlations[metric] = correlation\n",
    "\n",
    "    # Sort correlations by absolute value\n",
    "    correlations_sorted = {k: v for k, v in sorted(correlations.items(),\n",
    "                                                 key=lambda x: abs(x[1]),\n",
    "                                                 reverse=True)}\n",
    "\n",
    "    # Calculate basic statistics for coins with positive vs negative returns\n",
    "    positive_returns = df[df['coin_return'] > 0]\n",
    "    negative_returns = df[df['coin_return'] <= 0]\n",
    "\n",
    "    comparison_stats = {}\n",
    "    for metric in metrics_of_interest:\n",
    "        pos_mean = positive_returns[metric].mean()\n",
    "        neg_mean = negative_returns[metric].mean()\n",
    "        # Perform t-test\n",
    "        t_stat, p_value = stats.ttest_ind(positive_returns[metric],\n",
    "                                        negative_returns[metric])\n",
    "\n",
    "        comparison_stats[metric] = {\n",
    "            'positive_mean': pos_mean,\n",
    "            'negative_mean': neg_mean,\n",
    "            'difference': pos_mean - neg_mean,\n",
    "            'p_value': p_value\n",
    "        }\n",
    "\n",
    "    # Identify potential success indicators\n",
    "    success_indicators = {\n",
    "        metric: stats for metric, stats in comparison_stats.items()\n",
    "        if (abs(stats['difference']) > 0.1 * stats['negative_mean'] and\n",
    "            stats['p_value'] < 0.05)\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'correlations': correlations_sorted,\n",
    "        'comparison_stats': comparison_stats,\n",
    "        'success_indicators': success_indicators\n",
    "    }\n",
    "\n",
    "# Create summary statistics\n",
    "def print_analysis_results(results):\n",
    "    \"\"\"\n",
    "    Print formatted analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Correlation Analysis ===\")\n",
    "    print(\"\\nCorrelations with coin return (sorted by strength):\")\n",
    "    for metric, corr in results['correlations'].items():\n",
    "        print(f\"{metric:25} : {corr:0.4f}\")\n",
    "\n",
    "    print(\"\\n=== Positive vs Negative Returns Analysis ===\")\n",
    "    print(\"\\nMetrics comparison for positive vs negative returns:\")\n",
    "    for metric, stats in results['comparison_stats'].items():\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Positive returns mean: {stats['positive_mean']:0.4f}\")\n",
    "        print(f\"  Negative returns mean: {stats['negative_mean']:0.4f}\")\n",
    "        print(f\"  Difference: {stats['difference']:0.4f}\")\n",
    "        print(f\"  P-value: {stats['p_value']:0.4f}\")\n",
    "\n",
    "    print(\"\\n=== Strong Success Indicators ===\")\n",
    "    print(\"\\nMetrics showing significant difference between positive and negative returns:\")\n",
    "    for metric, stats in results['success_indicators'].items():\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Mean difference: {stats['difference']:0.4f}\")\n",
    "        print(f\"  P-value: {stats['p_value']:0.4f}\")\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "def main():\n",
    "    # Read the data\n",
    "    df = pd.read_csv('coin_wallet_metrics.csv')\n",
    "\n",
    "    # Run analysis\n",
    "    results = analyze_coin_metrics(df)\n",
    "\n",
    "    # Print results\n",
    "    print_analysis_results(results)\n",
    "\n",
    "    # Create visualizations\n",
    "    create_visualizations(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorize the returns (apply caps to the top n % of values)\n",
    "returns_winsorized = u.winsorize(returns, winsorization_cutoff)\n",
    "\n",
    "# Merge datasets\n",
    "df = pd.DataFrame({\n",
    "    'predictions': predictions,\n",
    "    'returns': returns_winsorized,\n",
    "})\n",
    "\n",
    "# Sort by actual returns to obtain optimal performance\n",
    "df_sorted = df.sort_values('returns', ascending=False)\n",
    "cumulative_best_returns = np.cumsum(df_sorted['returns'])\n",
    "cumulative_best_avg_returns = df_sorted['returns'].expanding().mean()\n",
    "\n",
    "# Sort by model score to obtain modeled performance\n",
    "df_sorted = df.sort_values('predictions', ascending=False)\n",
    "cumulative_model_returns = np.cumsum(df_sorted['returns'])\n",
    "cumulative_model_avg_returns = df_sorted['returns'].expanding().mean()\n",
    "\n",
    "# Calculate average return across all data\n",
    "average_return = np.mean(returns_winsorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_model_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_forecasting']['top_n']\n",
    "max_market_cap = wallets_config['coin_forecasting']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_forecasting']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = wicf.validate_coin_performance(coin_validation_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# List the coins that would have been picked at the start of the validation period\n",
    "top_coins_df = coin_validation_df[\n",
    "    (coin_validation_df['market_cap_filled']<=max_market_cap)\n",
    "    & (coin_validation_df['market_cap_filled']>=min_market_cap)\n",
    "].copy()\n",
    "\n",
    "sort_column = wallets_config['coin_forecasting']['sort_method']\n",
    "\n",
    "top_coins_df.sort_values(sort_column,ascending=False).head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'coin_id': ['BTC', 'BTC', 'ETH', 'ETH', 'BTC', 'BTC', 'BTC', 'BTC'],\n",
    "    'wallet_address': [\n",
    "        'wallet1', 'wallet2', 'wallet1', 'wallet1',\n",
    "        'wallet2', 'wallet1', 'wallet2', 'wallet1'\n",
    "    ],\n",
    "    'date': [\n",
    "        '2024-01-01', '2024-01-01', '2024-01-02', '2024-01-05',\n",
    "        '2024-01-05', '2024-01-06', '2024-01-07', '2024-01-10'\n",
    "    ],\n",
    "    'net_transfers': [100, 50, 200, -100, 50, -50, -50, 50]\n",
    "})\n",
    "\n",
    "expected = np.array([0, 0, 0, 3, 2, 5, 4, 4.5])\n",
    "df2 = df.sort_values(by=['coin_id','wallet_address','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers_df_full.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = wts.calculate_average_holding_period(df2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
