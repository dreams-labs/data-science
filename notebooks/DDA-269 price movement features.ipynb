{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "import progressbar\n",
    "\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# import local files if necessary\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df, create_progress_bar\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "import utils as u\n",
    "importlib.reload(u)\n",
    "\n",
    "# load configs\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data (profits_df) Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "\n",
    "\n",
    "# retrieve and clean prices data\n",
    "prices_df = td.retrieve_prices_data()\n",
    "prices_df,prices_log = td.fill_prices_gaps(prices_df,config['data_cleaning']['max_gap_days'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "\n",
    "\n",
    "# # retrieve transfers data\n",
    "# transfers_df = td.retrieve_transfers_data(\n",
    "#     config['training_data']['training_period_start'],\n",
    "#     config['training_data']['modeling_period_start'],\n",
    "#     config['training_data']['modeling_period_end']\n",
    "#     )\n",
    "\n",
    "# # compile profits_df\n",
    "# profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "# profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "# profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n",
    "\n",
    "# # cohort configurations\n",
    "# cohort_name = list(config['wallet_cohorts'].keys())[0]\n",
    "# metric_description = f\"{cohort_name}_cohort\"\n",
    "# cohort_metrics_config = metrics_config['wallet_cohorts'][cohort_name]\n",
    "\n",
    "# # identify wallets in the cohort\n",
    "# cohort_summary_df = td.classify_wallet_cohort(profits_df, config['wallet_cohorts'][cohort_name])\n",
    "# cohort_wallets = cohort_summary_df[cohort_summary_df['in_cohort']==True]['wallet_address']\n",
    "\n",
    "# # generate and flatten buysell_metrics\n",
    "# buysell_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets)\n",
    "\n",
    "# # flatten, save, and preprocess the flattened df\n",
    "# flattened_output_directory = os.path.join(modeling_config['modeling']['modeling_folder'],'outputs/flattened_outputs')\n",
    "\n",
    "# flattened_buysell_metrics_df = fe.flatten_coin_date_df(\n",
    "#     buysell_metrics_df,\n",
    "#     cohort_metrics_config,\n",
    "#     config['training_data']['training_period_end']\n",
    ")\n",
    "# flattened_df, flattened_filepath = fe.save_flattened_outputs(\n",
    "#     flattened_buysell_metrics_df,\n",
    "#     flattened_output_directory,\n",
    "#     metric_description,\n",
    "#     config['training_data']['modeling_period_start']\n",
    "#     )\n",
    "# preprocessed_df, preprocessed_filepath = fe.preprocess_coin_df(flattened_filepath, modeling_config, cohort_metrics_config)\n",
    "\n",
    "# # create the training data df\n",
    "# input_directory = f\"{preprocessed_filepath.split('preprocessed_outputs/')[0]}preprocessed_outputs/\"\n",
    "# input_filenames = [\n",
    "#     preprocessed_filepath.split('preprocessed_outputs/')[1]\n",
    "# ]\n",
    "# training_data_df = fe.create_training_data_df(input_directory, input_filenames)\n",
    "\n",
    "# # create the target variable df\n",
    "# target_variable_df,_ = fe.create_target_variables_mooncrater(prices_df, config['training_data'], modeling_config)\n",
    "\n",
    "# # merge the two into the final model input df\n",
    "# model_input_df = fe.prepare_model_input_df(training_data_df, target_variable_df, modeling_config['modeling']['target_column'])\n",
    "\n",
    "# # split the df into train and test sets\n",
    "# X_train, X_test, y_train, y_test = m.split_model_input(\n",
    "#     model_input_df,\n",
    "#     modeling_config['modeling']['target_column'],\n",
    "#     modeling_config['modeling']['train_test_split'],\n",
    "#     modeling_config['modeling']['random_state']\n",
    "# )\n",
    "\n",
    "# # 3.4 Train the model using the current configuration and log the results\n",
    "# modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "# model, model_id = m.train_model(X_train, y_train, modeling_folder, modeling_config['modeling']['model_params'])\n",
    "\n",
    "# # 3.5 Evaluate the model's performance on the test set\n",
    "# metrics = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
    "\n",
    "# # 3.6 Log the experiment results for this configuration\n",
    "# m.log_trial_results(modeling_folder, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_time_series_df():\n",
    "    \"\"\"Fixture that provides a sample DataFrame for the time series with multiple coin_ids.\"\"\"\n",
    "    data = {\n",
    "        'coin_id': [1, 1, 1, 2, 2, 2],\n",
    "        'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-01', '2023-01-02', '2023-01-03'],\n",
    "        'price': [100, 110, 120, 200, 210, 220]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def sample_metrics_config():\n",
    "    \"\"\"Fixture that provides a sample metrics configuration for time series analysis.\"\"\"\n",
    "    return {\n",
    "        'time_series': {\n",
    "            'prices': {\n",
    "                'sma': {\n",
    "                    'parameters': {\n",
    "                        'period': 2\n",
    "                    }\n",
    "                },\n",
    "                'ema': {\n",
    "                    'parameters': {\n",
    "                        'period': 2\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "sample_time_series_df = sample_time_series_df()\n",
    "sample_metrics_config = sample_metrics_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'price' in prices_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @pytest.mark.unit\n",
    "# def test_generate_time_series_metrics_different_periods(sample_time_series_df):\n",
    "\"\"\"\n",
    "Test the functionality of generate_time_series_metrics with different periods for SMA and EMA.\n",
    "\"\"\"\n",
    "# Adjust the sample_metrics_config for different periods\n",
    "sample_metrics_config = {\n",
    "    'time_series': {\n",
    "        'prices': {\n",
    "            'sma': {\n",
    "                'parameters': {\n",
    "                    'period': 3  # Different period for SMA\n",
    "                }\n",
    "            },\n",
    "            'ema': {\n",
    "                'parameters': {\n",
    "                    'period': 2  # Different period for EMA\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the date to datetime in the sample data\n",
    "sample_time_series_df['date'] = pd.to_datetime(sample_time_series_df['date'])\n",
    "\n",
    "# Run the generate_time_series_metrics function\n",
    "result_df = cwm.generate_time_series_metrics(\n",
    "    time_series_df=sample_time_series_df,\n",
    "    metrics_config=sample_metrics_config,\n",
    "    dataset_key='prices',\n",
    "    colname='price'\n",
    ")\n",
    "\n",
    "# Expected columns in the result\n",
    "expected_columns = ['coin_id', 'date', 'price', 'prices_sma_3', 'prices_ema_2']\n",
    "\n",
    "# Assert that the columns exist in the result\n",
    "assert all(col in result_df.columns for col in expected_columns), \"Missing expected columns in the result.\"\n",
    "\n",
    "# Expected SMA and EMA values for coin_id=1\n",
    "expected_sma_1 = [float('nan'), float('nan'), 110.0]  # SMA for coin_id=1 with period=3\n",
    "expected_ema_1 = [100.0, 106.666667, 115.555556]  # EMA for coin_id=1 with period=2\n",
    "\n",
    "# Confirm that the SMA result matches the expected, with special logic to handle NaNs\n",
    "for i, (expected, actual) in enumerate(zip(\n",
    "    expected_sma_1,\n",
    "    result_df[result_df['coin_id'] == 1]['prices_sma_3'].tolist()\n",
    ")):\n",
    "    if np.isnan(expected) and np.isnan(actual):\n",
    "        continue  # Both values are NaN, so this is considered equal\n",
    "    assert expected == actual, f\"Mismatch at index {i}: expected {expected}, got {actual}\"\n",
    "\n",
    "# Confirm that the EMA result matches the expected\n",
    "assert result_df[result_df['coin_id'] == 1]['prices_ema_2'].tolist() == pytest.approx(\n",
    "    expected_ema_1,\n",
    "    abs=1e-2\n",
    "), \"EMA calculation incorrect for coin_id=1\"\n",
    "\n",
    "# Expected SMA and EMA values for coin_id=2\n",
    "expected_sma_2 = [float('nan'), float('nan'), 210.0]  # SMA for coin_id=2 with period=3\n",
    "expected_ema_2 = [200.0, 206.666667, 215.555556]  # EMA for coin_id=2 with period=2\n",
    "\n",
    "# Confirm that the SMA result matches the expected, with special logic to handle NaNs\n",
    "for i, (expected, actual) in enumerate(zip(\n",
    "    expected_sma_2,\n",
    "    result_df[result_df['coin_id'] == 2]['prices_sma_3'].tolist()\n",
    ")):\n",
    "    if np.isnan(expected) and np.isnan(actual):\n",
    "        continue  # Both values are NaN, so this is considered equal\n",
    "    assert expected == actual, f\"Mismatch at index {i}: expected {expected}, got {actual}\"\n",
    "\n",
    "# Confirm that the EMA result matches the expected\n",
    "assert result_df[result_df['coin_id'] == 2]['prices_ema_2'].tolist() == pytest.approx(\n",
    "    expected_ema_2,\n",
    "    abs=1e-2\n",
    "), \"EMA calculation incorrect for coin_id=2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_ema_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = result_df[result_df['coin_id'] == 1]['prices_sma_2'].tolist()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "print(type(expected_sma_1[i]))\n",
    "print(type(output[i]))\n",
    "print(expected_sma_1[i])\n",
    "print(output[i])\n",
    "print(expected_sma_1[i] == output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output == expected_sma_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_id = '004cb3d0-0803-4208-a9e1-c3457567ea3f'\n",
    "coin_df = prices_df[prices_df['coin_id']==coin_id]\n",
    "coin_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "prices_metrics_df = cwm.generate_time_series_metrics(prices_df, metrics_config, dataset_key='prices', colname='price')\n",
    "prices_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_time_series_metrics(df: pd.DataFrame, config: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates specified time series metrics based on the config file.\n",
    "\n",
    "    :param df: DataFrame with columns for coin_id (optional), date, and value.\n",
    "    :param config: Dictionary specifying which metrics to calculate (e.g., SMA, EMA, Bollinger Bands).\n",
    "    :return: DataFrame with metrics appended as columns.\n",
    "    \"\"\"\n",
    "    # Ensure date is in datetime format and sorted\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(by='date')\n",
    "\n",
    "    # Check if coin_id exists\n",
    "    if 'coin_id' in df.columns:\n",
    "        # Apply metrics group by coin_id\n",
    "        df = df.groupby('coin_id').apply(lambda group: apply_metrics(group, config)).reset_index(drop=True)\n",
    "    else:\n",
    "        # Apply metrics directly (no coin_id)\n",
    "        df = apply_metrics(df, config)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_metrics(df: pd.DataFrame, config: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply the required metrics to the DataFrame based on the config.\n",
    "    \"\"\"\n",
    "    # Apply each metric based on config\n",
    "    if 'sma' in config['metrics']:\n",
    "        df = df.join(calculate_sma_ema(df['value'], sma_period=config.get('sma_period', 20)))\n",
    "\n",
    "    # if 'bollinger_bands' in config['metrics']:\n",
    "    #     df = df.join(calculate_bollinger_bands(df['value'], config.get('bb_period', 20)))\n",
    "\n",
    "    # Add more metrics as needed\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_sma_ema(timeseries: pd.Series, sma_period: int = 20, ema_period: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the Simple Moving Average (SMA) and Exponential Moving Average (EMA)\n",
    "    for a given time series.\n",
    "\n",
    "    :param timeseries: Pandas Series representing the values over time (indexed by date).\n",
    "    :param sma_period: Period for calculating the SMA.\n",
    "    :param ema_period: Period for calculating the EMA.\n",
    "    :return: DataFrame containing the original series, SMA, and EMA.\n",
    "    \"\"\"\n",
    "    # Calculate the Simple Moving Average (SMA)\n",
    "    sma = timeseries.rolling(window=sma_period).mean()\n",
    "\n",
    "    # Calculate the Exponential Moving Average (EMA)\n",
    "    ema = timeseries.ewm(span=ema_period, adjust=False).mean()\n",
    "\n",
    "    # Combine results into a DataFrame\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'value': timeseries,\n",
    "        'sma': sma,\n",
    "        'ema': ema\n",
    "    })\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "# Example usage:\n",
    "timeseries = coin_df['price']  # assuming the df is already filtered for a single coin_id and sorted by date\n",
    "\n",
    "metrics_df = calculate_sma_ema(timeseries)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "time_series_config = metrics_config['time_series']['prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
