{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['LOGGING_FILE']=\"../../../Local/logs/wallet_modeling.log\"\n",
    "os.environ['ALERT_SOUND_FILEPATH']=\"../../../Local/assets/sounds/mixkit-alert-bells-echo-765.wav\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.clustering_features as wcl\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.performance_features as wpf\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.wallet_features_orchestrator as wfo\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_modeling_orchestrator as wmo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_modeling.model_reporting as wmr\n",
    "import wallet_modeling.wallet_model as wm\n",
    "import wallet_modeling.experiments_manager as wem\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.wallet_model_evaluation as wime\n",
    "import wallet_insights.wallet_validation_analysis as wiwv\n",
    "\n",
    "# Coin features\n",
    "import coin_wallet_features.wallet_balance_features as cwb\n",
    "\n",
    "# Coin modeling\n",
    "import coin_modeling.coin_model as cm\n",
    "\n",
    "# Coin insights\n",
    "import coin_insights.coin_model_evaluation as cime\n",
    "import coin_insights.coin_validation_analysis as civa\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [\n",
    "    u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp,\n",
    "    wmo, wtd, wmr, wm, wem,\n",
    "    wcl, wmc, wmt, wpf, wtf, wts, wfo,\n",
    "    wime, wiwv,\n",
    "    cwb,\n",
    "    cm,\n",
    "    cime, civa,\n",
    "]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "wallets_config = WalletsConfig.load_from_yaml('../config/wallets_config.yaml')\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "# logger = u.setup_local_logging(logger)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.export_code(\n",
    "    code_directories=[\n",
    "        # 'training_data',\n",
    "        'wallet_features',\n",
    "        # 'wallet_modeling',\n",
    "        # 'wallet_insights'\n",
    "    ],\n",
    "    # include_config = True,\n",
    "    # ipynb_notebook = 'DDA-456 wallet validation performance.ipynb'\n",
    ")\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wallet Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Complete Pre-Training Profits/Market Data\n",
    "# -----------------------------------------\n",
    "# Retrieve training period datasets and save them to temp/wallet_modeling_dfs\n",
    "_,_,_ = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['training_period_start'],\n",
    "    wallets_config['training_data']['training_period_end'],\n",
    "    parquet_prefix = 'training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define cohort and clean training datasets (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "\n",
    "# Add Indicators to Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Load relevant parquet dfs with pre-training history\n",
    "training_market_data_df_full = pd.read_parquet(\"temp/wallet_modeling_dfs/training_market_data_df_full.parquet\")\n",
    "\n",
    "# Generate indicators and save file\n",
    "_ = wmo.generate_training_indicators_df(training_market_data_df_full,wallets_metrics_config)\n",
    "\n",
    "\n",
    "\n",
    "# Identify Wallet Cohort\n",
    "# ----------------------------------------------------------\n",
    "# Remove market data from prior to the starting balance date\n",
    "training_market_data_df = training_market_data_df_full[training_market_data_df_full['date']\n",
    "                                        >=wallets_config['training_data']['training_starting_balance_date']]\n",
    "u.assert_period(training_market_data_df,\n",
    "                wallets_config['training_data']['training_period_start'],\n",
    "                wallets_config['training_data']['training_period_end'])\n",
    "del training_market_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "# Retrieve full profits history\n",
    "training_profits_df_full = pd.read_parquet(\"temp/wallet_modeling_dfs/training_profits_df_full.parquet\")\n",
    "\n",
    "# Define wallet cohort and return cohort-filtered training_profits_df\n",
    "training_profits_df, training_wallet_cohort = wmo.define_training_wallet_cohort(training_profits_df_full,\n",
    "                                                                                training_market_data_df)\n",
    "u.assert_period(training_profits_df,\n",
    "                wallets_config['training_data']['training_period_start'],\n",
    "                wallets_config['training_data']['training_period_end'])\n",
    "del training_profits_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Generate Cohort-Filtered Profits Data for Training Windows\n",
    "# ----------------------------------------------------------\n",
    "# Generate wallet_cohort-filtered profits_df for all training windows\n",
    "training_windows_profits_dfs = wmo.split_training_window_profits_dfs(\n",
    "                                                        training_profits_df,\n",
    "                                                        training_market_data_df,training_wallet_cohort)\n",
    "training_profits_df.to_parquet(\"temp/wallet_modeling_dfs/training_profits_df.parquet\",index=True)\n",
    "del training_profits_df, training_market_data_df\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "# Retrieve Transfers Data\n",
    "# ----------------------------------------------------------\n",
    "# Transfers data retrieval for the wallet_ids in temp.wallet_modeling_training_cohort\n",
    "training_transfers_sequencing_df = wts.retrieve_transfers_sequencing()\n",
    "training_transfers_sequencing_df.to_parquet(\"temp/wallet_modeling_dfs/training_transfers_sequencing_df.parquet\",index=True)\n",
    "del training_transfers_sequencing_df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate training features (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Load files\n",
    "training_profits_df = pd.read_parquet(\"temp/wallet_modeling_dfs/training_profits_df.parquet\")\n",
    "training_market_indicators_data_df = pd.read_parquet(\"temp/wallet_modeling_dfs/training_market_indicators_data_df.parquet\")\n",
    "training_transfers_sequencing_df = pd.read_parquet(\"temp/wallet_modeling_dfs/training_transfers_sequencing_df.parquet\")\n",
    "training_wallet_cohort = list(set(training_profits_df['wallet_address']))\n",
    "\n",
    "\n",
    "# Generate Features for the Full Training Period\n",
    "# ----------------------------------------------------------\n",
    "logger.info(\"Generating features for full training period...\")\n",
    "training_wallet_features_df = wfo.calculate_wallet_features(training_profits_df,\n",
    "                                                            training_market_indicators_data_df,\n",
    "                                                            training_transfers_sequencing_df,\n",
    "                                                            training_wallet_cohort,\n",
    "                                                            wallets_config['training_data']['training_period_start'],\n",
    "                                                            wallets_config['training_data']['training_period_end'])\n",
    "\n",
    "# Define the start of training_data_df appending a suffix for the window\n",
    "training_data_df = training_wallet_features_df.add_suffix(\"|all_windows\")\n",
    "\n",
    "# del training_profits_df,training_wallet_features_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Generate Features for Each Individual Window\n",
    "# ----------------------------------------------------------\n",
    "# Generate features for each window\n",
    "for i, window_profits_df in enumerate(training_windows_profits_dfs, 1):\n",
    "    logger.info(\"Generating features for window %s...\", i)\n",
    "\n",
    "    # Extract the window_df boundary dates that were validated by split_training_window_profits_dfs()\n",
    "    window_opening_balance_date = window_profits_df['date'].min()\n",
    "    window_start_date = window_opening_balance_date + timedelta(days=1)\n",
    "    window_end_date = window_profits_df['date'].max()\n",
    "\n",
    "    # Generate the features\n",
    "    window_wallet_features_df = wfo.calculate_wallet_features(\n",
    "        window_profits_df,  # profits_df is filtered to the window\n",
    "        training_market_indicators_data_df,training_transfers_sequencing_df,  # full training period dfs\n",
    "        training_wallet_cohort,  # full training cohort\n",
    "        window_start_date.strftime('%Y-%m-%d'), window_end_date.strftime('%Y-%m-%d')  # window-specific dates\n",
    "    )\n",
    "\n",
    "    # Check for NaN values and identify problematic columns\n",
    "    nan_columns = window_wallet_features_df.columns[window_wallet_features_df.isna().any()].tolist()\n",
    "    if nan_columns:\n",
    "        raise ValueError(f\"NaN values detected in window {i} in columns: {nan_columns}\")\n",
    "\n",
    "    # Add column suffix and join to training_data_df\n",
    "    window_wallet_features_df = window_wallet_features_df.add_suffix(f'|w{i}')\n",
    "    training_data_df = training_data_df.join(window_wallet_features_df, how='left')\n",
    "\n",
    "    # Check for NaN values and identify problematic columns\n",
    "    nan_columns = training_data_df.columns[training_data_df.isna().any()].tolist()\n",
    "    if nan_columns:\n",
    "        raise ValueError(f\"NaN values detected in training_data_df after window {i} in columns: {nan_columns}\")\n",
    "\n",
    "\n",
    "del window_profits_df,window_wallet_features_df,training_market_indicators_data_df,training_transfers_sequencing_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Clusters Using All Other Features\n",
    "# ----------------------------------------------------------\n",
    "# Append clustering features based on all numeric features in the base training data\n",
    "training_cluster_features_df = wcl.create_basic_cluster_features(training_data_df)\n",
    "training_cluster_features_df = training_cluster_features_df.add_prefix('cluster|')\n",
    "training_data_df = training_data_df.join(training_cluster_features_df, how='inner')\n",
    "\n",
    "\n",
    "\n",
    "# Save TRAINING_DATA_DF\n",
    "# ----------------------------------------------------------\n",
    "# Verify all input wallets exist in final output\n",
    "missing_wallets = set(training_wallet_cohort) - set(training_data_df.index)\n",
    "if missing_wallets:\n",
    "    raise ValueError(f\"Lost {len(missing_wallets)} wallets from original cohort during feature generation. First few missing: {list(missing_wallets)[:5]}\")\n",
    "logger.info(\"Feature generation complete. Final training_df shape: %s\", training_data_df.shape)\n",
    "\n",
    "\n",
    "# Save and clear from memory\n",
    "training_data_df.to_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\",index=True)\n",
    "del training_data_df,training_cluster_features_df\n",
    "gc.collect()\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Modeling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve modeling period datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve Modeling Profits and Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve training coin cohort to restrict modeling period data to only training period coins\n",
    "training_coin_cohort = pd.read_parquet(\"temp/wallet_modeling_dfs/training_market_indicators_data_df.parquet\",\n",
    "                                       columns=['coin_id'])['coin_id'].unique()\n",
    "# Retrieve full historical through modeling period datasets\n",
    "modeling_profits_df_full, modeling_market_data_df_full, modeling_coin_cohort = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['modeling_period_start'],\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    coin_cohort=training_coin_cohort\n",
    ")\n",
    "\n",
    "# Remove pre-modeling period prices\n",
    "modeling_market_data_df = modeling_market_data_df_full[modeling_market_data_df_full['date']\n",
    "                                                       >=wallets_config['training_data']['modeling_starting_balance_date']]\n",
    "del modeling_market_data_df_full,training_coin_cohort\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Filter to only training wallet cohort\n",
    "training_wallet_cohort = pd.read_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\", columns=[]).index.values\n",
    "modeling_profits_df = modeling_profits_df_full[modeling_profits_df_full['wallet_address'].isin(training_wallet_cohort)]\n",
    "del modeling_profits_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Assert period, save files, remove from memory\n",
    "u.assert_period(modeling_market_data_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n",
    "u.assert_period(modeling_profits_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n",
    "modeling_profits_df.to_parquet(\"temp/wallet_modeling_dfs/modeling_profits_df.parquet\",index=False)\n",
    "modeling_market_data_df.to_parquet(\"temp/wallet_modeling_dfs/modeling_market_data_df.parquet\",index=False)\n",
    "del modeling_profits_df,modeling_market_data_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Model Target Variable and Wallet Cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define modeling cohort and features (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Create training_cohort-Indexed modeling_wallet_features_df\n",
    "# -----------------------------------------------------------\n",
    "# Create a DataFrame with training wallet cohort as the index\n",
    "training_wallet_cohort = pd.read_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\", columns=[]).index.values\n",
    "modeling_wallet_features_df = pd.DataFrame(index=training_wallet_cohort)\n",
    "modeling_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "# Store feature sets with their prefixes for bulk renaming\n",
    "feature_column_names = {}\n",
    "\n",
    "\n",
    "# Identify Modeling Period Cohort\n",
    "# -----------------------------------------------------------\n",
    "# Retrieve trading features for all wallets in training_cohort with boolean for in_modeling_cohort\n",
    "modeling_profits_df = pd.read_parquet(\"temp/wallet_modeling_dfs/modeling_profits_df.parquet\")\n",
    "modeling_trading_features_df = wmo.identify_modeling_cohort(modeling_profits_df)\n",
    "modeling_wallet_features_df = modeling_wallet_features_df.join(modeling_trading_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in modeling_trading_features_df.columns})\n",
    "\n",
    "\n",
    "# Generate Modeling Period Performance Features\n",
    "# -----------------------------------------------------------\n",
    "# Calculate performance metrics for the training cohort (wallets with 0 activity still impact rank orders)\n",
    "modeling_performance_features_df = wpf.calculate_performance_features(modeling_wallet_features_df)\n",
    "modeling_wallet_features_df = modeling_wallet_features_df.join(modeling_performance_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in modeling_performance_features_df.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select target variable and build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create MODELING_DF and Construct Wallet Model\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "training_data_df = pd.read_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\")\n",
    "\n",
    "# Filter training data to only the modeling cohort through inner join to target variable\n",
    "modeling_cohort_target_var_df = modeling_wallet_features_df[['in_modeling_cohort', wallets_config['modeling']['target_variable']]]\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config)\n",
    "model_results = wallet_model.run_experiment(training_data_df,modeling_cohort_target_var_df)\n",
    "# del training_data_df\n",
    "# gc.collect()\n",
    "\n",
    "# Extract the trained model\n",
    "model = model_results['pipeline'].named_steps['regressor']\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, evaluator, modeling_wallet_scores_df = wmr.generate_and_save_model_artifacts(\n",
    "    model_results=model_results,\n",
    "    base_path='../wallet_modeling'\n",
    ")\n",
    "modeling_wallet_scores_df.to_parquet(\"temp/wallet_modeling_dfs/modeling_wallet_scores_df.parquet\",index=True)\n",
    "\n",
    "\n",
    "u.notify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess wallet model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Reload evaluator\n",
    "evaluator = wime.RegressionEvaluator(\n",
    "    y_train=model_results['y_train'],\n",
    "    y_true=model_results['y_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    training_cohort_pred=model_results['training_cohort_pred'],\n",
    "    training_cohort_actuals=model_results['training_cohort_actuals'],\n",
    "    model=model,\n",
    "    feature_names=model_results['X_train'].columns.tolist()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(evaluator.summary_report())\n",
    "evaluator.plot_evaluation()\n",
    "evaluator.importance_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# List of the x features with the highest importance in the model\n",
    "x_features = 8\n",
    "top_feature_metrics = list((pd.DataFrame(evaluator.metrics['importances'])\n",
    "                      .sort_values(by='importance',ascending=False)\n",
    "                      .head(x_features)['feature']))\n",
    "all_metrics = list(set(top_feature_metrics))\n",
    "\n",
    "# Cluster numbers\n",
    "n_clusters=4\n",
    "\n",
    "\n",
    "styled_df = wime.create_cluster_report(training_data_df, model_results, n_clusters, all_metrics)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Period Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original coin model feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Generate features based on the coin config files\n",
    "coin_features_training_data_df, _, _ = tw.generate_all_time_windows_model_inputs(config,metrics_config,modeling_config)\n",
    "\n",
    "# Remove time window index since we aren't using that for now\n",
    "coin_features_training_data_df = coin_features_training_data_df.reset_index(level='time_window', drop=True)\n",
    "\n",
    "# Save to parquet\n",
    "coin_features_training_data_df.to_parquet(\"temp/coin_modeling_dfs/coin_features_training_data_df.parquet\",index=True)\n",
    "\n",
    "u.notify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Retrieve base datasets used by all windows\n",
    "# ---------------------------------------------\n",
    "macro_trends_df, market_data_df, profits_df, prices_df = tw.prepare_all_windows_base_data(config,\n",
    "                                                                                        metrics_config)\n",
    "\n",
    "\n",
    "# FILTER TO COIN COHORT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = market_data_df['coin_id']\n",
    "print(len(set(coin_ids)))\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Generate flattened features for each dataset in each window\n",
    "# --------------------------------------------------------------\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = tw.generate_time_windows(config)\n",
    "\n",
    "all_flattened_dfs = []\n",
    "all_flattened_filepaths = []\n",
    "\n",
    "for _, time_window in enumerate(time_windows):\n",
    "\n",
    "    # Prepare time window config files\n",
    "    window_config, window_metrics_config, window_modeling_config = (\n",
    "        exp.prepare_configs(modeling_config['modeling']['config_folder'], time_window))\n",
    "\n",
    "    # Generate flattened feature dfs for all datasets for the window\n",
    "    window_flattened_dfs, window_flattened_filepaths = tw.generate_window_flattened_dfs(\n",
    "        market_data_df,\n",
    "        macro_trends_df,\n",
    "        profits_df,\n",
    "        prices_df,\n",
    "        window_config,\n",
    "        window_metrics_config,\n",
    "        window_modeling_config\n",
    "    )\n",
    "\n",
    "    # Store window's flattened features\n",
    "    all_flattened_dfs.extend(window_flattened_dfs)\n",
    "    all_flattened_filepaths.extend(window_flattened_filepaths)\n",
    "\n",
    "# 3. Combine features from all datasets in all time windows with target variables\n",
    "# -------------------------------------------------------------------------------\n",
    "# Combine all time windows for each dataset, the join the datasets together\n",
    "concatenated_dfs = tw.concat_dataset_time_windows_dfs(all_flattened_filepaths,modeling_config)\n",
    "training_data_df, join_logs_df = tw.join_dataset_all_windows_dfs(concatenated_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# def generate_window_flattened_dfs(\n",
    "\n",
    "window_flattened_dfs = []\n",
    "window_flattened_filepaths = []\n",
    "\n",
    "# # Market data: generate window-specific flattened metrics\n",
    "# flattened_market_data_df, flattened_market_data_filepath = fg.generate_window_time_series_features(\n",
    "#     market_data_df,\n",
    "#     'time_series-market_data',\n",
    "#     config,\n",
    "#     metrics_config['time_series']['market_data'],\n",
    "#     modeling_config\n",
    "# )\n",
    "# window_flattened_dfs.extend([flattened_market_data_df])\n",
    "# window_flattened_filepaths.extend([flattened_market_data_filepath])\n",
    "\n",
    "# Macro trends: generate window-specific flattened metrics\n",
    "if not macro_trends_df.drop(columns='date').empty:\n",
    "    flattened_macro_trends_df, flattened_macro_trends_filepath = fg.generate_window_macro_trends_features(\n",
    "        macro_trends_df,\n",
    "        'macro_trends',\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )\n",
    "    window_flattened_dfs.extend([flattened_macro_trends_df])\n",
    "    window_flattened_filepaths.extend([flattened_macro_trends_filepath])\n",
    "\n",
    "# Cohorts: generate window-specific flattened metrics\n",
    "flattened_cohort_dfs, flattened_cohort_filepaths = fg.generate_window_wallet_cohort_features(\n",
    "    profits_df,\n",
    "    prices_df,\n",
    "    config,\n",
    "    metrics_config,\n",
    "    modeling_config\n",
    ")\n",
    "window_flattened_dfs.extend(flattened_cohort_dfs)\n",
    "window_flattened_filepaths.extend(flattened_cohort_filepaths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro trends: generate window-specific flattened metrics\n",
    "if not macro_trends_df.drop(columns='date').empty:\n",
    "    flattened_macro_trends_df, flattened_macro_trends_filepath = fg.generate_window_macro_trends_features(\n",
    "        macro_trends_df,\n",
    "        'macro_trends',\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )\n",
    "    # window_flattened_dfs.extend([flattened_macro_trends_df])\n",
    "    # window_flattened_filepaths.extend([flattened_macro_trends_filepath])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_macro_trends_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.notify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = flattened_cohort_dfs[0]['coin_id']\n",
    "print(len(set(coin_ids)))\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = market_data_df['coin_id']\n",
    "print(len(set(coin_ids)))\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate_window_wallet_cohort_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_window_wallet_cohort_features(\n",
    "\n",
    "# 1. Impute all required dates\n",
    "# ----------------------------\n",
    "# Identify all required imputation dates\n",
    "imputation_dates = pri.identify_imputation_dates(config)\n",
    "\n",
    "# Impute all required dates\n",
    "window_profits_df = pri.impute_profits_for_multiple_dates(profits_df, prices_df, imputation_dates, n_threads=24)\n",
    "window_profits_df = (window_profits_df[(window_profits_df['date'] >= pd.to_datetime(min(imputation_dates))) &\n",
    "                                    (window_profits_df['date'] <= pd.to_datetime(max(imputation_dates)))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = window_profits_df['coin_id']\n",
    "print(len(set(coin_ids)))\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "# 2. Generate metrics and indicators for all cohorts\n",
    "# --------------------------------------------------\n",
    "# Set up lists to store flattened cohort data\n",
    "flattened_cohort_dfs = []\n",
    "flattened_cohort_filepaths = []\n",
    "\n",
    "# for cohort_name in metrics_config['wallet_cohorts']:\n",
    "cohort_name = 'whales'\n",
    "\n",
    "# load configs\n",
    "dataset_metrics_config = metrics_config['wallet_cohorts'][cohort_name]\n",
    "dataset_config = config['datasets']['wallet_cohorts'][cohort_name]\n",
    "\n",
    "# filter profits_df to the cohort lookback\n",
    "training_period_start = config['training_data']['training_period_start']\n",
    "cohort_lookback = config['datasets']['wallet_cohorts'][cohort_name]['lookback_period']\n",
    "cohort_lookback_start = pd.to_datetime(training_period_start) - timedelta(days=cohort_lookback)\n",
    "cohort_profits_df = window_profits_df[window_profits_df['date']>=cohort_lookback_start]\n",
    "\n",
    "# identify wallets in the cohort based on the full lookback period\n",
    "cohort_summary_df = cwm.classify_wallet_cohort(cohort_profits_df, dataset_config, cohort_name)\n",
    "cohort_wallets = cohort_summary_df[cohort_summary_df['in_cohort']]['wallet_address']\n",
    "\n",
    "# # # If no cohort members were identified, continue\n",
    "# # if len(cohort_wallets) == 0:\n",
    "# #     logger.info(\"No wallets identified as members of cohort '%s'\", cohort_name)\n",
    "# #     continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_profits_df_full = cohort_profits_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = cohort_profits_df['coin_id']\n",
    "print(len(set(coin_ids)))\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate cohort buysell_metrics\n",
    "cohort_metrics_df = cwm.generate_buysell_metrics_df(cohort_profits_df,\n",
    "                                                    config['training_data']['training_period_end'],\n",
    "                                                    cohort_wallets)\n",
    "\n",
    "# # Generate cohort indicator metrics\n",
    "# cohort_metrics_df = ind.generate_time_series_indicators(cohort_metrics_df,\n",
    "#                                                         metrics_config['wallet_cohorts'][cohort_name],\n",
    "#                                                         'coin_id')\n",
    "\n",
    "# # Flatten cohort metrics\n",
    "# flattened_cohort_df, flattened_cohort_filepath = fg.generate_window_time_series_features(\n",
    "#     cohort_metrics_df,\n",
    "#     f'wallet_cohorts-{cohort_name}',\n",
    "#     config,\n",
    "#     dataset_metrics_config,\n",
    "#     modeling_config\n",
    "# )\n",
    "\n",
    "# flattened_cohort_dfs.extend([flattened_cohort_df])\n",
    "# flattened_cohort_filepaths.extend([flattened_cohort_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = cohort_metrics_df['coin_id']\n",
    "print(len(set(coin_ids)))\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cwm.generate_buysell_metrics_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = cohort_profits_df_full['coin_id']\n",
    "print(len(set(coin_ids)))\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = cohort_profits_df_full.copy()\n",
    "training_period_end = config['training_data']['training_period_end']\n",
    "cohort_wallets = cohort_wallets\n",
    "\n",
    "# def generate_buysell_metrics_df(profits_df,training_period_end,cohort_wallets):\n",
    "\n",
    "start_time = time.time()\n",
    "logger.debug('Preparing buysell_metrics_df...')\n",
    "\n",
    "\n",
    "# Step 1: Filter profits_df to cohort and conduct data quality checks\n",
    "# -------------------------------------------------------------------\n",
    "# Raise an error if either the wallet cohort or coin list is empty\n",
    "if len(cohort_wallets) == 0:\n",
    "    raise ValueError(\"Wallet cohort is empty. Provide at least one wallet address.\")\n",
    "\n",
    "# Create cohort_profits_df by filtering profits_df to only include the cohort coins and wallets\n",
    "# during the training period\n",
    "profits_df = profits_df[profits_df['date']<=training_period_end]\n",
    "cohort_profits_df = profits_df[profits_df['wallet_address'].isin(cohort_wallets)]\n",
    "\n",
    "logger.info(\"No wallet cohort activity found for %s coins during the window.\",\n",
    "            len(profits_df['coin_id'].unique()) - len(cohort_profits_df['coin_id'].unique()))\n",
    "\n",
    "cohort_profits_df = cohort_profits_df[['coin_id','wallet_address','date','usd_balance','usd_net_transfers']]\n",
    "\n",
    "# Raise an error if the filtered df is empty\n",
    "if cohort_profits_df.empty:\n",
    "    raise ValueError(\"Cohort-filtered profits_df is empty. Please check input parameters\")\n",
    "\n",
    "\n",
    "# Step 2: Add buy_sequence and sell_sequence columns\n",
    "# --------------------------------------------------\n",
    "# Initialize the buy and sell sequence columns\n",
    "cohort_profits_df['buy_sequence'] = np.where(cohort_profits_df['usd_net_transfers'] > 0, 1, np.nan)\n",
    "cohort_profits_df['sell_sequence'] = np.where(cohort_profits_df['usd_net_transfers'] < 0, 1, np.nan)\n",
    "\n",
    "# Calculate cumulative sum to simulate transfer sequence, skipping rows where usd_net_transfers == 0\n",
    "cohort_profits_df['buy_sequence'] = cohort_profits_df.groupby(['coin_id', 'wallet_address'], observed=True)['buy_sequence'].cumsum()\n",
    "cohort_profits_df['sell_sequence'] = cohort_profits_df.groupby(['coin_id', 'wallet_address'], observed=True)['sell_sequence'].cumsum()\n",
    "\n",
    "# Set buy_sequence and sell_sequence to null where usd_net_transfers == 0\n",
    "cohort_profits_df.loc[cohort_profits_df['usd_net_transfers'] == 0, ['buy_sequence', 'sell_sequence']] = np.nan\n",
    "\n",
    "\n",
    "# Step 3: Calculate coin metrics\n",
    "# ------------------------------\n",
    "# Initialize an empty list to store DataFrames for each coin\n",
    "coin_features_list = []\n",
    "\n",
    "# Loop through all unique coin_ids\n",
    "for c in cohort_profits_df['coin_id'].unique():\n",
    "    # Filter cohort_profits_df for the current coin_id and create a copy\n",
    "    coin_cohort_profits_df = cohort_profits_df[cohort_profits_df['coin_id'] == c].copy()\n",
    "\n",
    "    # Call the feature calculation function\n",
    "    coin_features_df = cwm.generate_coin_buysell_metrics_df(coin_cohort_profits_df)\n",
    "\n",
    "    # Add coin_id back to the DataFrame to retain coin information\n",
    "    coin_features_df['coin_id'] = c\n",
    "\n",
    "    # Append the result to the list\n",
    "    coin_features_list.append(coin_features_df)\n",
    "\n",
    "\n",
    "# Step 4: Consolidate all metrics into a filled DataFrame\n",
    "# -------------------------------------------------------\n",
    "# Concatenate all features DataFrames into a single DataFrame\n",
    "buysell_metrics_df = pd.concat(coin_features_list, ignore_index=True)\n",
    "\n",
    "# Ensure full date range coverage through the training_period_end for each coin-wallet pair\n",
    "buysell_metrics_df = cwm.fill_buysell_metrics_df(buysell_metrics_df, training_period_end)\n",
    "\n",
    "logger.info('Generated buysell_metrics_df after %.2f seconds.', time.time() - start_time)\n",
    "\n",
    "\n",
    "coin_ids = cohort_profits_df['coin_id']\n",
    "print(len(set(coin_ids)))\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "coin_ids = cohort_profits_df['coin_id']\n",
    "print(len(set(coin_ids)))\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "all_windows_time_series_df = market_data_df.copy()\n",
    "dataset_name = 'time_series-market_data'\n",
    "config = config\n",
    "dataset_metrics_config = metrics_config['time_series']['market_data']\n",
    "modeling_config = modeling_config\n",
    "\n",
    "\n",
    "# def generate_window_time_series_features(\n",
    "\n",
    "# Filter input data to time window\n",
    "window_time_series_df = cwm.apply_period_boundaries(\n",
    "    all_windows_time_series_df,\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['training_period_end'],\n",
    ")\n",
    "\n",
    "# Flatten the metrics DataFrame to be keyed only on coin_id\n",
    "flattened_metrics_df = flt.flatten_coin_date_df(\n",
    "    window_time_series_df,\n",
    "    dataset_metrics_config,\n",
    "    config['training_data']['training_period_end']  # Ensure data is up to training period end\n",
    ")\n",
    "\n",
    "# Add time window modeling period start\n",
    "flattened_metrics_df.loc[:,'time_window'] = config['training_data']['modeling_period_start']\n",
    "\n",
    "# Add dataset_name as a prefix to all columns so their lineage is fully documented\n",
    "flattened_metrics_df = flattened_metrics_df.rename(\n",
    "    columns=lambda x:\n",
    "    f\"{dataset_name.replace('-', '|')}|{x}\"\n",
    "    if x not in ['coin_id', 'time_window']\n",
    "    else x)\n",
    "\n",
    "# Save the flattened output and retrieve the file path\n",
    "_, flattened_metrics_filepath = flt.save_flattened_outputs(\n",
    "    flattened_metrics_df,\n",
    "    os.path.join(\n",
    "        modeling_config['modeling']['modeling_folder'],  # Folder to store flattened outputs\n",
    "        'outputs/flattened_outputs'\n",
    "    ),\n",
    "    dataset_name,  # Descriptive metadata for the dataset\n",
    "    config['training_data']['modeling_period_start']  # Ensure data starts from modeling period\n",
    ")\n",
    "\n",
    "\n",
    "flattened_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coin_ids = flattened_metrics_df['coin_id']\n",
    "\n",
    "\n",
    "print(len(set(coin_ids)))\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_time_series_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_time_series_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = window_time_series_df['coin_id']\n",
    "\n",
    "\n",
    "print(len(set(coin_ids)))\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = all_windows_time_series_df['coin_id']\n",
    "\n",
    "\n",
    "print(len(set(coin_ids)))\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df = pd.DataFrame(all_windows_time_series_df.groupby('coin_id',observed=True)['date'].max())\n",
    "dates_df.groupby('date').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_windows_time_series_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_windows_time_series_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_dataframe_by_coverage(\n",
    "time_series_df = all_windows_time_series_df.copy()\n",
    "start_date = config['training_data']['training_period_start']\n",
    "end_date = config['training_data']['training_period_end']\n",
    "id_column = id_column='coin_id'\n",
    "drop_outside_date_range = True\n",
    "\n",
    "\n",
    "# Convert params to datetime\n",
    "start_date = pd.to_datetime(start_date)\n",
    "end_date = pd.to_datetime(end_date)\n",
    "\n",
    "# Create copy of df\n",
    "time_series_df = time_series_df.copy()\n",
    "\n",
    "# Drop all rows with any NaN values\n",
    "time_series_df = time_series_df.dropna()\n",
    "\n",
    "# # Define a function to check if a date range has full coverage\n",
    "# def has_full_coverage(min_date, max_date):\n",
    "#     return (min_date <= start_date) and (max_date >= end_date)\n",
    "\n",
    "# if id_column:\n",
    "#     # Multi-series data\n",
    "#     series_data_range = time_series_df.groupby(id_column, observed=True)['date'].agg(['min', 'max'])\n",
    "#     full_duration_series = series_data_range[series_data_range.apply(lambda x: has_full_coverage(x['min'], x['max']), axis=1)].index\n",
    "# else:\n",
    "#     # Single-series data\n",
    "#     series_data_range = time_series_df['date'].agg(['min', 'max'])\n",
    "#     full_duration_series = [0] if has_full_coverage(series_data_range['min'], series_data_range['max']) else []\n",
    "\n",
    "# # Calculate coverage statistics\n",
    "# full_coverage_count = len(full_duration_series)\n",
    "\n",
    "# # Split the dataframe\n",
    "# if id_column:\n",
    "#     # Convert id column to categorical to reduce memory usage\n",
    "#     time_series_df[id_column] = time_series_df[id_column].astype('category')\n",
    "#     full_coverage_df = time_series_df[time_series_df[id_column].isin(full_duration_series)]\n",
    "#     partial_coverage_df = time_series_df[~time_series_df[id_column].isin(full_duration_series)]\n",
    "# else:\n",
    "#     full_coverage_df = time_series_df if full_coverage_count else pd.DataFrame(columns=time_series_df.columns)\n",
    "#     partial_coverage_df = time_series_df if not full_coverage_count else pd.DataFrame(columns=time_series_df.columns)\n",
    "\n",
    "# logger.debug(\"Split df with dimensions %s into %s full coverage records and %s partial coverage records.\",\n",
    "#             time_series_df.shape,\n",
    "#             len(full_coverage_df),\n",
    "#             len(partial_coverage_df))\n",
    "\n",
    "# if drop_outside_date_range:\n",
    "#     # Remove rows outside the date range for both dataframes\n",
    "#     full_coverage_df = (full_coverage_df[(full_coverage_df['date'] >= start_date) &\n",
    "#                                             (full_coverage_df['date'] <= end_date)])\n",
    "#     partial_coverage_df = (partial_coverage_df[(partial_coverage_df['date'] >= start_date) &\n",
    "#                                                 (partial_coverage_df['date'] <= end_date)])\n",
    "\n",
    "#     # Log the number of remaining records\n",
    "#     total_remaining = len(full_coverage_df) + len(partial_coverage_df)\n",
    "#     logger.debug(\"After removing records outside the date range, %s records remain.\",\n",
    "#                 total_remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = time_series_df['coin_id']\n",
    "\n",
    "\n",
    "print(len(set(coin_ids)))\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coin_ids = window_time_series_df['coin_id']\n",
    "\n",
    "\n",
    "# print(len(set(coin_ids)))\n",
    "# wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "# print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(window_time_series_df['coin_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_time_series_df.groupby('coin_id',observed=True).agg({\n",
    "    'date': ['min','max']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_df.groupby('coin_id',observed=True).agg({\n",
    "    'date': ['min','max']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = partial_df['coin_id']\n",
    "\n",
    "\n",
    "print(len(set(coin_ids)))\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flattened_macro_trends_df.shape)\n",
    "flattened_macro_trends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_ids = profits_df['coin_id']\n",
    "\n",
    "wallet_features_only = set(modeling_profits_df['coin_id']) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing coins assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_features_training_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Extract id lists\n",
    "coin_features_ids = coin_features_training_data_df.index\n",
    "wallet_features_ids = modeling_profits_df['coin_id']\n",
    "\n",
    "\n",
    "# Perform comparisons\n",
    "both_sets_all_coin_ids = list(set(coin_features_ids) | set(wallet_features_ids))\n",
    "overlap = set(coin_features_ids) & set(wallet_features_ids)\n",
    "coin_features_only = set(coin_features_ids) - set(wallet_features_ids)\n",
    "wallet_features_only = set(wallet_features_ids) - set(coin_features_ids)\n",
    "\n",
    "print(f'all coin ids: {len(both_sets_all_coin_ids)}')\n",
    "print(f'wallet coin ids: {len((set(wallet_features_ids)))}')\n",
    "print(f'coin coin ids: {len(set(coin_features_ids))}')\n",
    "print(f'overlapping coin ids: {len(overlap)}')\n",
    "print(f'coin features only: {len(coin_features_only)}')\n",
    "print(f'wallet features only: {len(wallet_features_only)}')\n",
    "\n",
    "\n",
    "# Define index\n",
    "all_coin_ids = list(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "market_data_df_full = dr.retrieve_market_data(dataset=config['training_data']['dataset'])\n",
    "\n",
    "coin_ids = market_data_df_full['coin_id']\n",
    "wallet_features_only = set(wallet_features_ids) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "market_data_df = market_data_df_full.copy()\n",
    "\n",
    "market_data_df = dr.clean_market_data(market_data_df, config,\n",
    "                                        config['training_data']['earliest_window_start'],\n",
    "                                        config['training_data']['training_period_end'])\n",
    "\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "\n",
    "coin_ids = market_data_df['coin_id']\n",
    "wallet_features_only = set(wallet_features_ids) - set(coin_ids)\n",
    "print(f'wallet features only: {len(wallet_features_only)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_features_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_volume_coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c =  '0bf15fd6-ed3d-4485-b066-c473cfb81f06'\n",
    "\n",
    "volume_df = pd.DataFrame(mean_volume)\n",
    "volume_df.loc[c]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare coin_training_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Load modeling period scores and data\n",
    "modeling_wallet_scores_df = pd.read_parquet(\"temp/wallet_modeling_dfs/modeling_wallet_scores_df.parquet\")\n",
    "modeling_market_data_df = pd.read_parquet(\"temp/wallet_modeling_dfs/modeling_market_data_df.parquet\")\n",
    "modeling_profits_df = pd.read_parquet(\"temp/wallet_modeling_dfs/modeling_profits_df.parquet\")\n",
    "u.assert_period(modeling_market_data_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n",
    "u.assert_period(modeling_profits_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define full coin_id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Extract id lists\n",
    "coin_features_ids = coin_features_training_data_df.index\n",
    "wallet_features_ids = modeling_profits_df['coin_id']\n",
    "\n",
    "\n",
    "# Perform comparisons\n",
    "both_sets_all_coin_ids = list(set(coin_features_ids) | set(wallet_features_ids))\n",
    "overlap = set(coin_features_ids) & set(wallet_features_ids)\n",
    "coin_features_only = set(coin_features_ids) - set(wallet_features_ids)\n",
    "wallet_features_only = set(wallet_features_ids) - set(coin_features_ids)\n",
    "\n",
    "print(f'all coin ids: {len(both_sets_all_coin_ids)}')\n",
    "print(f'overlapping coin ids: {len(overlap)}')\n",
    "print(f'coin features only: {len(coin_features_only)}')\n",
    "print(f'wallet features only: {len(wallet_features_only)}')\n",
    "\n",
    "\n",
    "# Define index\n",
    "all_coin_ids = list(overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate coin features as of the end of the modeling period (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Initialize with complete coin list\n",
    "coin_wallet_features_df = pd.DataFrame(index=all_coin_ids)\n",
    "coin_wallet_features_df.index.name = 'coin_id'\n",
    "\n",
    "# Generate coin-level features based on modeling period end wallet scores and balances\n",
    "coin_wallet_balance_features_modeling_end_df = cwb.calculate_coin_wallet_balance_features(\n",
    "    modeling_profits_df,\n",
    "    modeling_wallet_scores_df,\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    all_coin_ids\n",
    ")\n",
    "coin_wallet_balance_features_modeling_end_df = coin_wallet_balance_features_modeling_end_df.add_prefix('wallet_balance|')\n",
    "coin_wallet_balance_features_modeling_end_df = coin_wallet_balance_features_modeling_end_df.add_suffix('|modeling_end')\n",
    "coin_wallet_features_df = coin_wallet_features_df.join(coin_wallet_balance_features_modeling_end_df,how='inner')\n",
    "\n",
    "# Generate coin-level features based on modeling period start wallet scores and balances\n",
    "coin_wallet_balance_features_modeling_start_df = cwb.calculate_coin_wallet_balance_features(\n",
    "    modeling_profits_df,\n",
    "    modeling_wallet_scores_df,\n",
    "    wallets_config['training_data']['modeling_period_start'],\n",
    "    all_coin_ids\n",
    ")\n",
    "coin_wallet_balance_features_modeling_start_df = coin_wallet_balance_features_modeling_start_df.add_prefix('wallet_balance|')\n",
    "coin_wallet_balance_features_modeling_start_df = coin_wallet_balance_features_modeling_start_df.add_suffix('|modeling_start')\n",
    "coin_wallet_features_df = coin_wallet_features_df.join(coin_wallet_balance_features_modeling_start_df,how='inner')\n",
    "\n",
    "coin_wallet_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from coin features pipeline\n",
    "coin_features_training_data_df = pd.read_parquet(\"temp/coin_modeling_dfs/coin_features_training_data_df.parquet\")\n",
    "\n",
    "\n",
    "# Crude join\n",
    "coin_training_data_df = coin_features_training_data_df.join(coin_wallet_features_df,how='inner')\n",
    "coin_training_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare coin_modeling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve Validation Profits and Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve full historical through validation period datasets\n",
    "\n",
    "# Retrieve training coin cohort to ensure all training period coins are reflected\n",
    "# TODO: assess whether this cohort filter should be removed\n",
    "training_coin_cohort = pd.read_parquet(\"temp/wallet_modeling_dfs/training_market_indicators_data_df.parquet\",\n",
    "                                       columns=['coin_id'])['coin_id'].unique()\n",
    "validation_profits_df, validation_market_data_df_full, validation_coin_cohort = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['validation_period_start'],\n",
    "    wallets_config['training_data']['validation_period_end'],\n",
    "    training_coin_cohort\n",
    ")\n",
    "\n",
    "# Remove pre-validation period prices\n",
    "validation_market_data_df = validation_market_data_df_full[validation_market_data_df_full['date']\n",
    "                                                       >=wallets_config['training_data']['validation_starting_balance_date']]\n",
    "del validation_market_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Assert period, save files, remove from memory\n",
    "u.assert_period(validation_market_data_df,\n",
    "                wallets_config['training_data']['validation_period_start'],\n",
    "                wallets_config['training_data']['validation_period_end'])\n",
    "u.assert_period(validation_profits_df,\n",
    "                wallets_config['training_data']['validation_period_start'],\n",
    "                wallets_config['training_data']['validation_period_end'])\n",
    "validation_profits_df.to_parquet(\"temp/wallet_modeling_dfs/validation_profits_df.parquet\",index=False)\n",
    "validation_market_data_df.to_parquet(\"temp/wallet_modeling_dfs/validation_market_data_df.parquet\",index=False)\n",
    "del validation_profits_df,validation_market_data_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare target variable (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load market data\n",
    "validation_market_data_df = pd.read_parquet(\"temp/wallet_modeling_dfs/validation_market_data_df.parquet\")\n",
    "\n",
    "\n",
    "# Calculate coin return performance during validation period\n",
    "validation_coin_performance_df = civa.calculate_coin_performance(\n",
    "    validation_market_data_df,\n",
    "    wallets_config['training_data']['validation_period_start'],\n",
    "    wallets_config['training_data']['validation_period_end']\n",
    ")\n",
    "validation_coin_performance_df['coin_return_winsorized'] = u.winsorize(\n",
    "        validation_coin_performance_df['coin_return'],\n",
    "        wallets_coin_config['coin_modeling']['returns_winsorization'])\n",
    "\n",
    "# Validation: check if any coin_ids missing from final features\n",
    "missing_coins = set(coin_training_data_df.index) - set(validation_coin_performance_df.index)\n",
    "if missing_coins:\n",
    "    raise ValueError(f\"Found {len(missing_coins)} coin_ids in training_data_df without validation period target variables.\")\n",
    "\n",
    "\n",
    "# Attach target variable column to training_data_df\n",
    "target_var_column = wallets_coin_config['coin_modeling']['target_variable']\n",
    "coin_modeling_df = coin_training_data_df.join(validation_coin_performance_df[[target_var_column]])\n",
    "\n",
    "coin_modeling_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build coin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Initialize and run model\n",
    "coin_model = cm.CoinModel(wallets_coin_config=wallets_coin_config)\n",
    "coin_model_results = coin_model.run_experiment(feature_df=coin_modeling_df)\n",
    "\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = cime.CoinRegressionEvaluator(\n",
    "    y_test=coin_model_results['y_test'],\n",
    "    y_pred=coin_model_results['y_pred'],\n",
    "    model=coin_model.pipeline.named_steps['regressor'],\n",
    "    feature_names=coin_model_results['X_train'].columns.tolist()\n",
    ")\n",
    "\n",
    "# Generate reports\n",
    "print(evaluator.summary_report())\n",
    "evaluator.plot_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet aggregated analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate validation wallet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Load parquet\n",
    "validation_profits_df = pd.read_parquet(\"temp/wallet_modeling_dfs/validation_profits_df.parquet\")\n",
    "validation_market_data_df = pd.read_parquet(\"temp/wallet_modeling_dfs/validation_market_data_df.parquet\")\n",
    "\n",
    "\n",
    "# Create a DataFrame with all wallets that should exist\n",
    "validation_wallet_features_df = pd.DataFrame(index=training_wallet_cohort)\n",
    "validation_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "\n",
    "# Calculate modeling period wallet metrics\n",
    "validation_trading_features_df = wtf.calculate_wallet_trading_features(validation_profits_df,\n",
    "                                                            wallets_config['training_data']['validation_period_start'],\n",
    "                                                            wallets_config['training_data']['validation_period_end'])\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(validation_trading_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in validation_trading_features_df.columns})\n",
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features_df = wpf.calculate_performance_features(validation_wallet_features_df)\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(performance_features_df, how='inner')\n",
    "validation_wallet_features_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wallet validation period trading/performance by score quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create analysis by prediction bands\n",
    "metrics = [\n",
    "    'crypto_net_gain/max_investment/winsorized',\n",
    "    'net_crypto_investment/max_investment/winsorized',\n",
    "    'max_investment',\n",
    "    'crypto_net_gain',\n",
    "    'net_crypto_investment',\n",
    "    'total_volume',\n",
    "]\n",
    "\n",
    "min_wallet_volume_usd = 1000\n",
    "num_quantiles = 5\n",
    "\n",
    "wiwv.create_quantile_report(\n",
    "    validation_wallet_features_df,\n",
    "    model_results['y_pred'],\n",
    "    metrics,  # Your existing metrics list\n",
    "    num_quantiles,  # Split into ntiles\n",
    "    min_wallet_volume_usd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin aggregated analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coin-aggregated wallet metrics by coin performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Load wallet scores from the modeling period\n",
    "modeling_wallet_scores_df = pd.read_parquet(\"temp/wallet_modeling_dfs/modeling_wallet_scores_df.parquet\")\n",
    "\n",
    "# Generate coin-level features about wallet behavior during the\n",
    "modeling_coin_end_balance_features_df = cwsf.calculate_coin_end_balance_features(\n",
    "    modeling_profits_df,\n",
    "    modeling_wallet_scores_df\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate and join coin return performance during validation period\n",
    "validation_coin_performance_df = civa.calculate_coin_performance(\n",
    "    validation_market_data_df,\n",
    "    wallets_config['training_data']['validation_period_start'],\n",
    "    wallets_config['training_data']['validation_period_end']\n",
    ")\n",
    "validation_coin_wallet_features_df = modeling_coin_end_balance_features_df.join(validation_coin_performance_df,how='inner')\n",
    "\n",
    "\n",
    "# Create styled performance analysis\n",
    "civa.create_top_coins_wallet_metrics_report(validation_coin_wallet_features_df,percentile=90,method='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = civa.analyze_market_cap_segments(\n",
    "    coin_wallet_features_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "civa.plot_segment_heatmap(summary_df)\n",
    "civa.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_validation_analysis']['top_n']\n",
    "max_market_cap = wallets_config['coin_validation_analysis']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_validation_analysis']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = civa.validate_coin_performance(coin_wallet_features_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "civa.print_performance_analysis(coin_wallet_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_performance_features_df():\n",
    "    \"\"\"\n",
    "    Fixture to provide a sample DataFrame for testing ratio calculations.\n",
    "    Includes profits and balance metrics for multiple wallets,\n",
    "    including one with all 0 values and another with losses.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'profits_total_gain': [100, 200, 300, 0, -50],\n",
    "        'profits_realized_gain': [50, 150, 250, 0, -30],\n",
    "        'profits_unrealized_gain': [50, 50, 50, 0, -20],\n",
    "        'balance_max_investment': [1000, 2000, 3000, 0, 500],\n",
    "        'balance_time_weighted_balance': [500, 1500, 2500, 0, 300],\n",
    "        'balance_active_time_weighted_balance': [400, 1200, 2200, 0, 250],\n",
    "    }\n",
    "    index = ['wallet1', 'wallet2', 'wallet3', 'wallet4_zero', 'wallet5_loss']\n",
    "    return pd.DataFrame(data, index=index)\n",
    "\n",
    "sample_performance_features_df = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @pytest.mark.unit\n",
    "# def test_transform_performance_ratios(sample_performance_features_df):\n",
    "\"\"\"\n",
    "Test to validate the correctness of transformations applied to performance ratios by\n",
    "wpf.transform_performance_ratios.\n",
    "Steps:\n",
    "1. Generate raw ratios using wpf.calculate_performance_ratios.\n",
    "2. Apply transformations, including rank, log, winsorization, and ntile rank.\n",
    "3. Validate the correctness of each transformation step.\n",
    "\"\"\"\n",
    "# Step 1: Generate raw ratios\n",
    "ratio_df = wpf.calculate_performance_ratios(sample_performance_features_df)\n",
    "\n",
    "# Step 2: Define balance metrics for ntile calculation\n",
    "balance_features_df = sample_performance_features_df.filter(like='balance_')\n",
    "\n",
    "# Step 3: Transform the performance ratios\n",
    "transformed_df = wpf.transform_performance_ratios(ratio_df, balance_features_df)\n",
    "\n",
    "# Explanation of assertions:\n",
    "# 1. Base ratios: Validate that the base ratios remain unchanged after transformation.\n",
    "for col in ratio_df.columns:\n",
    "    assert np.allclose(\n",
    "        transformed_df[f\"{col}/base\"].values,\n",
    "        ratio_df[col].values,\n",
    "        equal_nan=True\n",
    "    ), f\"Base ratio for {col} does not match expected values.\"\n",
    "\n",
    "# 2. Rank: Validate that the ranks are correctly calculated as percentiles.\n",
    "for col in ratio_df.columns:\n",
    "    expected_rank = ratio_df[col].rank(method=\"average\", pct=True).values\n",
    "    assert np.allclose(\n",
    "        transformed_df[f\"{col}/rank\"].values,\n",
    "        expected_rank,\n",
    "        equal_nan=True\n",
    "    ), f\"Rank for {col} does not match expected values.\"\n",
    "\n",
    "# 3. Log transformation: Validate signed log calculations.\n",
    "for col in ratio_df.columns:\n",
    "    expected_log = np.sign(ratio_df[col]) * np.log1p(ratio_df[col].abs())\n",
    "    assert np.allclose(\n",
    "        transformed_df[f\"{col}/log\"].values,\n",
    "        expected_log,\n",
    "        equal_nan=True\n",
    "    ), f\"Log transformation for {col} does not match expected values.\"\n",
    "\n",
    "# 4. Winsorization: Validate winsorized ratios based on config.\n",
    "# Assume wallets_config['features']['returns_winsorization'] = 0.05\n",
    "winsorization_threshold = wallets_config['features']['returns_winsorization']\n",
    "for col in ratio_df.columns:\n",
    "    series = ratio_df[col]\n",
    "    expected_winsorized = u.winsorize(series, cutoff=winsorization_threshold)\n",
    "    assert np.allclose(\n",
    "        transformed_df[f\"{col}/winsorized\"].values,\n",
    "        expected_winsorized.values,\n",
    "        equal_nan=True\n",
    "    ), f\"Winsorized values for {col} do not match expected values.\"\n",
    "\n",
    "# 5. Ntile rank: Validate that ntile ranks are calculated correctly.\n",
    "ntile_count = 10  # Assume config sets this to 10\n",
    "for col in ratio_df.columns:\n",
    "    denominator = col.split(\"/\")[1]\n",
    "    balance_col = f\"balance_{denominator}\"\n",
    "    metric_ntiles = pd.qcut(\n",
    "        balance_features_df[balance_col],\n",
    "        q=ntile_count,\n",
    "        labels=False,\n",
    "        duplicates=\"drop\"\n",
    "    )\n",
    "    expected_ntile_rank = (\n",
    "        ratio_df[col]\n",
    "        .groupby(metric_ntiles)\n",
    "        .rank(method=\"average\", pct=True)\n",
    "        .fillna(0)\n",
    "    )\n",
    "    assert np.allclose(\n",
    "        transformed_df[f\"{col}/ntile_rank\"].values,\n",
    "        expected_ntile_rank.values,\n",
    "        equal_nan=True\n",
    "    ), f\"Ntile rank for {col} does not match expected values.\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
