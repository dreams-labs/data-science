{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import copy\n",
    "import logging\n",
    "import re\n",
    "from itertools import chain,combinations\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from google.cloud import bigquery\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    log_loss,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['LOGGING_FILE'] = \"../../../Local/logs/wallet_modeling.log\"\n",
    "os.environ['NOTIFICATION_SOUNDS_DIR'] = \"../../../Local\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import insights.modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "import feature_engineering.coin_flow_features_orchestrator as cffo\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.clustering_features as wcl\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.performance_features as wpf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.scenario_features as wsc\n",
    "import wallet_features.balance_features as wbf\n",
    "import wallet_features.macroeconomic_features as wmac\n",
    "import wallet_features.wallet_features_orchestrator as wfo\n",
    "\n",
    "# Base modeling\n",
    "import base_modeling.base_model as bm\n",
    "import base_modeling.feature_selection as fs\n",
    "import base_modeling.pipeline as bp\n",
    "import base_modeling.pipeline as bsc\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_training_data_orchestrator as wtdo\n",
    "import wallet_modeling.wallet_epochs_orchestrator as weo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_modeling.wallet_model as wm\n",
    "import wallet_modeling.wallet_model_orchestrator as wmo\n",
    "import wallet_modeling.wallets_config_manager as wcm\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.wallet_model_reporting as wimr\n",
    "import wallet_insights.model_evaluation as wime\n",
    "import wallet_insights.wallet_validation_analysis as wiva\n",
    "import wallet_insights.wallet_cluster_analysis as wica\n",
    "\n",
    "# Coin features\n",
    "import coin_wallet_features.coin_features_orchestrator as cfo\n",
    "import coin_wallet_features.wallet_metrics as cwwm\n",
    "import coin_wallet_features.wallet_metrics_flattening as cwwmf\n",
    "import coin_wallet_features.wallet_segmentation as cws\n",
    "\n",
    "# Coin modeling\n",
    "import coin_modeling.coin_model as cm\n",
    "import coin_modeling.coin_epochs_orchestrator as ceo\n",
    "from coin_modeling.coin_config_manager import WalletsCoinConfig\n",
    "\n",
    "# Coin insights\n",
    "import coin_insights.coin_validation_analysis as civa\n",
    "import coin_insights.coin_model_reporting as cimr\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [\n",
    "    u, dr, pri, cwm, ind, fg, flt, ds, tv, prp, m, ia, exp, cffo,\n",
    "    wtdo, weo, wtd, wm, wmo, wcm,\n",
    "    wcl, wmc, wmt, wtf, wpf, wts, wsc, wbf, wmac, wfo,\n",
    "    bm, fs, bp, bsc,\n",
    "    wimr, wime, wiva, wica,\n",
    "    cfo, cwwm, cwwmf, cws,\n",
    "    cm, ceo,\n",
    "    civa, cimr,\n",
    "]\n",
    "\n",
    "# load all configs\n",
    "(\n",
    "    coin_flow_config,\n",
    "    coin_flow_metrics_config,\n",
    "    coin_flow_modeling_config,\n",
    "    coin_flow_experiments_config\n",
    ") = u.load_all_configs('../config')\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "wcm.validate_config_alignment(coin_flow_config,wallets_config,wallets_coin_config)\n",
    "\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_epochs_config = yaml.safe_load(Path('../config/wallets_epochs_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_coins_metrics_config = u.load_config('../config/wallets_coins_metrics_config.yaml')\n",
    "\n",
    "# make parquet dirs if they don't already exist\n",
    "Path(wallets_config['training_data']['parquet_folder']).mkdir(parents=True, exist_ok=True)\n",
    "Path(wallets_coin_config['training_data']['parquet_folder']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set the custom error handler\n",
    "ipython = IPython.get_ipython()\n",
    "ipython.set_custom_exc((Exception,), u.notify_on_failure)\n",
    "\n",
    "# configure logger\n",
    "logger = u.setup_notebook_logger('../logs/notebook_logs.log')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# u.export_code(\n",
    "#     code_directories=[\n",
    "#         # 'training_data',\n",
    "#         # 'wallet_modeling',\n",
    "#         # 'wallet_features',\n",
    "#         # 'coin_wallet_features',\n",
    "#         'base_modeling',\n",
    "#         'coin_modeling',\n",
    "#         # 'coin_insights',\n",
    "#         # 'wallet_insights'\n",
    "#     ],\n",
    "#     # include_config = True,\n",
    "#     # ipynb_notebook = 'DDA-769 coin model score dist toggle.ipynb'\n",
    "# )\n",
    "\n",
    "\n",
    "[importlib.reload(module) for module in modules]\n",
    "u.notify('retro')\n",
    "\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wallet Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load complete wallet datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_epochs_config = yaml.safe_load(Path('../config/wallets_epochs_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Initiate orchestrator\n",
    "epochs_orchestrator = weo.WalletEpochsOrchestrator(\n",
    "    wallets_config.config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    wallets_epochs_config\n",
    ")\n",
    "\n",
    "epochs_orchestrator.load_complete_raw_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate modeling and validation features (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "wallets_epochs_config = yaml.safe_load(Path('../config/wallets_epochs_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "parquet_folder = wallets_config['training_data']['parquet_folder']\n",
    "complete_profits_df = pd.read_parquet(f\"{parquet_folder}/complete_profits_df.parquet\")\n",
    "complete_market_data_df = pd.read_parquet(f\"{parquet_folder}/complete_market_data_df.parquet\")\n",
    "complete_macro_trends_df = pd.read_parquet(f\"{parquet_folder}/complete_macro_trends_df.parquet\")\n",
    "complete_hybrid_cw_id_df = pd.read_parquet(f\"{parquet_folder}/complete_hybrid_cw_id_df.parquet\")\n",
    "\n",
    "# Initiate orchestrator\n",
    "epochs_orchestrator = weo.WalletEpochsOrchestrator(\n",
    "    wallets_config.config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    wallets_epochs_config,\n",
    "    complete_profits_df,\n",
    "    complete_market_data_df,\n",
    "    complete_macro_trends_df,\n",
    "    complete_hybrid_cw_id_df\n",
    ")\n",
    "\n",
    "# Generate training and modeling dfs for all windows\n",
    "(wallet_training_data_df,modeling_wallet_features_df,\n",
    " validation_training_data_df,validation_wallet_features_df) = epochs_orchestrator.generate_epochs_training_data()\n",
    "\n",
    "\n",
    "# Confirm all pairs in profits_df have a hybrid mapping\n",
    "if complete_hybrid_cw_id_df is not None:\n",
    "    wtdo.validate_hybrid_mapping_completeness(wallet_training_data_df,complete_hybrid_cw_id_df)\n",
    "    if not validation_training_data_df.empty:\n",
    "        wtdo.validate_hybrid_mapping_completeness(validation_training_data_df,complete_hybrid_cw_id_df)\n",
    "\n",
    "# Save files\n",
    "wallet_training_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_wallet_training_data_df.parquet\",index=True)\n",
    "modeling_wallet_features_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_modeling_wallet_features_df.parquet\",index=True)\n",
    "validation_training_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_validation_training_data_df.parquet\",index=True)\n",
    "validation_wallet_features_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_validation_wallet_features_df.parquet\",index=True)\n",
    "\n",
    "# sorted(list(wallet_training_data_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parse columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# put features into dict and analyze list\n",
    "features_dict = {}\n",
    "features_dict['feature'] = list(wallet_training_data_df.columns)\n",
    "features_dict['importance'] = [1] * len(wallet_training_data_df.columns)\n",
    "feature_importances_df = wiva.analyze_wallet_model_importance(features_dict)\n",
    "feature_importances_df = feature_importances_df.copy()\n",
    "\n",
    "feature_categories_filter = [\n",
    "    # 'performance',\n",
    "    # 'timing',\n",
    "    # 'cw_timing',\n",
    "    'trading',\n",
    "    # 'transfers',\n",
    "    # 'mktcap',\n",
    "    # 'scenario',\n",
    "    # 'macro',\n",
    "    # 'cluster',\n",
    "]\n",
    "\n",
    "feature_names_filter = [\n",
    "    # 'price_sma_2',\n",
    "    # 'price_rsi_5',\n",
    "    # 'volume_sma_5',\n",
    "    # 'market_cap_filled',\n",
    "    # 'mktcap',\n",
    "    # 'cluster',\n",
    "    # 'btc_vdd_multiple',\n",
    "    'gtrends_memecoin_us',\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    # 'feature_category',\n",
    "    # 'feature_name',\n",
    "    # 'feature_comparison',\n",
    "    # 'feature_aggregation',\n",
    "    # 'training_segment',\n",
    "    # 'feature'\n",
    "]\n",
    "\n",
    "(feature_importances_df\n",
    " [feature_importances_df['feature_category'].isin(feature_categories_filter)]\n",
    "#  [feature_importances_df['feature_name'].isin(feature_names_filter)]\n",
    " .fillna('None')\n",
    " .groupby(groups)['importance']\n",
    " .agg(['sum', 'count'])\n",
    " .sort_values(by='sum',ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "fs.validate_drop_params(wallet_training_data_df,wallets_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct wallet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wallet model w validation (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Load modeling and validation files\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_wallet_training_data_df.parquet\")\n",
    "modeling_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_modeling_wallet_features_df.parquet\")\n",
    "validation_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_validation_training_data_df.parquet\")\n",
    "validation_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_validation_wallet_features_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_training_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(\n",
    "    wallet_training_data_df, modeling_wallet_features_df,\n",
    "    validation_training_data_df, validation_wallet_features_df\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in wallet_model_results:\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    model_id, wallet_evaluator, modeling_wallet_scores_df = wimr.generate_and_save_wallet_model_artifacts(\n",
    "        model_results=wallet_model_results,\n",
    "        base_path='../artifacts/wallet_modeling',\n",
    "        configs = {\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "            'wallets_features_config': wallets_features_config,\n",
    "            'wallets_epochs_config': wallets_epochs_config\n",
    "        }\n",
    "    )\n",
    "    wallet_evaluator.summary_report()\n",
    "    wallet_evaluator.plot_wallet_evaluation()\n",
    "else:\n",
    "    display(wallet_model.generate_search_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_wallet_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wallet model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no w1\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(\n",
    "    wallet_training_data_df, modeling_wallet_features_df,\n",
    "    validation_training_data_df, validation_wallet_features_df\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in wallet_model_results:\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    model_id, wallet_evaluator, modeling_wallet_scores_df = wimr.generate_and_save_wallet_model_artifacts(\n",
    "        model_results=wallet_model_results,\n",
    "        base_path='../artifacts/wallet_modeling',\n",
    "        configs = {\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "            'wallets_features_config': wallets_features_config,\n",
    "            'wallets_epochs_config': wallets_epochs_config\n",
    "        }\n",
    "    )\n",
    "    wallet_evaluator.summary_report()\n",
    "    wallet_evaluator.plot_wallet_evaluation()\n",
    "else:\n",
    "    display(wallet_model.generate_search_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(\n",
    "    wallet_training_data_df, modeling_wallet_features_df,\n",
    "    validation_training_data_df, validation_wallet_features_df\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in wallet_model_results:\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    model_id, wallet_evaluator, modeling_wallet_scores_df = wimr.generate_and_save_wallet_model_artifacts(\n",
    "        model_results=wallet_model_results,\n",
    "        base_path='../artifacts/wallet_modeling',\n",
    "        configs = {\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "            'wallets_features_config': wallets_features_config,\n",
    "            'wallets_epochs_config': wallets_epochs_config\n",
    "        }\n",
    "    )\n",
    "    wallet_evaluator.summary_report()\n",
    "    wallet_evaluator.plot_wallet_evaluation()\n",
    "else:\n",
    "    display(wallet_model.generate_search_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wallet model without validation (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Load modeling files\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_wallet_training_data_df.parquet\")\n",
    "modeling_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_modeling_wallet_features_df.parquet\")\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(\n",
    "    wallet_training_data_df, modeling_wallet_features_df\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in wallet_model_results:\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    model_id, wallet_evaluator, modeling_wallet_scores_df = wimr.generate_and_save_wallet_model_artifacts(\n",
    "        model_results=wallet_model_results,\n",
    "        base_path='../artifacts/wallet_modeling',\n",
    "        configs = {\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "            'wallets_features_config': wallets_features_config\n",
    "        }\n",
    "    )\n",
    "    wallet_evaluator.summary_report()\n",
    "else:\n",
    "    display(wallet_model.generate_search_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save individual scores for modeling and coin_modeling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "score_name = wallets_config['modeling']['score_name']\n",
    "base_path = wallets_config['training_data']['model_artifacts_folder']\n",
    "\n",
    "# model_id = '8e55189e-a040-4b68-9d69-83c3f95ee652'\n",
    "score_name = 'dda528_net_gain_max_inv_025'\n",
    "\n",
    "# Load and predict\n",
    "wamo_training_data_df = pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}\"\n",
    "                                        \"/wamo_training_data_df.parquet\")\n",
    "wamo_y_pred = wiva.load_and_predict(model_id,wamo_training_data_df,base_path)\n",
    "wamo_wallet_scores_df = pd.DataFrame({\n",
    "    f'score|{score_name}': wamo_y_pred\n",
    "})\n",
    "wamo_wallet_scores_df.to_parquet(f\"temp/wallet_modeling_score_dfs/{score_name}|wamo.parquet\",index=True)\n",
    "\n",
    "# Load and predict\n",
    "como_training_data_df = pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}\"\n",
    "                                             \"/como_training_data_df.parquet\")\n",
    "como_y_pred = wiva.load_and_predict(model_id,como_training_data_df,base_path)\n",
    "como_wallet_scores_df = pd.DataFrame({\n",
    "    f'score|{score_name}': como_y_pred\n",
    "})\n",
    "como_wallet_scores_df.to_parquet(f\"temp/wallet_modeling_score_dfs/{score_name}|como.parquet\",index=True)\n",
    "\n",
    "u.notify(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict training data with existing model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "base_path = wallets_config['training_data']['model_artifacts_folder']\n",
    "model_id = '85e79c0e-c6a6-4514-97bb-277b945086fd'\n",
    "score_name = 'dda785_net_flows'\n",
    "\n",
    "# Load and predict\n",
    "training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}\"\n",
    "                                        \"/multiwindow_wallet_training_data_df.parquet\")\n",
    "y_pred = wiva.load_and_predict(model_id,training_data_df,base_path)\n",
    "wallet_scores_df = pd.DataFrame({\n",
    "    'score': y_pred\n",
    "})\n",
    "\n",
    "wallet_scores_df = wtdo.dehybridize_wallet_address(wallet_scores_df,complete_hybrid_cw_id_df)\n",
    "wallet_scores_df = wallet_scores_df.reset_index()\n",
    "wallet_scores_df['model_id'] = model_id\n",
    "wallet_scores_df['scored_at'] = datetime.now()\n",
    "wallet_scores_df['model_type'] = wallets_config['modeling']['model_type']\n",
    "wallet_scores_df['target_var'] = wallets_config['modeling']['target_variable']\n",
    "wallet_scores_df['target_var_threshold'] = wallets_config['modeling']['target_var_min_threshold']\n",
    "\n",
    "\n",
    "table_name = f\"wallets_{datetime.now().strftime('%Y%m%d_%Hh%Mm%Ss')}_{wallets_config['modeling']['target_variable'].replace('/','_')}\"\n",
    "\n",
    "\n",
    "# Basic syntax\n",
    "pandas_gbq.to_gbq(\n",
    "    dataframe=wallet_scores_df,\n",
    "    destination_table=f'scores.{table_name}',\n",
    "    project_id='western-verve-411004',\n",
    "    if_exists='fail'  # Options: 'fail', 'replace', or 'append'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "complete_hybrid_cw_id_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}\"\n",
    "                                        \"/complete_hybrid_cw_id_df.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values_present = complete_hybrid_cw_id_df['hybrid_cw_id'].isin(wallet_scores_df.index.get_level_values('wallet_address')).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_scores_df.index.get_level_values('wallet_address').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xw_ids = set(complete_hybrid_cw_id_df['hybrid_cw_id'].astype(int))\n",
    "scores_ids = set(wallet_scores_df.index.get_level_values('wallet_address').astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xw_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ids - xw_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xw_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = complete_hybrid_cw_id_df['hybrid_cw_id'][~complete_hybrid_cw_id_df['hybrid_cw_id'].isin(wallet_scores_df.index.get_level_values('wallet_address'))]\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_scores_df.index.get_level_values('wallet_address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtdo.dehybridize_wallet_address(wallet_scores_df,complete_hybrid_cw_id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_scores_df = wallet_scores_df.reset_index().rename(columns={'wallet_address': 'hybrid_cw_id'})\n",
    "wallet_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_scores_df.merge(complete_hybrid_cw_id_df,on='hybrid_cw_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wallet_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wallet_scores_df\n",
    "hybrid_cw_id_df = complete_hybrid_cw_id_df\n",
    "\n",
    "logger.info(\"De‑hybridizing DataFrame with shape %s …\", df.shape)\n",
    "df_out = df.copy()\n",
    "original_index = df_out.index.names\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Detect where the hybrid IDs live and rename the\n",
    "# column/index level to *hybrid_cw_id* so we can\n",
    "# merge cleanly without duplicate label errors.\n",
    "# -------------------------------------------------\n",
    "if 'wallet_address' in df_out.columns:\n",
    "    # Column case → rename in‑place\n",
    "    df_out = df_out.rename(columns={'wallet_address': 'hybrid_cw_id'})\n",
    "    wallet_col = 'hybrid_cw_id'\n",
    "    used_index = False\n",
    "\n",
    "elif 'wallet_address' in df_out.index.names:\n",
    "    # Index case → bring into columns, then rename\n",
    "    # Drop any duplicate column first to avoid reset_index collision\n",
    "    if 'wallet_address' in df_out.columns:\n",
    "        df_out = df_out.drop(columns=['wallet_address'])\n",
    "\n",
    "    df_out = df_out.reset_index()\n",
    "    df_out = df_out.rename(columns={'wallet_address': 'hybrid_cw_id'})\n",
    "    wallet_col = 'hybrid_cw_id'\n",
    "    used_index = True\n",
    "\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"dehybridize_wallet_address: expected 'wallet_address' either as \"\n",
    "        \"a column or an index level containing hybrid IDs.\"\n",
    "    )\n",
    "\n",
    "# Merge to add wallet_id + coin_id\n",
    "df_out = df_out.merge(hybrid_cw_id_df, on=wallet_col, how='left')\n",
    "\n",
    "# Verify mapping completeness\n",
    "if df_out['wallet_id'].isna().any():\n",
    "    missing = df_out['wallet_id'].isna().sum()\n",
    "    raise ValueError(\n",
    "        f\"Failed to de‑hybridize {missing} rows – missing hybrid_cw_id \"\n",
    "        \"mappings.\"\n",
    "    )\n",
    "\n",
    "# Replace hybrid id with original wallet_id and rename for consistency\n",
    "df_out['wallet_address'] = df_out['wallet_id']\n",
    "df_out = df_out.drop(columns=['wallet_id', 'hybrid_cw_id'])\n",
    "\n",
    "# Restore original index structure\n",
    "if used_index:\n",
    "    # Re‑establish MultiIndex (wallet_address, coin_id, [other …])\n",
    "    df_out = df_out.set_index(\n",
    "        ['wallet_address', 'coin_id'] +\n",
    "        [col for col in original_index if col not in ('wallet_address', 'coin_id')]\n",
    "    )\n",
    "else:\n",
    "    # Ensure wallet_address & coin_id are regular columns\n",
    "    pass  # nothing required\n",
    "\n",
    "logger.info(\"Completed de‑hybridization; resulting shape %s.\", df_out.shape)\n",
    "# return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load evaluation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "model_id = '3493a19d-0ee3-4272-ab52-40afc6ab6d1b'\n",
    "base_path = wallets_config['training_data']['model_artifacts_folder']\n",
    "configs_output = 'temp/configs_revival/dda_691_3493a19d'\n",
    "\n",
    "report = wimr.load_model_report(model_id, base_path, configs_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_evaluator.importance_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Reload evaluator\n",
    "wallet_evaluator = wime.ClassifierEvaluator(wallet_model_results)\n",
    "\n",
    "feature_importances_df = wiva.analyze_wallet_model_importance(wallet_evaluator.metrics['importances'])\n",
    "feature_importances_df = feature_importances_df.copy()\n",
    "\n",
    "feature_categories_filter = [\n",
    "    # 'performance',\n",
    "    # 'cw_timing',\n",
    "    # 'trading',\n",
    "    # 'transfers',\n",
    "    # 'cw_mktcap',\n",
    "    # 'scenario',\n",
    "    # 'macro',\n",
    "    # 'cluster',\n",
    "]\n",
    "\n",
    "feature_names_filter = [\n",
    "    # 'price_sma_2',\n",
    "    # 'price_rsi_5',\n",
    "    # 'volume_sma_5',\n",
    "    # 'market_cap_filled',\n",
    "    # 'mktcap',\n",
    "    # 'cluster',\n",
    "    # 'portfolio_mcap_max',\n",
    "    # 'crypto_net_flows',\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    # 'feature_category',\n",
    "    # 'feature_name',\n",
    "    # 'feature_comparison',\n",
    "    # 'feature_aggregation',\n",
    "    'training_segment',\n",
    "    # 'feature'\n",
    "]\n",
    "\n",
    "(feature_importances_df\n",
    "#  [feature_importances_df['feature_category'].isin(feature_categories_filter)]\n",
    "#  [feature_importances_df['feature_name'].isin(feature_names_filter)]\n",
    " .fillna('None')\n",
    " .groupby(groups)['importance']\n",
    " .agg(['sum', 'count'])\n",
    " .sort_values(by='sum',ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict validation data with existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'bfa55a33-712e-4d82-bb5c-11fc942bcb62'\n",
    "validation_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}\"\n",
    "                                              \"/multiwindow_validation_training_data_df.parquet\")\n",
    "\n",
    "validation_y_pred = wiva.load_and_predict(\n",
    "    model_id,\n",
    "    validation_training_data_df,\n",
    "    wallets_config['training_data']['model_artifacts_folder']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_validation_wallet_features_df.parquet\")\n",
    "\n",
    "validation_y_true = validation_wallet_features_df[wallets_config['modeling']['target_variable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    log_loss,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "def evaluate_classification(y_true: pd.Series, y_prob: pd.Series, threshold: float = 0.0) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate metrics for binary classification based on continuous values.\n",
    "\n",
    "    Params:\n",
    "    - y_true (Series): Actual continuous values.\n",
    "    - y_prob (Series): Predicted continuous values.\n",
    "    - threshold (float): Threshold for converting to binary. Default 0.0.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Core performance metrics computed on overlapping ids.\n",
    "    \"\"\"\n",
    "    # Identify common ids between y_true and y_prob\n",
    "    common_idx = y_true.index.intersection(y_prob.index)\n",
    "    if len(common_idx) == 0:\n",
    "        raise ValueError(\"No overlapping ids between y_true and y_prob\")\n",
    "\n",
    "    # Filter to only overlapping ids\n",
    "    y_true_common = y_true.loc[common_idx].values\n",
    "    y_prob_common = y_prob.loc[common_idx].values\n",
    "\n",
    "    # Convert continuous values to binary for classification metrics\n",
    "    y_true_binary = (y_true_common > threshold).astype(int)\n",
    "    y_pred_binary = (y_prob_common > threshold).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true_binary, y_pred_binary),\n",
    "        'precision': precision_score(y_true_binary, y_pred_binary),\n",
    "        'recall': recall_score(y_true_binary, y_pred_binary),\n",
    "        'f1': f1_score(y_true_binary, y_pred_binary),\n",
    "        'confusion_matrix': confusion_matrix(y_true_binary, y_pred_binary).tolist(),\n",
    "        'mse': mean_squared_error(y_true_common, y_prob_common),\n",
    "        'mae': mean_absolute_error(y_true_common, y_prob_common)\n",
    "    }\n",
    "\n",
    "    # Add ROC AUC if we have both positive and negative classes\n",
    "    if len(np.unique(y_true_binary)) > 1:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_true_binary, y_prob_common)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "evaluate_classification(validation_y_true,validation_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assess segment performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "pd.set_option('display.max_colwidth', None)  # Shows full text in columns\n",
    "\n",
    "\n",
    "# Reload evaluator\n",
    "if wallet_model_results['model_type'] == 'regression':\n",
    "    wallet_evaluator = wime.RegressorEvaluator(wallet_model_results)\n",
    "else:\n",
    "    wallet_evaluator = wime.ClassifierEvaluator(wallet_model_results)\n",
    "\n",
    "segmentation_features = [\n",
    "    # 'mktcap|portfolio_mcap_mean/market_cap_unadj|all_windows',\n",
    "    'mktcap|volume_wtd_market_cap/market_cap_filled|all_windows',\n",
    "    # 'timing|btc_mvrv_z_score/buy_weighted|all_windows',\n",
    "    # 'timing|btc_mvrv_z_score/sell_weighted|all_windows',\n",
    "    # 'macro|btc_mvrv_z_score_first|all_windows',\n",
    "    # 'macro|btc_mvrv_z_score_last|all_windows',\n",
    "    'trading|crypto_net_gain|all_windows',\n",
    "    'trading|total_volume|all_windows',\n",
    "    'trading|crypto_net_cash_flows|all_windows',\n",
    "    'trading|unique_coins_traded|all_windows',\n",
    "    # 'transfers|first_buy/median_avg_wallet_rank|all_windows',\n",
    "    'trading|max_investment|all_windows'\n",
    "]\n",
    "segmentation_features = [\n",
    "    # 'mktcap|portfolio_mcap_mean/market_cap_unadj|w5',\n",
    "    'mktcap|volume_wtd_market_cap/market_cap_filled|w5',\n",
    "    # 'timing|btc_mvrv_z_score/buy_weighted|w5',\n",
    "    # 'timing|btc_mvrv_z_score/sell_weighted|w5',\n",
    "    # 'macro|btc_mvrv_z_score_first|w5',\n",
    "    # 'macro|btc_mvrv_z_score_last|w5',\n",
    "    'trading|crypto_net_gain|w5',\n",
    "    'trading|total_volume|w5',\n",
    "    'trading|crypto_net_cash_flows|w5',\n",
    "    'trading|unique_coins_traded|w5',\n",
    "    # 'transfers|first_buy/median_avg_wallet_rank|w5',\n",
    "    'trading|max_investment|w5'\n",
    "]\n",
    "\n",
    "\n",
    "# get raw segments\n",
    "segments_df = wallet_evaluator.identify_predictive_populations(\n",
    "    segmentation_features,\n",
    "    min_pop_pct=0.02,\n",
    "    max_segments=25\n",
    ")\n",
    "\n",
    "# coerce the formatted strings to numbers, then sort\n",
    "# segments_df.sort_values('RMSE vs Overall', ascending=True)\n",
    "segments_df.sort_values('R2 vs Overall', ascending=False)\n",
    "# segments_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modeling multi window r2 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = sorted(list(modeling_wallet_scores_df.index.get_level_values('epoch_start_date').unique()))\n",
    "\n",
    "for epoch in epochs:\n",
    "    epoch_mask = modeling_wallet_scores_df.index.get_level_values('epoch_start_date') == epoch\n",
    "    # Add cohort filter\n",
    "    cohort_mask = modeling_wallet_scores_df['in_modeling_cohort'] == True\n",
    "    combined_mask = epoch_mask & cohort_mask\n",
    "\n",
    "    y_true = modeling_wallet_scores_df[combined_mask]['actual']\n",
    "    y_pred = modeling_wallet_scores_df[combined_mask]['score']\n",
    "\n",
    "    # Skip epochs with no actual values\n",
    "    if y_true.isna().all():\n",
    "        continue\n",
    "\n",
    "    metrics = wiva.evaluate_predictions(y_true, y_pred)\n",
    "    print(f\"Epoch {epoch}: R² = {metrics['r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Load parquet\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\")\n",
    "\n",
    "\n",
    "# List of the x features with the highest importance in the model\n",
    "x_features = 6\n",
    "top_feature_metrics = list((pd.DataFrame(wallet_evaluator.metrics['importances'])\n",
    "                      .sort_values(by='importance',ascending=False)\n",
    "                      .head(x_features)['feature']))\n",
    "comparison_metrics = list(set(top_feature_metrics))\n",
    "\n",
    "\n",
    "\n",
    "# Cluster numbers\n",
    "n_clusters=4\n",
    "\n",
    "styled_df,cluster_results_df = wica.create_cluster_report(wallet_training_data_df, wallet_model_results, n_clusters, comparison_metrics, 'median')\n",
    "\n",
    "del(wallet_training_data_df)\n",
    "gc.collect()\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_df = wallet_training_data_df.copy()\n",
    "\n",
    "base_metrics = [\n",
    "    'trading|max_investment|all_windows',\n",
    "    'trading|crypto_net_gain|all_windows',\n",
    "    'mktcap|end_portfolio_wtd_market_cap|all_windows',\n",
    "    'performance|crypto_net_gain/max_investment/base|all_windows',\n",
    "]\n",
    "cluster_cols = [col for col in modeling_df.columns if col.startswith('cluster|')]\n",
    "cluster_analysis_df = modeling_df[list(set(cluster_cols + base_metrics + comparison_metrics))].copy()\n",
    "\n",
    "\n",
    "# Assign wallets to categorical clusters based on the distance values\n",
    "cluster_assignments_df = wcl.assign_clusters_from_distances(cluster_analysis_df,\n",
    "                                                        wallets_config['features']['clustering_n_clusters'])\n",
    "# cluster_analysis_df = cluster_analysis_df.join(cluster_assignments_df,how='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cluster_analysis_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coin Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin model training data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pull all data and generate all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "\n",
    "# Initiate orchestrator\n",
    "coin_epochs_orchestrator = ceo.CoinEpochsOrchestrator(\n",
    "    wallets_coin_config,\n",
    "    wallets_coins_metrics_config,\n",
    "    wallets_config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    wallets_epochs_config,\n",
    "    coin_flow_config,\n",
    "    coin_flow_modeling_config,\n",
    "    coin_flow_metrics_config\n",
    ")\n",
    "\n",
    "coin_epochs_orchestrator.load_complete_raw_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Initiate orchestrator\n",
    "coin_epochs_orchestrator = ceo.CoinEpochsOrchestrator(\n",
    "    wallets_coin_config,\n",
    "    wallets_coins_metrics_config,\n",
    "    wallets_config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    wallets_epochs_config,\n",
    "    coin_flow_config,\n",
    "    coin_flow_modeling_config,\n",
    "    coin_flow_metrics_config\n",
    ")\n",
    "\n",
    "coin_epochs_orchestrator.load_complete_raw_datasets()\n",
    "\n",
    "coin_epochs_orchestrator.orchestrate_coin_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dda 741 devspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_offset_days = [\n",
    "    # 30,\n",
    "    # 60,\n",
    "    # 90,\n",
    "\n",
    "    120,\n",
    "    150,\n",
    "    180,\n",
    "\n",
    "    # 210,\n",
    "    # 240,\n",
    "    # 270\n",
    "\n",
    "    # 0,\n",
    "    # -30,\n",
    "    # -60,\n",
    "]\n",
    "# file_prefix='investing_'\n",
    "file_prefix='investing_val'\n",
    "\n",
    "coin_epochs_orchestrator.orchestrate_coin_epochs(\n",
    "    custom_offset_days,\n",
    "    file_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "model_id = 'bb10db73-1fda-4141-b9ca-64716b41db00'\n",
    "\n",
    "file_prefix='investing_val'\n",
    "parquet_folder = wallets_coin_config['training_data']['parquet_folder']\n",
    "como_features_df = pd.read_parquet(f\"{parquet_folder}/{file_prefix}multiwindow_como_coin_training_data_df_full.parquet\")\n",
    "como_target_var_df = pd.read_parquet(f\"{parquet_folder}/{file_prefix}multiwindow_como_coin_target_var_df.parquet\")\n",
    "\n",
    "# Create a list of the current index level dtypes\n",
    "idx_dtypes = list(como_target_var_df.index.dtypes)\n",
    "# Convert only the coin_id level (assuming it's the first level)\n",
    "como_target_var_df.index = como_target_var_df.index.set_levels(\n",
    "    como_target_var_df.index.levels[0].astype(str),\n",
    "    level=0\n",
    ")\n",
    "\n",
    "como_scores_df = coin_epochs_orchestrator.score_coin_training_data(\n",
    "    model_id,\n",
    "    '../artifacts/coin_modeling',\n",
    "    como_features_df,\n",
    ")\n",
    "como_scores_df.describe()\n",
    "plot_return_vs_rank(como_scores_df['score'],como_target_var_df['coin_return_winsorized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "model_id = 'cd4fe30a-dae6-4bd5-aac8-51b9d03030cd'\n",
    "\n",
    "file_prefix='investing_val'\n",
    "parquet_folder = wallets_coin_config['training_data']['parquet_folder']\n",
    "como_features_df = pd.read_parquet(f\"{parquet_folder}/{file_prefix}multiwindow_como_coin_training_data_df_full.parquet\")\n",
    "como_target_var_df = pd.read_parquet(f\"{parquet_folder}/{file_prefix}multiwindow_como_coin_target_var_df.parquet\")\n",
    "\n",
    "# Create a list of the current index level dtypes\n",
    "idx_dtypes = list(como_target_var_df.index.dtypes)\n",
    "# Convert only the coin_id level (assuming it's the first level)\n",
    "como_target_var_df.index = como_target_var_df.index.set_levels(\n",
    "    como_target_var_df.index.levels[0].astype(str),\n",
    "    level=0\n",
    ")\n",
    "\n",
    "como_scores_df = coin_epochs_orchestrator.score_coin_training_data(\n",
    "    model_id,\n",
    "    '../artifacts/coin_modeling',\n",
    "    como_features_df,\n",
    ")\n",
    "como_scores_df.describe()\n",
    "plot_return_vs_rank(como_scores_df['score'],como_target_var_df['coin_return_winsorized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_return_vs_rank(y_pred_proba: pd.Series, target_variable: pd.Series,\n",
    "                        ax=None, n_buckets: int = 10):\n",
    "    \"\"\"\n",
    "    Plot histogram of prediction probabilities and returns by probability bins.\n",
    "\n",
    "    Params:\n",
    "    - y_pred_proba (Series): Prediction probabilities with wallet indices\n",
    "    - target_variable (Series): Actual returns with matching wallet indices\n",
    "    - ax (matplotlib.axes): Optional axes to plot on, creates one if None\n",
    "    - n_buckets (int): Number of probability buckets to divide data into\n",
    "\n",
    "    Returns:\n",
    "    - ax (matplotlib.axes): The axes with the plotted data\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import textwrap\n",
    "\n",
    "    # Create axes if not provided\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Align data using indices\n",
    "    returns = target_variable.reindex(y_pred_proba.index)\n",
    "\n",
    "    # Winsorize returns (cap outliers)\n",
    "    def winsorize(series, limit):\n",
    "        lower = series.quantile(limit)\n",
    "        upper = series.quantile(1 - limit)\n",
    "        return series.clip(lower=lower, upper=upper)\n",
    "\n",
    "    returns_winsorized = winsorize(returns, 0.01)\n",
    "\n",
    "    # Create dataframe for analysis\n",
    "    df = pd.DataFrame({\n",
    "        \"proba\": y_pred_proba,\n",
    "        \"ret\": returns,\n",
    "        \"ret_win\": returns_winsorized\n",
    "    }).dropna()\n",
    "\n",
    "    # Define score bins\n",
    "    try:\n",
    "        score_min, score_max = df[\"proba\"].min(), df[\"proba\"].max()\n",
    "        bin_edges = np.linspace(score_min, score_max, n_buckets + 1)\n",
    "        df[\"score_bin\"] = pd.cut(df[\"proba\"], bins=bin_edges, include_lowest=True)\n",
    "    except ValueError:\n",
    "        ax.text(0.5, 0.5, 'Insufficient score spread to generate bins.',\n",
    "                ha='center', va='center')\n",
    "        return ax\n",
    "\n",
    "    # Compute stats per bin\n",
    "    bin_counts = df.groupby(\"score_bin\", observed=True).size()\n",
    "    bin_mean_ret = df.groupby(\"score_bin\", observed=True)[\"ret\"].mean()\n",
    "    bin_median_ret = df.groupby(\"score_bin\", observed=True)[\"ret\"].median()\n",
    "    bin_winsorized_ret = df.groupby(\"score_bin\", observed=True)[\"ret_win\"].mean()\n",
    "\n",
    "    # Drop bins with zero count\n",
    "    valid_bins = bin_counts[bin_counts > 0]\n",
    "    valid_centers = [\n",
    "        interval.left + (interval.right - interval.left) / 2\n",
    "        for interval in valid_bins.index\n",
    "    ]\n",
    "    valid_counts = valid_bins.values\n",
    "    valid_mean_ret = bin_mean_ret.reindex(valid_bins.index).values\n",
    "    valid_median_ret = bin_median_ret.reindex(valid_bins.index).values\n",
    "    valid_winsorized_ret = bin_winsorized_ret.reindex(valid_bins.index).values\n",
    "    width = bin_edges[1] - bin_edges[0]\n",
    "\n",
    "    # Primary axis: histogram of counts\n",
    "    ax.bar(valid_centers, valid_counts, width=width, alpha=0.6, label=\"Count\")\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    # Secondary axis: return lines\n",
    "    ax2 = ax.twinx()\n",
    "    abs_returns = np.abs(df[\"ret\"])\n",
    "    linthresh = np.percentile(abs_returns, 95)\n",
    "    if linthresh <= 0:\n",
    "        max_abs = abs_returns.max()\n",
    "        linthresh = max_abs * 0.05 if max_abs > 0 else 1.0\n",
    "    ax2.set_yscale(\"linear\")\n",
    "\n",
    "    # Plot return metrics\n",
    "    ax2.plot(valid_centers, valid_median_ret, marker='o', linestyle='-',\n",
    "             linewidth=2, label=\"Median Return\", color=\"#8000ff\")\n",
    "    ax2.plot(valid_centers, valid_winsorized_ret, marker='o', linestyle='-',\n",
    "             linewidth=2, label=\"Winsorized Return\", color=\"#ffe000\")\n",
    "    ax2.plot(valid_centers, valid_mean_ret, marker='o', linestyle='-',\n",
    "             linewidth=2, label=\"Mean Return\", color=\"#22DD22\")\n",
    "\n",
    "    # Overall mean return line\n",
    "    overall_mean = df[\"ret\"].mean()\n",
    "    ax2.axhline(overall_mean, linestyle=\"--\", color=\"#afc6ba\",\n",
    "                linewidth=1, label=\"Overall mean return\")\n",
    "\n",
    "    # Annotate extremes of winsorized returns\n",
    "    if len(bin_winsorized_ret) > 0:\n",
    "        low_interval = bin_winsorized_ret.idxmin()\n",
    "        high_interval = bin_winsorized_ret.idxmax()\n",
    "        x_low = (low_interval.left + low_interval.right) / 2\n",
    "        x_high = (high_interval.left + high_interval.right) / 2\n",
    "        y_low = bin_winsorized_ret.loc[low_interval]\n",
    "        y_high = bin_winsorized_ret.loc[high_interval]\n",
    "        ax2.annotate(f\"{y_low:.2f}\", xy=(x_low, y_low),\n",
    "                     xytext=(0, -10), textcoords=\"offset points\",\n",
    "                     ha=\"center\", va=\"top\")\n",
    "        ax2.annotate(f\"{y_high:.2f}\", xy=(x_high, y_high),\n",
    "                     xytext=(0, 10), textcoords=\"offset points\",\n",
    "                     ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(\"Prediction Score\")\n",
    "    ax.set_ylabel(\"Number of Wallets\")\n",
    "    label = \"Target Variable Returns\"\n",
    "    wrapped_label = \"\\n\".join(textwrap.wrap(label, width=30))\n",
    "    ax2.set_ylabel(wrapped_label)\n",
    "    ax.set_title(\"Prediction Score Distribution and Returns\")\n",
    "    ax.grid(True, linestyle=\":\", alpha=0.3)\n",
    "\n",
    "    # Combine legends from both axes\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(lines + lines2, labels + labels2, loc=\"upper left\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stepwise coin model generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train all models and save all scores (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiwindow modeling and validation files\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_wallet_training_data_df.parquet\")\n",
    "modeling_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_modeling_wallet_features_df.parquet\")\n",
    "validation_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_validation_training_data_df.parquet\")\n",
    "validation_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/multiwindow_validation_wallet_features_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Instantiate orchestrator\n",
    "model_orchestrator = wmo.WalletModelOrchestrator(\n",
    "        wallets_config.config,\n",
    "        wallets_metrics_config,\n",
    "        wallets_features_config,\n",
    "        wallets_epochs_config,\n",
    "        wallets_coin_config.config\n",
    ")\n",
    "\n",
    "# Train all models\n",
    "models_dict = model_orchestrator.train_wallet_models(\n",
    "    wallet_training_data_df,\n",
    "    modeling_wallet_features_df,\n",
    "    validation_training_data_df,\n",
    "    validation_wallet_features_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load or generate training data dfs (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create wallet model training data for dates through the end of the original modeling period.\n",
    "# This will be used to create \"current\" scores as of the end of the modeling period, that can be\n",
    "# used to generate features for the \"current\" coin model built at the end of the modeling period.\n",
    "\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_epochs_config = yaml.safe_load(Path('../config/wallets_epochs_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "complete_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_profits_df.parquet\")\n",
    "complete_market_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_market_data_df.parquet\")\n",
    "complete_macro_trends_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_macro_trends_df.parquet\")\n",
    "\n",
    "# Identify offset needed to generate training data directly following the modeling period to the validation period start\n",
    "modeling_offset = wallets_config['training_data']['modeling_period_duration']\n",
    "coin_modeling_epochs_config = {\n",
    "    'offset_epochs': {\n",
    "        'offsets': [modeling_offset],\n",
    "        'validation_offsets': [modeling_offset*2]\n",
    "    }\n",
    "}\n",
    "# Initiate orchestrator\n",
    "epochs_orchestrator = weo.WalletEpochsOrchestrator(\n",
    "    wallets_config.config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    coin_modeling_epochs_config,\n",
    "    complete_profits_df,\n",
    "    complete_market_data_df,\n",
    "    complete_macro_trends_df\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Save files\n",
    "wamo_training_data_df.to_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}/wamo_training_data_df.parquet\",index=True)\n",
    "wamo_modeling_data_df.to_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}/wamo_modeling_data_df.parquet\",index=True)\n",
    "como_training_data_df.to_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}/como_training_data_df.parquet\",index=True)\n",
    "como_modeling_data_df.to_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}/como_modeling_data_df.parquet\",index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### generate and save scores for all models (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Score training data with all models\n",
    "wamo_training_data_df = pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}\"\n",
    "                                        \"/wamo_training_data_df.parquet\")\n",
    "\n",
    "# Instantiate orchestrator\n",
    "model_orchestrator = wmo.WalletModelOrchestrator(\n",
    "        wallets_config,\n",
    "        wallets_metrics_config,\n",
    "        wallets_features_config,\n",
    "        wallets_epochs_config,\n",
    "        wallets_coin_config\n",
    ")\n",
    "# Load dict\n",
    "with open(f\"{wallets_coin_config['training_data']['parquet_folder']}/wallet_model_ids.json\") as f:\n",
    "    models_dict = json.load(f)\n",
    "\n",
    "model_orchestrator.predict_and_store(models_dict,wamo_training_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature generation for predicting coin modeling period outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load wallet modeling period files (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "wamo_training_data_df= pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}/wamo_training_data_df.parquet\")\n",
    "wamo_modeling_data_df= pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}/wamo_modeling_data_df.parquet\")\n",
    "como_training_data_df= pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}/como_training_data_df.parquet\")\n",
    "como_modeling_data_df= pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}/como_modeling_data_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "(training_coin_cohort, wamo_profits_df, como_market_data_df, como_profits_df, investing_market_data_df\n",
    "    ) = cfo.load_wallet_data_for_coin_features(wallets_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### generate all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "features_generator = cfo.CoinFeaturesOrchestrator(\n",
    "    wallets_config,\n",
    "    wallets_coin_config,\n",
    "    metrics_config,\n",
    "    config,\n",
    "    modeling_config,\n",
    "    training_coin_cohort\n",
    ")\n",
    "\n",
    "# Feature generation for training data set\n",
    "wamo_modeling_suffix = pd.to_datetime(wallets_config['training_data']['coin_modeling_period_start']).strftime('%Y%m%d')\n",
    "wamo_coin_training_data_df_full = features_generator.generate_coin_features_for_period(\n",
    "    wamo_profits_df,\n",
    "    wamo_training_data_df,\n",
    "    'modeling',\n",
    "    wamo_modeling_suffix\n",
    ")\n",
    "\n",
    "# Feature gene ration for validation set\n",
    "como_coin_training_data_df_full = features_generator.generate_coin_features_for_period(\n",
    "    como_profits_df,\n",
    "    como_training_data_df,\n",
    "    'coin_modeling',\n",
    "    wamo_modeling_suffix  # predict validation outcomes with the same model\n",
    ")\n",
    "\n",
    "wamo_coin_training_data_df_full.to_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}\"\n",
    "                                           \"/wamo_coin_training_data_df_full.parquet\",index=True)\n",
    "como_coin_training_data_df_full.to_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}\"\n",
    "                                          \"/como_coin_training_data_df_full.parquet\",index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### target vars (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Load data\n",
    "wamo_coin_training_data_df_full = pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}\"\n",
    "                                           \"/wamo_coin_training_data_df_full.parquet\")\n",
    "como_coin_training_data_df_full = pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}\"\n",
    "                                          \"/como_coin_training_data_df_full.parquet\")\n",
    "(training_coin_cohort, wamo_profits_df, como_market_data_df, como_profits_df, investing_market_data_df\n",
    "    ) = cfo.load_wallet_data_for_coin_features(wallets_config)\n",
    "\n",
    "\n",
    "# Instantiate orchestrator\n",
    "features_generator = cfo.CoinFeaturesOrchestrator(\n",
    "    wallets_config,\n",
    "    wallets_coin_config,\n",
    "    metrics_config,\n",
    "    config,\n",
    "    modeling_config,\n",
    "    training_coin_cohort\n",
    ")\n",
    "\n",
    "# Target var for wallet modeling period is performance during the coin modeling period\n",
    "wamo_coin_target_var_df = features_generator.calculate_target_variables(\n",
    "    como_market_data_df,\n",
    "    wallets_config['training_data']['coin_modeling_period_start'],\n",
    "    wallets_config['training_data']['coin_modeling_period_end'],\n",
    "    set(wamo_coin_training_data_df_full.index)\n",
    ")\n",
    "\n",
    "\n",
    "# Target var for coin modeling period is performance during the investing period\n",
    "como_coin_target_var_df = features_generator.calculate_target_variables(\n",
    "    investing_market_data_df,\n",
    "    wallets_config['training_data']['investing_period_start'],\n",
    "    wallets_config['training_data']['investing_period_end'],\n",
    "    set(como_coin_training_data_df_full.index)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List all cols\n",
    "wamo_coin_training_data_df_full = pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}\"\n",
    "                                                  \"/multiwindow_wamo_coin_training_data_df_full.parquet\")\n",
    "list(wamo_coin_training_data_df_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "\n",
    "\n",
    "# Load df\n",
    "# Create dataframe of column names\n",
    "df = pd.DataFrame(wamo_coin_training_data_df_full.columns)\n",
    "df.columns = ['feature']\n",
    "feature_details_df = cfo.parse_feature_names(df)\n",
    "\n",
    "# Select features\n",
    "segment_category_filter = [\n",
    "    # 'all_wallets',\n",
    "    # 'score_quantile',\n",
    "    # 'score_binary',\n",
    "    # 'training_clusters',\n",
    "    # 'time_series',\n",
    "    # 'wallet_cohorts',\n",
    "    'macro',\n",
    "]\n",
    "segment_family_filter = [\n",
    "    # 'all',\n",
    "    # 'cw_return_rate_min_025',\n",
    "    'global_market_cap',\n",
    "    'btc_mvrv_z_score',\n",
    "    'btc_price',\n",
    "    # 'wallet_cohorts',\n",
    "]\n",
    "metric_filter = [\n",
    "    # 'trading',\n",
    "    'balances',\n",
    "]\n",
    "metric_detail_filter = [\n",
    "    # 'crypto_net_gain',\n",
    "    'usd_balance_ending',\n",
    "]\n",
    "transformation_category_filter = [\n",
    "    # 'aggregations',\n",
    "    'score_wtd',\n",
    "    # 'score_dist',\n",
    "]\n",
    "transformation_base_filter = [\n",
    "    'cw_return_rate_min_000_score',\n",
    "]\n",
    "transformation_method_filter = [\n",
    "    # 'count',\n",
    "    # 'sum',\n",
    "    'kurt'\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    'segment_category',\n",
    "    'segment_family',\n",
    "    # 'segment_value',\n",
    "    # 'metric',\n",
    "    # 'metric_detail',\n",
    "    # 'transformation_category',\n",
    "    # 'transformation_base',\n",
    "    # 'transformation_method',\n",
    "    'feature_full',\n",
    "\n",
    "]\n",
    "pd.DataFrame(feature_details_df\n",
    " [\n",
    "  (feature_details_df['segment_category'].isin(feature_details_df['segment_category']))  # Dummy line that always evaluates to True\n",
    " & (feature_details_df['segment_category'].isin(segment_category_filter))\n",
    " & (feature_details_df['segment_family'].isin(segment_family_filter))\n",
    "#  & (feature_details_df['metric'].isin(metric_filter))\n",
    "#  & (feature_details_df['metric_detail'].isin(metric_detail_filter))\n",
    "#  & (feature_details_df['transformation_category'].isin(transformation_category_filter))\n",
    "#  & (feature_details_df['transformation_base'].isin(transformation_base_filter))\n",
    "#  & (feature_details_df['transformation_method'].isin(transformation_method_filter))\n",
    "    ]\n",
    " .fillna('None').groupby(groups)\n",
    " .size()\n",
    "# ).columns\n",
    ").sort_values(by=0,ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build coin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_folder = wallets_coin_config['training_data']['parquet_folder']\n",
    "wamo_coin_training_data_df_full = pd.read_parquet(f\"{parquet_folder}/multiwindow_wamo_coin_training_data_df_full.parquet\")\n",
    "wamo_coin_target_var_df         = pd.read_parquet(f\"{parquet_folder}/multiwindow_wamo_coin_target_var_df.parquet\")\n",
    "como_coin_training_data_df_full = pd.read_parquet(f\"{parquet_folder}/multiwindow_como_coin_training_data_df_full.parquet\")\n",
    "como_coin_target_var_df         = pd.read_parquet(f\"{parquet_folder}/multiwindow_como_coin_target_var_df.parquet\")\n",
    "investing_coin_training_data_df_full = pd.read_parquet(f\"{parquet_folder}/investing_multiwindow_como_coin_training_data_df_full.parquet\")\n",
    "investing_coin_target_var_df         = pd.read_parquet(f\"{parquet_folder}/investing_multiwindow_como_coin_target_var_df.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(set(wamo_coin_training_data_df_full.index.get_level_values('coin_epoch_start_date')).intersection(\n",
    "set(investing_coin_training_data_df_full.index.get_level_values('coin_epoch_start_date')))) > 0:\n",
    "    raise ValueError(\"no overlap allowed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "# Initialize and run model\n",
    "coin_model = cm.CoinModel(modeling_config=wallets_coin_config['coin_modeling'])\n",
    "coin_model_results = coin_model.construct_coin_model(\n",
    "    wamo_coin_training_data_df_full,wamo_coin_target_var_df,\n",
    "    # como_coin_training_data_df_full,como_coin_target_var_df\n",
    "    investing_coin_training_data_df_full,investing_coin_target_var_df\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in coin_model_results:\n",
    "\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    coin_model_id, coin_evaluator, coin_scores_df = cimr.generate_and_save_coin_model_artifacts(\n",
    "        model_results=coin_model_results,\n",
    "        base_path='../artifacts/coin_modeling',\n",
    "        configs = {\n",
    "            'wallets_coin_config': wallets_coin_config.config,\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_epochs_config': wallets_epochs_config,\n",
    "            'wallets_features_config': wallets_features_config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "        }\n",
    "    )\n",
    "    coin_evaluator.plot_wallet_evaluation()\n",
    "else:\n",
    "    display(coin_model.generate_search_report())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "model_id = coin_model_id\n",
    "# model_id = 'bb10db73-1fda-4141-b9ca-64716b41db00'\n",
    "\n",
    "file_prefix='investing_val'\n",
    "parquet_folder = wallets_coin_config['training_data']['parquet_folder']\n",
    "como_features_df = pd.read_parquet(f\"{parquet_folder}/{file_prefix}multiwindow_como_coin_training_data_df_full.parquet\")\n",
    "como_target_var_df = pd.read_parquet(f\"{parquet_folder}/{file_prefix}multiwindow_como_coin_target_var_df.parquet\")\n",
    "\n",
    "if len(set(como_target_var_df.index.get_level_values('coin_epoch_start_date')).intersection(\n",
    "set(investing_coin_training_data_df_full.index.get_level_values('coin_epoch_start_date')))) > 0:\n",
    "    raise ValueError(\"no overlap allowed\")\n",
    "\n",
    "\n",
    "# Create a list of the current index level dtypes\n",
    "idx_dtypes = list(como_target_var_df.index.dtypes)\n",
    "# Convert only the coin_id level (assuming it's the first level)\n",
    "como_target_var_df.index = como_target_var_df.index.set_levels(\n",
    "    como_target_var_df.index.levels[0].astype(str),\n",
    "    level=0\n",
    ")\n",
    "\n",
    "como_scores_df = coin_epochs_orchestrator.score_coin_training_data(\n",
    "    model_id,\n",
    "    '../artifacts/coin_modeling',\n",
    "    como_features_df,\n",
    ")\n",
    "logger.info(set(como_features_df.index.get_level_values('coin_epoch_start_date')))\n",
    "plot_return_vs_rank(como_scores_df['score'],como_target_var_df['coin_return_winsorized'],n_buckets=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "\n",
    "# Initialize and run model\n",
    "coin_model = cm.CoinModel(modeling_config=wallets_coin_config['coin_modeling'])\n",
    "coin_model_results = coin_model.construct_coin_model(\n",
    "    wamo_coin_training_data_df_full,wamo_coin_target_var_df,\n",
    "    como_coin_training_data_df_full,como_coin_target_var_df\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in coin_model_results:\n",
    "\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    coin_model_id, coin_evaluator, coin_scores_df = cimr.generate_and_save_coin_model_artifacts(\n",
    "        model_results=coin_model_results,\n",
    "        base_path='../artifacts/coin_modeling',\n",
    "        configs = {\n",
    "            'wallets_coin_config': wallets_coin_config.config,\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_epochs_config': wallets_epochs_config,\n",
    "            'wallets_features_config': wallets_features_config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "        }\n",
    "    )\n",
    "    coin_evaluator.plot_wallet_evaluation()\n",
    "else:\n",
    "    display(coin_model.generate_search_report())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "\n",
    "# Load df\n",
    "importances_df = pd.DataFrame(coin_evaluator.metrics['importances'])\n",
    "feature_details_df = cfo.parse_feature_names(importances_df,'importance')\n",
    "\n",
    "# Select features\n",
    "segment_category_filter = [\n",
    "    # 'all_wallets',\n",
    "    # 'macro',\n",
    "    # 'score_quantile',\n",
    "    # 'score_binary',\n",
    "    # 'training_clusters',\n",
    "    # 'time_series',\n",
    "    # 'wallet_cohorts',\n",
    "]\n",
    "segment_family_filter = [\n",
    "    # 'all_wallets',\n",
    "    # 'net_gain_winsorized_dda619_grid_score',\n",
    "    'cw_return_rate_regression_score',\n",
    "    # 'time_series',\n",
    "    # 'wallet_cohorts',\n",
    "]\n",
    "segment_value_filter = [\n",
    "    'cluster_4',\n",
    "]\n",
    "metric_filter = [\n",
    "    'trading',\n",
    "    'balances',\n",
    "]\n",
    "metric_detail_filter = [\n",
    "    'crypto_net_gain',\n",
    "    'usd_balance_241031',\n",
    "]\n",
    "transformation_category_filter = [\n",
    "    # 'aggregations',\n",
    "    # 'score_wtd',\n",
    "    'score_dist',\n",
    "]\n",
    "transformation_base_filter = [\n",
    "    # 'aggregations',\n",
    "    'cw_return_rate_min_040_score',\n",
    "]\n",
    "transformation_method_filter = [\n",
    "    # 'count',\n",
    "    # 'sum',\n",
    "    # 'dda528_net_gain_max_inv_025_score_p90'\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    'segment_category',\n",
    "    'segment_family',\n",
    "    # 'segment_value',\n",
    "    # 'metric',\n",
    "    # 'metric_detail',\n",
    "    # 'transformation_category',\n",
    "    # 'transformation_base',\n",
    "    # 'transformation_method',\n",
    "    # 'feature_full',\n",
    "\n",
    "]\n",
    "pd.DataFrame(feature_details_df\n",
    " [\n",
    "  (feature_details_df['segment_category'].isin(feature_details_df['segment_category']))  # Dummy line that always evaluates to True\n",
    "#  & (feature_details_df['segment_category'].isin(segment_category_filter))\n",
    "#  & (feature_details_df['segment_family'].isin(segment_family_filter))\n",
    "#  & (feature_details_df['segment_value'].isin(segment_value_filter))\n",
    "#  & (feature_details_df['metric'].isin(metric_filter))\n",
    "#  & (feature_details_df['metric_detail'].isin(metric_detail_filter))\n",
    "#  & (feature_details_df['transformation_category'].isin(transformation_category_filter))\n",
    "#  & (feature_details_df['transformation_base'].isin(transformation_base_filter))\n",
    "#  & (feature_details_df['transformation_method'].isin(transformation_method_filter))\n",
    "    ]\n",
    " .fillna('None')\n",
    " .groupby(groups)['importance']\n",
    " .agg(['sum', 'count'])\n",
    ").sort_values(by='sum',ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate wallet scores for investing period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wallet training data for the coin modeling period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create wallet model training data for dates through the end of the original modeling period.\n",
    "# This will be used to create \"current\" scores as of the end of the modeling period, that can be\n",
    "# used to generate features for the \"current\" coin model built at the end of the modeling period.\n",
    "\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_epochs_config = yaml.safe_load(Path('../config/wallets_epochs_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "complete_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_profits_df.parquet\")\n",
    "complete_market_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_market_data_df.parquet\")\n",
    "complete_macro_trends_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/complete_macro_trends_df.parquet\")\n",
    "\n",
    "# Identify offset needed to generate training data directly following the modeling period to the validation period start\n",
    "modeling_offset = (datetime.strptime(wallets_config['training_data']['modeling_period_end'], '%Y-%m-%d') - datetime.strptime(wallets_config['training_data']['training_period_end'], '%Y-%m-%d')).days\n",
    "coin_modeling_epochs_config = {\n",
    "    'offset_epochs': {\n",
    "        'offsets': [modeling_offset]\n",
    "    }\n",
    "}\n",
    "# Initiate orchestrator\n",
    "epochs_orchestrator = weo.WalletEpochsOrchestrator(\n",
    "    wallets_config.config,\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    coin_modeling_epochs_config,\n",
    "    complete_profits_df,\n",
    "    complete_market_data_df,\n",
    "    complete_macro_trends_df\n",
    ")\n",
    "\n",
    "# Generate TRAINING_DATA_DF for the modeling period offset window\n",
    "como_training_data_df, como_modeling_data_df, _, _ = epochs_orchestrator.generate_epochs_training_data()\n",
    "\n",
    "# Save files\n",
    "como_training_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/como_training_data_df.parquet\",index=True)\n",
    "como_modeling_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/como_modeling_data_df.parquet\",index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save scores for coin modeling training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# model_id = 'c1fd04e8-5d57-48d7-9d7d-57b61afff9d5'\n",
    "score_name = wallets_config['modeling']['score_name']\n",
    "\n",
    "\n",
    "# Load and predict\n",
    "como_training_data_df = pd.read_parquet(f\"{wallets_coin_config['training_data']['parquet_folder']}\"\n",
    "                                           \"/como_coin_training_data_df_full.parquet\")\n",
    "\n",
    "base_path = wallets_config['training_data']['model_artifacts_folder']\n",
    "como_y_pred = wiva.load_and_predict(model_id,como_training_data_df,base_path)\n",
    "\n",
    "# Create wallet scores DataFrame with both cohorts\n",
    "modeling_wallet_scores_df = pd.DataFrame({\n",
    "    f'score|{score_name}': como_y_pred\n",
    "})\n",
    "modeling_wallet_scores_df.to_parquet(f\"temp/wallet_modeling_score_dfs/{score_name}.parquet\",index=True)\n",
    "\n",
    "u.notify(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "\n",
    "# Initialize evaluator\n",
    "coin_evaluator = wime.RegressorEvaluator(coin_model_results)\n",
    "\n",
    "print(coin_evaluator.summary_report())\n",
    "coin_evaluator.plot_coin_evaluation()\n",
    "coin_evaluator.importance_summary(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "\n",
    "feature_details_df = civa.analyze_coin_model_importance(coin_evaluator.metrics['importances'])\n",
    "\n",
    "segment_category_filter = [\n",
    "    # 'all_wallets',\n",
    "    'score_quantile',\n",
    "    # 'time_series',\n",
    "    # 'wallet_cohorts',\n",
    "    # 'training_clusters',\n",
    "]\n",
    "segment_family_filter = [\n",
    "    'all_wallets',\n",
    "    'net_gain_winsorized_dda619_grid_score',\n",
    "    # 'time_series',\n",
    "    # 'wallet_cohorts',\n",
    "]\n",
    "metric_filter = [\n",
    "    # 'trading',\n",
    "    'balances',\n",
    "]\n",
    "metric_detail_filter = [\n",
    "    'crypto_net_gain',\n",
    "    'usd_balance_241031',\n",
    "]\n",
    "transformation_filter = [\n",
    "    # 'aggregations',\n",
    "    # 'score_wtd',\n",
    "]\n",
    "transformation_method_filter = [\n",
    "    'net_gain_winsorized_dda619_grid_residual_p10',\n",
    "    # 'sum',\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    'segment_category',\n",
    "    # 'segment_family',\n",
    "    # 'segment_value',\n",
    "    'metric',\n",
    "    'metric_detail',\n",
    "    'transformation',\n",
    "    'transformation_method',\n",
    "    # 'feature_full',\n",
    "\n",
    "]\n",
    "\n",
    "pd.DataFrame(feature_details_df\n",
    " [\n",
    " (feature_details_df['segment_category'].isin(segment_category_filter))\n",
    "#  & (feature_details_df['segment_family'].isin(segment_family_filter))\n",
    "#  & (feature_details_df['metric'].isin(metric_filter))\n",
    "#  & (feature_details_df['metric_detail'].isin(metric_detail_filter))\n",
    "#  & (feature_details_df['transformation'].isin(transformation_filter))\n",
    "#  & (feature_details_df['transformation_method'].isin(transformation_method_filter))\n",
    "    ]\n",
    " .fillna('None').groupby(groups)\n",
    " .sum('importance')\n",
    "# ).columns\n",
    ").sort_values(by='importance',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load importances\n",
    "feature_importance_df = pd.DataFrame(coin_evaluator.metrics['importances'])\n",
    "\n",
    "# Split on pipe delimiters\n",
    "split_df = feature_importance_df['feature'].str.split('|', expand=True)\n",
    "split_df.columns = ['segment_category','segment_family','metric','transformation']\n",
    "\n",
    "# Split nested components\n",
    "segment_families = split_df['segment_family'].str.split('/', expand=True)\n",
    "segment_families.columns = ['segment_family', 'segment_value']\n",
    "\n",
    "metrics = split_df['metric'].str.split('/', expand=True)\n",
    "metrics.columns = ['metric', 'metric_detail']\n",
    "\n",
    "transformations = split_df['transformation'].str.split('/', expand=True)\n",
    "transformations.columns = ['transformation', 'transformation_method']\n",
    "\n",
    "# Combine all components\n",
    "feature_details_df = pd.concat([\n",
    "    split_df['segment_category'],\n",
    "    segment_families,\n",
    "    metrics,\n",
    "    transformations,\n",
    "    feature_importance_df['importance']\n",
    "], axis=1)\n",
    "\n",
    "feature_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(feature_importance_df['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    'segment_category',\n",
    "    'segment_family',\n",
    "    # 'segment_value',\n",
    "    'metric',\n",
    "    'metric_detail',\n",
    "    # 'transformation',\n",
    "    # 'transformation_method',\n",
    "]\n",
    "\n",
    "feature_details_df.groupby(groups).sum('importance').sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named `df`\n",
    "# Calculate correlations\n",
    "correlation_matrix = coin_modeling_df.corr()\n",
    "\n",
    "# Extract correlations with the target variable\n",
    "target_correlations = correlation_matrix[target_var_column].sort_values(ascending=False)\n",
    "\n",
    "# Display the top features correlated with the target\n",
    "target_correlations[:15]\n",
    "# target_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "\n",
    "\n",
    "# # Wallet metrics to analyze\n",
    "# wallet_metrics = [\n",
    "# ]\n",
    "\n",
    "wallet_metrics = coin_modeling_df.columns\n",
    "wallet_metrics = target_correlations[:15].index.values\n",
    "\n",
    "# number of score buckets\n",
    "n_quantiles = 5\n",
    "\n",
    "analyze_df = civa.analyze_metric_segments(\n",
    "    coin_modeling_df,\n",
    "    wallet_metrics,\n",
    "    n_quantiles,\n",
    "    target_var_column,\n",
    ")\n",
    "civa.style_metric_segments(analyze_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Coin Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet aggregated analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate validation wallet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "\n",
    "# Create a DataFrame with all wallets that should exist\n",
    "validation_wallet_features_df = pd.DataFrame(index=training_wallet_cohort)\n",
    "validation_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "\n",
    "# Calculate modeling period wallet metrics\n",
    "validation_trading_features_df = wtf.calculate_wallet_trading_features(validation_profits_df,\n",
    "                                                            wallets_config['training_data']['validation_period_start'],\n",
    "                                                            wallets_config['training_data']['validation_period_end'],\n",
    "                                                            include_twb_metrics=False)\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(validation_trading_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in validation_trading_features_df.columns})\n",
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features_df = wpf.calculate_performance_features(validation_wallet_features_df,include_twb_metrics=False)\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(performance_features_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_wallet_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wallet validation period trading/performance by score quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base df with all wallet addresses and scores\n",
    "modeling_wallet_scores_df = cfo.load_wallet_scores(wallets_coin_config['wallet_segments']['wallet_scores'],\n",
    "                                            wallets_coin_config['wallet_segments']['wallet_scores_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create analysis by prediction bands\n",
    "metrics = [\n",
    "    'crypto_net_gain/max_investment/winsorized',\n",
    "    'crypto_net_gain/max_investment/base',\n",
    "    'crypto_net_gain/max_investment/ntile_rank',\n",
    "    'crypto_net_gain/active_twb/winsorized',\n",
    "    'crypto_net_gain/active_twb/base',\n",
    "    'max_investment',\n",
    "    'crypto_net_gain',\n",
    "    'crypto_net_flows',\n",
    "    'total_volume',\n",
    "]\n",
    "\n",
    "min_wallet_volume_usd = 0\n",
    "num_quantiles = 5\n",
    "\n",
    "wiva.create_quantile_report(\n",
    "    validation_wallet_features_df,\n",
    "    modeling_wallet_scores_df[wallets_config['modeling']['score_name']],\n",
    "    metrics,  # Your existing metrics list\n",
    "    num_quantiles,  # Split into ntiles\n",
    "    min_wallet_volume_usd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create analysis by prediction bands\n",
    "metrics = [\n",
    "    'crypto_net_gain/max_investment/winsorized',\n",
    "    'crypto_net_gain/max_investment/base',\n",
    "    'crypto_net_gain/max_investment/ntile_rank',\n",
    "    'crypto_net_gain/active_twb/winsorized',\n",
    "    'crypto_net_gain/active_twb/base',\n",
    "    'max_investment',\n",
    "    'crypto_net_gain',\n",
    "    'crypto_net_flows',\n",
    "    'total_volume',\n",
    "]\n",
    "\n",
    "min_wallet_volume_usd = 0\n",
    "num_quantiles = 5\n",
    "\n",
    "wiva.create_quantile_report(\n",
    "    validation_wallet_features_df,\n",
    "    modeling_wallet_scores_df[wallets_config['modeling']['score_name']],\n",
    "    metrics,  # Your existing metrics list\n",
    "    num_quantiles,  # Split into ntiles\n",
    "    min_wallet_volume_usd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "\n",
    "# Wallet metrics to analyze\n",
    "wallet_metrics = [\n",
    "    'top_100pct/balance_wtd_mean_score',\n",
    "    'top_10pct/count',\n",
    "    'top_25pct/count',\n",
    "    'top_50pct/count',\n",
    "    'top_100pct/count',\n",
    "    'top_10pct/count_pct',\n",
    "    'top_10pct/balance_pct',\n",
    "    'top_25pct/count_pct',\n",
    "    'top_25pct/balance_pct',\n",
    "    'top_50pct/count_pct',\n",
    "    'top_50pct/balance_pct',\n",
    "]\n",
    "# wallet_metrics = list(validation_coin_wallet_features_df.columns)\n",
    "\n",
    "# Create styled performance analysis\n",
    "civa.create_top_coins_wallet_metrics_report(validation_coin_wallet_features_df,percentile=90,wallet_metrics=wallet_metrics,method='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = civa.analyze_market_cap_segments(\n",
    "    coin_wallet_features_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "civa.plot_segment_heatmap(summary_df)\n",
    "civa.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_validation_analysis']['top_n']\n",
    "max_market_cap = wallets_config['coin_validation_analysis']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_validation_analysis']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = civa.validate_coin_performance(coin_wallet_features_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "civa.print_performance_analysis(coin_wallet_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Single Window Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training Data Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load orchestrator\n",
    "training_data_orchestrator = wtdo.WalletTrainingDataOrchestrator(\n",
    "    copy.deepcopy(wallets_config.config),\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data\n",
    "_,_,_,_ = training_data_orchestrator.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['training_period_start'],\n",
    "    wallets_config['training_data']['training_period_end'],\n",
    "    parquet_prefix='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select cohort and prepare training data\n",
    "parquet_folder = wallets_config['training_data']['parquet_folder']\n",
    "training_profits_df_full = pd.read_parquet(f\"{parquet_folder}/training_profits_df_full.parquet\")\n",
    "training_market_data_df_full = pd.read_parquet(f\"{parquet_folder}/training_market_data_df_full.parquet\")\n",
    "training_macro_trends_df_full = pd.read_parquet(f\"{parquet_folder}/training_macro_trends_df_full.parquet\")\n",
    "\n",
    "\n",
    "_ = training_data_orchestrator.prepare_training_data(\n",
    "    training_profits_df_full,\n",
    "    training_market_data_df_full,\n",
    "    training_macro_trends_df_full\n",
    ")\n",
    "\n",
    "# Store hybrid ID map\n",
    "if wallets_config['training_data']['hybridize_wallet_ids']:\n",
    "    pd.to_pickle(training_data_orchestrator.hybrid_cw_id_map, f\"{parquet_folder}/hybrid_cw_id_map.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training features\n",
    "parquet_folder = wallets_config['training_data']['parquet_folder']\n",
    "training_profits_df = pd.read_parquet(f\"{parquet_folder}/training_profits_df.parquet\")\n",
    "training_market_indicators_df = pd.read_parquet(f\"{parquet_folder}/training_market_indicators_data_df.parquet\")\n",
    "training_macro_indicators_df = pd.read_parquet(f\"{parquet_folder}/training_macro_indicators_df.parquet\")\n",
    "training_transfers_df = pd.read_parquet(f\"{parquet_folder}/training_transfers_sequencing_df.parquet\")\n",
    "\n",
    "training_data_orchestrator.generate_training_features(\n",
    "    training_profits_df,\n",
    "    training_market_indicators_df,\n",
    "    training_macro_indicators_df,\n",
    "    training_transfers_df\n",
    ")\n",
    "\n",
    "u.notify(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet Model Target Variable and Wallet Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modeling datasets\n",
    "training_coin_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_market_indicators_data_df.parquet\",\n",
    "                                       columns=['coin_id'])['coin_id'].unique()\n",
    "_,_,_,_ = training_data_orchestrator.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['modeling_period_start'],\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    training_coin_cohort,\n",
    "    parquet_prefix='modeling'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "training_wallet_cohort = pd.read_parquet(\n",
    "    f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\",\n",
    "    columns=[]\n",
    ").index.values\n",
    "\n",
    "# Load orchestrator\n",
    "training_data_orchestrator = wtdo.WalletTrainingDataOrchestrator(\n",
    "    copy.deepcopy(wallets_config.config),\n",
    "    wallets_metrics_config,\n",
    "    wallets_features_config,\n",
    "    training_wallet_cohort\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare modeling features for target variables\n",
    "modeling_profits_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_profits_df_full.parquet\")\n",
    "hybrid_cw_id_map = None\n",
    "if wallets_config['training_data']['hybridize_wallet_ids']:\n",
    "    hybrid_cw_id_map = pd.read_pickle(f\"{wallets_config['training_data']['parquet_folder']}/hybrid_cw_id_map.pkl\")\n",
    "\n",
    "_ = training_data_orchestrator.prepare_modeling_features(\n",
    "    modeling_profits_df_full,\n",
    "    hybrid_cw_id_map\n",
    ")\n",
    "\n",
    "u.notify(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet Model Construction and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select target variable (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create MODELING_DF and Construct Wallet Model\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "modeling_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_wallet_features_df.parquet\")\n",
    "\n",
    "# Filter training data to only the modeling cohort through inner join to target variable\n",
    "modeling_cohort_target_var_df = modeling_wallet_features_df[['in_modeling_cohort', wallets_config['modeling']['target_variable']]].copy()\n",
    "\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\")\n",
    "logger.info(\"Training data df shape: %s\", wallet_training_data_df.shape)\n",
    "# sorted(list(wallet_training_data_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build wallet model or run search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\")\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "\n",
    "# Validate indices match\n",
    "if not all(\n",
    "    wallet_training_data_df.sort_index().index.get_level_values(level).equals(\n",
    "        modeling_cohort_target_var_df.sort_index().index.get_level_values(level)\n",
    "    ) for level in wallet_training_data_df.index.names\n",
    "):\n",
    "    raise ValueError(\"Merged training and modeling DataFrames have mismatched indices.\")\n",
    "\n",
    "\n",
    "wallet_model_results = wallet_model.construct_wallet_model(wallet_training_data_df,modeling_cohort_target_var_df)\n",
    "del wallet_training_data_df\n",
    "gc.collect()\n",
    "\n",
    "# Print summary\n",
    "if 'y_train' in wallet_model_results:\n",
    "\n",
    "    # Generate and save all model artifacts\n",
    "    model_id, wallet_evaluator, modeling_wallet_scores_df = wimr.generate_and_save_wallet_model_artifacts(\n",
    "        model_results=wallet_model_results,\n",
    "        base_path='../artifacts/wallet_modeling',\n",
    "        configs = {\n",
    "            'wallets_config': wallets_config.config,\n",
    "            'wallets_metrics_config': wallets_metrics_config,\n",
    "            'wallets_features_config': wallets_features_config\n",
    "        },\n",
    "        save_scores=False\n",
    "    )\n",
    "    print(wallet_evaluator.summary_report())\n",
    "else:\n",
    "    display(wallet_model.generate_search_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n",
    "\n",
    "wallets_config, wallets_coin_config = wcm.load_all_wallets_configs('../config')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
