{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# import local files if necessary\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "import utils as u\n",
    "importlib.reload(u)\n",
    "\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Custom format function for displaying numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "\n",
    "# Load all configs as global variables\n",
    "global CONFIG, METRICS_CONFIG, MODELING_CONFIG, EXPERIMENTS_CONFIG, MODELING_FOLDER\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "CONFIG = config\n",
    "METRICS_CONFIG = metrics_config\n",
    "MODELING_CONFIG = modeling_config\n",
    "EXPERIMENTS_CONFIG = experiments_config\n",
    "MODELING_FOLDER = MODELING_CONFIG['modeling']['modeling_folder']\n",
    "modeling_folder = MODELING_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "start_date = config['training_data']['training_period_start']\n",
    "end_date = config['training_data']['modeling_period_end']\n",
    "\n",
    "# Retrieve market data\n",
    "market_data_df = td.retrieve_market_data()\n",
    "market_data_df, _ = cwm.split_dataframe_by_coverage(market_data_df, start_date, end_date, id_column='coin_id')\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "# Retrieve profits data if necessary\n",
    "if 'profits_df' not in globals():\n",
    "    profits_df = None\n",
    "profits_df = i.rebuild_profits_df_if_necessary(\n",
    "                config,\n",
    "                modeling_folder,\n",
    "                prices_df,\n",
    "                profits_df)\n",
    "\n",
    "# Filter market_data rows without transfers if configured to do so\n",
    "if config['data_cleaning']['exclude_coins_without_transfers']:\n",
    "    market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n",
    "    prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "# Retrieve Google Trends data\n",
    "google_trends_df = td.retrieve_google_trends_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Initialize empty lists to hold concatenated data\n",
    "X_train_all, X_test_all = [], []\n",
    "y_train_all, y_test_all = [], []\n",
    "returns_test_all = []\n",
    "\n",
    "time_windows = td.generate_time_windows(config)\n",
    "\n",
    "for n, window in enumerate(time_windows):\n",
    "\n",
    "    # Prepare the full configuration by applying overrides from the current trial config\n",
    "    config, metrics_config, modeling_config = i.prepare_configs(modeling_config['modeling']['config_folder'], window)\n",
    "\n",
    "    # Define window start and end dates\n",
    "    start_date = config['training_data']['training_period_start']\n",
    "    end_date = config['training_data']['modeling_period_end']\n",
    "\n",
    "    # Rebuild market data\n",
    "    market_data_df = td.retrieve_market_data()\n",
    "    market_data_df, _ = cwm.split_dataframe_by_coverage(market_data_df, start_date, end_date, id_column='coin_id')\n",
    "    prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "    # Rebuild profits_df\n",
    "    profits_df = i.rebuild_profits_df_if_necessary(config, modeling_folder, prices_df, profits_df)\n",
    "\n",
    "    # Build the configured model input data for the nth window\n",
    "    X_train_n, X_test_n, y_train_n, y_test_n, returns_test_n = i.build_configured_model_input(\n",
    "                                        profits_df,\n",
    "                                        market_data_df,\n",
    "                                        google_trends_df,\n",
    "                                        config,\n",
    "                                        metrics_config,\n",
    "                                        modeling_config)\n",
    "\n",
    "    # Append the current window's data to the lists\n",
    "    X_train_all.append(X_train_n)\n",
    "    X_test_all.append(X_test_n)\n",
    "    y_train_all.append(y_train_n)\n",
    "    y_test_all.append(y_test_n)\n",
    "    returns_test_all.append(returns_test_n)\n",
    "\n",
    "# Concatenate all the data for each part\n",
    "X_train = pd.concat(X_train_all, axis=0)\n",
    "X_test = pd.concat(X_test_all, axis=0)\n",
    "y_train = pd.concat(y_train_all, axis=0)\n",
    "y_test = pd.concat(y_test_all, axis=0)\n",
    "returns_test = pd.concat(returns_test_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Train the model using the current configuration and log the results\n",
    "model, model_id = m.train_model(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    modeling_folder,\n",
    "                    modeling_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# 3.5 Evaluate and save the model performance on the test set to a CSV\n",
    "metrics_dict, y_pred, y_pred_prob = m.evaluate_model(model, X_test, y_test, model_id, returns_test, modeling_config)\n",
    "\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(returns_test).sort_values('returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_profitability_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(running_profitability_scores).sort_values('returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "running_profitability_scores = m.calculate_running_profitability_score(\n",
    "                                                        y_pred_prob,\n",
    "                                                        returns_test,\n",
    "                                                        modeling_config[\"evaluation\"][\"winsorization_cutoff\"]\n",
    "                                                        )\n",
    "\n",
    "\n",
    "running_profitability_scores.reset_index().plot(kind='line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "google_trends_df = td.retrieve_google_trends_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "training_data_tuples = []\n",
    "\n",
    "# 1. Generate and merge features for all datasets\n",
    "# -------------------------------------\n",
    "# Time series features\n",
    "dataset_name = 'market_data'  # update to loop through all time series\n",
    "market_data_tuples, _ = fe.generate_time_series_features(\n",
    "        dataset_name,\n",
    "        market_data_df,\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )\n",
    "training_data_tuples.extend(market_data_tuples)\n",
    "\n",
    "# Wallet cohort features\n",
    "wallet_cohort_tuples, _ = fe.generate_wallet_cohort_features(\n",
    "        profits_df,\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )\n",
    "training_data_tuples.extend(wallet_cohort_tuples)\n",
    "\n",
    "# Google trends features\n",
    "dataset_name = 'google_trends'  # update to loop through all macro trends\n",
    "google_trends_tuples, _ = fe.generate_macro_trends_features(\n",
    "        dataset_name,\n",
    "        google_trends_df,\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )\n",
    "training_data_tuples.extend(google_trends_tuples)\n",
    "\n",
    "# Merge all the features\n",
    "training_data_df, _ = fe.create_training_data_df(\n",
    "                        modeling_config['modeling']['modeling_folder'],\n",
    "                        training_data_tuples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = config['datasets']['macro_trends'][dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# set parameters\n",
    "dataset_name = 'google_trends'\n",
    "dataset_df = google_trends_df\n",
    "config,\n",
    "metrics_config,\n",
    "modeling_config\n",
    "\n",
    "training_data_tuples, training_data_dfs = fe.generate_macro_trends_features(\n",
    "        dataset_name,\n",
    "        dataset_df,\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_config['macro_trends'][dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = config['datasets']['macro_trends'][dataset_name]\n",
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten metrics\n",
    "flattened_features = fe.flatten_date_features(value_column_metrics_df,dataset_metrics_config)\n",
    "flattened_google_trends_df = pd.DataFrame([flattened_features])\n",
    "\n",
    "# save flattened metrics\n",
    "flattened_google_trends_df, flattened_google_trends_filepath = fe.save_flattened_outputs(\n",
    "    flattened_google_trends_df,\n",
    "    os.path.join(\n",
    "        modeling_config['modeling']['modeling_folder'],  # Folder to store flattened outputs\n",
    "        'outputs/flattened_outputs'\n",
    "    ),\n",
    "    value_column_config['description'],  # Descriptive metadata for the dataset\n",
    "    config['training_data']['modeling_period_start']  # Ensure data starts from modeling period\n",
    ")\n",
    "\n",
    "# preprocess metrics\n",
    "google_trends_preprocessed_df, google_trends_preprocessed_filepath = fe.preprocess_coin_df(\n",
    "    flattened_google_trends_filepath\n",
    "    ,modeling_config\n",
    "    ,value_column_config\n",
    "    ,value_column_metrics_config\n",
    ")\n",
    "\n",
    "google_trends_tuple = (google_trends_preprocessed_filepath.split('preprocessed_outputs/')[1], value_column_config['fill_method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['datasets']['macro_trends'][dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# set up config variables\n",
    "dataset_category = 'macro_trends'\n",
    "dataset_name = 'google_trends'\n",
    "dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "dataset_metrics_config = metrics_config[dataset_category][dataset_name]\n",
    "\n",
    "# load dataset\n",
    "google_trends_df = td.retrieve_google_trends_data()\n",
    "\n",
    "\n",
    "# calculate and merge all metrics in the config\n",
    "all_metrics = []\n",
    "for key in list(dataset_metrics_config.keys()):\n",
    "    value_column_metrics_config = metrics_config[dataset_category][dataset_name][key]\n",
    "    metric_df = google_trends_df[['date',key]]\n",
    "\n",
    "    # check if there are any time series indicators to add, e.g. sma, ema, etc\n",
    "    if 'indicators' in value_column_metrics_config:\n",
    "        value_column_metrics_df, _ = cwm.generate_time_series_indicators(\n",
    "            metric_df,\n",
    "            config,\n",
    "            value_column_metrics_config,\n",
    "            key,\n",
    "            id_column=None\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # if no indicators are needed, pass through coins with complete date coverage\n",
    "        logging.getLogger().setLevel(logging.WARNING)\n",
    "        value_column_metrics_df, _ = cwm.split_dataframe_by_coverage(\n",
    "            value_column_df,\n",
    "            config['training_data']['training_period_start'],\n",
    "            config['training_data']['training_period_end'],\n",
    "            id_column='coin_id'\n",
    "        )\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    all_metrics.append(metric_df)\n",
    "\n",
    "all_metrics_df = all_metrics[0]\n",
    "for metrics_df in all_metrics[1:]:\n",
    "    all_metrics_df = pd.merge(all_metrics_df, metrics_df, on='date', how='outer')\n",
    "\n",
    "\n",
    "# flatten metrics\n",
    "flattened_features = fe.flatten_date_features(all_metrics_df,dataset_metrics_config)\n",
    "flattened_google_trends_df = pd.DataFrame([flattened_features])\n",
    "\n",
    "# save flattened metrics\n",
    "flattened_google_trends_df, flattened_google_trends_filepath = fe.save_flattened_outputs(\n",
    "    flattened_google_trends_df,\n",
    "    os.path.join(modeling_config['modeling']['modeling_folder'],'outputs/flattened_outputs'),\n",
    "    dataset_config['description'],\n",
    "    config['training_data']['modeling_period_start']\n",
    ")\n",
    "\n",
    "# preprocess metrics\n",
    "google_trends_preprocessed_df, google_trends_preprocessed_filepath = fe.preprocess_coin_df(\n",
    "    flattened_google_trends_filepath\n",
    "    ,modeling_config\n",
    "    ,dataset_config\n",
    "    ,dataset_metrics_config\n",
    ")\n",
    "\n",
    "google_trends_tuple = (google_trends_preprocessed_filepath.split('preprocessed_outputs/')[1], dataset_config['fill_method'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
