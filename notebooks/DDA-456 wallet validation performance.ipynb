{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['ALERT_SOUND_FILEPATH']=\"../../../Local/assets/sounds/mixkit-alert-bells-echo-765.wav\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_modeling_orchestrator as wmo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_modeling.model_reporting as wmr\n",
    "import wallet_modeling.wallet_model as wm\n",
    "import wallet_modeling.experiments_manager as wem\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.clustering_features as wcl\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.performance_features as wpf\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.features_orchestrator as wfo\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.wallet_model_evaluation as wime\n",
    "import wallet_insights.wallet_validation_analysis as wiwv\n",
    "import wallet_insights.coin_validation_analysis as wicv\n",
    "import wallet_insights.coin_validation_model as wicm\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp,\n",
    "           wmo, wtd, wmr, wm, wem,\n",
    "           wcl, wmc, wmt, wpf, wtf, wts, wfo,\n",
    "           wime, wiwv, wicv, wicm]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "wallets_config = WalletsConfig.load_from_yaml('../config/wallets_config.yaml')\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.export_code(\n",
    "    code_directories=[\n",
    "        # 'training_data',\n",
    "        'wallet_features',\n",
    "        # 'wallet_modeling',\n",
    "        # 'wallet_insights'\n",
    "    ],\n",
    "    # include_config = True,\n",
    "    # ipynb_notebook = 'DDA-456 wallet validation performance.ipynb'\n",
    ")\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wallet Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Complete Pre-Training Profits/Market Data\n",
    "# -----------------------------------------\n",
    "# Retrieve training period datasets and save them to temp/wallet_modeling_dfs\n",
    "wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['training_period_start'],\n",
    "    wallets_config['training_data']['training_period_end'],\n",
    "    parquet_prefix = 'training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "training_profits_df,training_market_data_df,coin_cohort = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['training_period_start'],\n",
    "    wallets_config['training_data']['training_period_end'])\n",
    "\n",
    "modeling_profits_df,modeling_market_data_df,_ = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['modeling_period_start'],\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    coin_cohort=coin_cohort)\n",
    "\n",
    "combined_profits_df,combined_market_data_df,_ = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['training_period_start'],\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    coin_cohort=coin_cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### useable assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily adjust log level\n",
    "logger.info(\"Generating training, modeling, and combined datasets...\")\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Target the dev schema to avoid a very long runtime\n",
    "wallets_config['training_data']['dataset'] = 'dev'\n",
    "\n",
    "# Get initial training data and coin cohort\n",
    "training_profits_df, training_market_df, coin_cohort = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['training_period_start'],\n",
    "    wallets_config['training_data']['training_period_end']\n",
    ")\n",
    "\n",
    "# Get modeling period data\n",
    "modeling_profits_df, modeling_market_df, _ = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['modeling_period_start'],\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    coin_cohort=coin_cohort\n",
    ")\n",
    "\n",
    "# Get combined period data\n",
    "combined_profits_df, combined_market_df, _ = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['training_period_start'],\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    coin_cohort=coin_cohort\n",
    ")\n",
    "\n",
    "period_datasets = (\n",
    "    training_profits_df, training_market_df,\n",
    "    modeling_profits_df, modeling_market_df,\n",
    "    combined_profits_df, combined_market_df\n",
    ")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info(\"All dev data retrieved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_wallet_coin_balance_continuity(period_datasets):\n",
    "    \"\"\"\n",
    "    Test that all wallet-coin pair balances match at the training/modeling boundary\n",
    "    using vectorized operations. Allows for 0.0001% difference due to floating point math.\n",
    "    \"\"\"\n",
    "    training_df, _, modeling_df, _, _, _ = period_datasets\n",
    "\n",
    "    # Get boundary data\n",
    "    training_last = training_df['date'].max()\n",
    "    training_end_df = training_df[training_df['date']==training_last]\n",
    "\n",
    "    modeling_first = modeling_df['date'].min()\n",
    "    modeling_start_df = modeling_df[modeling_df['date']==modeling_first]\n",
    "\n",
    "    # Create merged df on composite key\n",
    "    balance_compare_df = pd.merge(\n",
    "        training_end_df[['wallet_address', 'coin_id', 'usd_balance']],\n",
    "        modeling_start_df[['wallet_address', 'coin_id', 'usd_balance']],\n",
    "        on=['wallet_address', 'coin_id'],\n",
    "        suffixes=('_train', '_model')\n",
    "    )\n",
    "\n",
    "    # Convert to float64 for consistency\n",
    "    balance_compare_df['usd_balance_train'] = balance_compare_df['usd_balance_train'].astype('float64')\n",
    "    balance_compare_df['usd_balance_model'] = balance_compare_df['usd_balance_model'].astype('float64')\n",
    "\n",
    "    # Filter out zero balance pairs to avoid div by zero\n",
    "    nonzero_mask = ~((balance_compare_df['usd_balance_train'] == 0) &\n",
    "                        (balance_compare_df['usd_balance_model'] == 0))\n",
    "    balance_compare_df = balance_compare_df[nonzero_mask]\n",
    "\n",
    "    # Calculate both absolute and percentage differences\n",
    "    balance_compare_df['abs_diff'] = abs(\n",
    "        balance_compare_df['usd_balance_train'] -\n",
    "        balance_compare_df['usd_balance_model']\n",
    "    )\n",
    "\n",
    "    balance_compare_df['pct_diff'] = abs(\n",
    "        balance_compare_df['usd_balance_train'] /\n",
    "        balance_compare_df['usd_balance_model'] - 1\n",
    "    )\n",
    "\n",
    "    # Flag significant mismatches (both conditions must be true)\n",
    "    significant_diffs = balance_compare_df[\n",
    "        (balance_compare_df['abs_diff'] > 0.1) &\n",
    "        (balance_compare_df['pct_diff'] > 0.00001)\n",
    "    ]\n",
    "\n",
    "    assert len(significant_diffs) == 0, \\\n",
    "        \"Found wallet-coin pairs with significant balance mismatches (>$0.01 and >0.0001%)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_compare_df.sort_values('pct_diff',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_profits_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_coin_set_consistency(period_datasets):\n",
    "#     \"\"\"Test that coin sets match between periods\"\"\"\n",
    "training_df, _, modeling_df, _, combined_df, _ = datasets\n",
    "training_coins = set(training_df['coin_id'])\n",
    "modeling_coins = set(modeling_df['coin_id'])\n",
    "combined_coins = set(combined_df['coin_id'])\n",
    "assert training_coins == combined_coins\n",
    "assert len(training_coins - modeling_coins) == 0\n",
    "\n",
    "# def test_transfer_amount_consistency(period_datasets):\n",
    "#     \"\"\"Test that transfer amounts sum correctly\"\"\"\n",
    "training_df, _, modeling_df, _, combined_df, _ = datasets\n",
    "training_transfers = abs(training_df['usd_net_transfers']).astype('float64').sum()\n",
    "modeling_transfers = abs(modeling_df['usd_net_transfers']).astype('float64').sum()\n",
    "combined_transfers = abs(combined_df['usd_net_transfers']).astype('float64').sum()\n",
    "assert abs(combined_transfers - (training_transfers + modeling_transfers)) < 0.01\n",
    "\n",
    "# def test_time_period_boundaries(period_datasets):\n",
    "#     \"\"\"Test that period boundaries align correctly\"\"\"\n",
    "training_df, _, modeling_df, _, _, _ = datasets\n",
    "training_last = training_df['date'].max()\n",
    "modeling_first = modeling_df['date'].min()\n",
    "assert training_last == modeling_first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, _, modeling_df, _, combined_df, _ = datasets\n",
    "training_transfers = abs(training_df['usd_net_transfers']).astype('float64').sum()\n",
    "modeling_transfers = abs(modeling_df['usd_net_transfers']).astype('float64').sum()\n",
    "combined_transfers = abs(combined_df['usd_net_transfers']).astype('float64').sum()\n",
    "\n",
    "combined_transfers - (training_transfers + modeling_transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_transfers + modeling_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, _, modeling_df, _, _, _ = datasets\n",
    "\n",
    "# Check date boundaries align\n",
    "training_last = training_df['date'].max()\n",
    "modeling_first = modeling_df['date'].min()\n",
    "assert training_last == modeling_first\n",
    "\n",
    "# Check balances match at boundary\n",
    "training_end_df = training_df[training_df['date']==training_last]\n",
    "modeling_start_df = modeling_df[modeling_df['date']==modeling_first]\n",
    "\n",
    "training_end_balance = training_end_df['usd_balance'].astype('float64').sum()\n",
    "modeling_start_balance = modeling_start_df['usd_balance'].astype('float64').sum()\n",
    "\n",
    "# Balance difference must be within 0.0001%\n",
    "assert abs(training_end_balance / modeling_start_balance - 1) < 0.000001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, _, modeling_df, _, _, _ = datasets\n",
    "training_last = training_df['date'].max()\n",
    "modeling_first = modeling_df['date'].min()\n",
    "assert training_last == modeling_first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_transfers + modeling_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transfers - (training_transfers + modeling_transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert coins match\n",
    "training_coins = set(training_profits_df['coin_id'])\n",
    "modeling_coins = set(modeling_profits_df['coin_id'])\n",
    "combined_coins = set(combined_profits_df['coin_id'])\n",
    "\n",
    "# Training set and combined set have identical coins\n",
    "assert training_coins == combined_coins\n",
    "# All modeling coins are included in the training coins\n",
    "assert len(training_coins - modeling_coins) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules and config\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Calculate total transfers across both periods and ensure they match the combined count\n",
    "training_transfers = abs(training_profits_df['usd_net_transfers']).astype('float64').sum()\n",
    "modeling_transfers = abs(modeling_profits_df['usd_net_transfers']).astype('float64').sum()\n",
    "combined_transfers = abs(combined_profits_df['usd_net_transfers']).astype('float64').sum()\n",
    "\n",
    "# Assert the difference is within $0.01\n",
    "assert abs(combined_transfers - (training_transfers+modeling_transfers)) < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_last = training_profits_df['date'].max()\n",
    "modeling_first = modeling_profits_df['date'].min()\n",
    "\n",
    "# Assert that the last and first dates match\n",
    "assert training_last == modeling_first\n",
    "\n",
    "\n",
    "training_end_df = training_profits_df[training_profits_df['date']==training_last]\n",
    "modeling_start_df = modeling_profits_df[modeling_profits_df['date']==modeling_first]\n",
    "\n",
    "training_end_balance = training_end_df['usd_balance'].astype('float64').sum()\n",
    "modeling_start_balance = modeling_start_df['usd_balance'].astype('float64').sum()\n",
    "\n",
    "# Assert the ending balances are within 0.0001% of each other to account for floating points\n",
    "assert abs(training_end_balance / modeling_start_balance - 1) < 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end_balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_start_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proper deduplication considering coin-wallet pairs\n",
    "training_end_balance = (training_end_df\n",
    "    .groupby(['wallet_address', 'coin_id'], observed=True)['usd_balance']\n",
    "    .sum()\n",
    "    .astype('float64'))\n",
    "\n",
    "modeling_start_balance = (modeling_start_df\n",
    "    .groupby(['wallet_address', 'coin_id'], observed=True)['usd_balance']\n",
    "    .sum()\n",
    "    .astype('float64'))\n",
    "\n",
    "# Check pairs with discrepancies\n",
    "pair_analysis = pd.DataFrame({\n",
    "    'training_end': training_end_balance,\n",
    "    'modeling_start': modeling_start_balance\n",
    "}).reset_index()\n",
    "\n",
    "pair_analysis['diff'] = pair_analysis['training_end'] - pair_analysis['modeling_start']\n",
    "discrepancies = pair_analysis[pair_analysis['diff'].abs() > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '0f17de35-54d9-4fba-85fc-7b6fb131f609'\n",
    "w = 17597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.cw_filter_df(combined_profits_df,c,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.cw_filter_df(training_profits_df,c,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.cw_filter_df(modeling_profits_df,c,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_start_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end_df['usd_balance'].astype('float64').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_start_df['usd_balance'].astype('float64').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### codespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transfers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    - df (DataFrame): input profits data\n",
    "\n",
    "    Returns:\n",
    "    - result (DataFrame): transfer calculations with consistent precision\n",
    "    \"\"\"\n",
    "    # Use vectorized operations instead of groupby\n",
    "    result = pd.DataFrame({\n",
    "        'train_transfers': df.query('wallet_address == @w and coin_id == @c')['usd_net_transfers'].sum(),\n",
    "    }).astype('float64')  # Force higher precision\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules and config\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Calculate transfers using vectorized operations\n",
    "training_xfers = training_profits_df[training_profits_df['usd_net_transfers'].notna()]['usd_net_transfers'].sum()\n",
    "modeling_xfers = modeling_profits_df[modeling_profits_df['usd_net_transfers'].notna()]['usd_net_transfers'].sum()\n",
    "combined_xfers = combined_profits_df[combined_profits_df['usd_net_transfers'].notna()]['usd_net_transfers'].sum()\n",
    "\n",
    "print(training_xfers)\n",
    "print(modeling_xfers)\n",
    "print(combined_xfers)\n",
    "print(combined_xfers - (training_xfers+modeling_xfers))\n",
    "\n",
    "# # Test specific wallet-coin combination\n",
    "# c = '1c3d1f11-b299-4eb1-84fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '1c3d1f11-b299-4eb1-84fa-abe6e013cb03'\n",
    "w = 23754641\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Direct vectorized calculation with float64 precision\n",
    "train_sum = training_profits_df.query('wallet_address == @w and coin_id == @c')['usd_net_transfers'].astype('float64').sum()\n",
    "combined_sum = combined_profits_df.query('wallet_address == @w and coin_id == @c')['usd_net_transfers'].astype('float64').sum()\n",
    "\n",
    "print(f\"\\nTraining sum: {train_sum}\")\n",
    "print(f\"Combined sum: {combined_sum}\")\n",
    "\n",
    "# Create result dataframe with consistent precision\n",
    "result = pd.DataFrame({\n",
    "    'wallet_address': [w],\n",
    "    'coin_id': [c],\n",
    "    'train_transfers': [train_sum],\n",
    "    'model_transfers': [0],  # Assuming no model transfers based on previous output\n",
    "    'combined_transfers': [combined_sum],\n",
    "    'transfer_diff': [combined_sum - train_sum],\n",
    "    'abs_diff': [abs(combined_sum - train_sum)]\n",
    "}).astype({'wallet_address': 'int64', 'train_transfers': 'float64', 'combined_transfers': 'float64'})\n",
    "\n",
    "print(\"\\nFinal result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '1c3d1f11-b299-4eb1-84fa-abe6e013cb03'\n",
    "w = 23754641\n",
    "\n",
    "u.cw_filter_df(training_profits_df,c,w)['usd_net_transfers'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '1c3d1f11-b299-4eb1-84fa-abe6e013cb03'\n",
    "w = 23754641\n",
    "\n",
    "u.cw_filter_df(combined_profits_df,c,w)['usd_net_transfers'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = training_profits_df.copy()\n",
    "model_df = modeling_profits_df.copy()\n",
    "combined_df = combined_profits_df.copy()\n",
    "\n",
    "# Group and sum transfers by wallet and coin\n",
    "train_sums = train_df.groupby(['wallet_address', 'coin_id'],observed=True)['usd_net_transfers'].sum()\n",
    "model_sums = model_df.groupby(['wallet_address', 'coin_id'],observed=True)['usd_net_transfers'].sum()\n",
    "combined_sums = combined_df.groupby(['wallet_address', 'coin_id'],observed=True)['usd_net_transfers'].sum()\n",
    "\n",
    "# Combine into single df and fill NaN with 0\n",
    "result = pd.concat([\n",
    "    train_sums.rename('train_transfers'),\n",
    "    model_sums.rename('model_transfers'),\n",
    "    combined_sums.rename('combined_transfers')\n",
    "], axis=1).fillna(0)\n",
    "\n",
    "# Calculate difference\n",
    "result['transfer_diff'] = result['combined_transfers'] - (result['train_transfers'] + result['model_transfers'])\n",
    "result['abs_diff'] = abs(result['transfer_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='abs_diff',ascending=False).head(5).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '1c3d1f11-b299-4eb1-84fa-abe6e013cb03'\n",
    "w = 23754641\n",
    "\n",
    "assert c in coin_cohort\n",
    "\n",
    "u.cw_filter_df(train_df,c,w)['usd_net_transfers'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '1c3d1f11-b299-4eb1-84fa-abe6e013cb03'\n",
    "w = 23754641\n",
    "\n",
    "assert c in coin_cohort\n",
    "\n",
    "u.cw_filter_df(combined_df,c,w)['usd_net_transfers'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_transfer_calcs(df: pd.DataFrame, wallet_id: str, coin_id: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    - df (DataFrame): Combined transfer data\n",
    "    - wallet_id (str): Wallet to analyze\n",
    "    - coin_id (str): Coin to analyze\n",
    "\n",
    "    Returns:\n",
    "    - comparison_df (DataFrame): Parallel cumsum vs total calculations\n",
    "    \"\"\"\n",
    "    mask = (df['wallet_address'] == wallet_id) & (df['coin_id'] == coin_id)\n",
    "\n",
    "    # Get both calculations for comparison\n",
    "    running_total = df[mask]['usd_net_transfers'].cumsum()\n",
    "    total_sum = df[mask]['usd_net_transfers'].sum()\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'running_total': running_total,\n",
    "        'static_total': total_sum,\n",
    "        'difference': running_total - total_sum\n",
    "    })\n",
    "\n",
    "def check_transfer_sequence(df: pd.DataFrame, wallet_id: str, coin_id: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    - df (DataFrame): Transfer data\n",
    "    - wallet_id (str): Target wallet\n",
    "    - coin_id (str): Target coin\n",
    "\n",
    "    Returns:\n",
    "    - sequence_df (DataFrame): Ordered transfer sequence\n",
    "    \"\"\"\n",
    "    mask = (df['wallet_address'] == wallet_id) & (df['coin_id'] == coin_id)\n",
    "    return df[mask][['date', 'usd_net_transfers']].sort_values('date')\n",
    "\n",
    "# Let's analyze both training and modeling data\n",
    "c = '1c3d1f11-b299-4eb1-84fa-abe6e013cb03'\n",
    "w = 23754641\n",
    "\n",
    "\n",
    "# Original transfer comparison\n",
    "print(\"=== Transfer Total Analysis ===\")\n",
    "print(\"\\nTraining Data Analysis:\")\n",
    "train_compare = compare_transfer_calcs(train_df, w, c)\n",
    "print(train_compare)\n",
    "\n",
    "print(\"\\nModeling Data Analysis:\")\n",
    "model_compare = compare_transfer_calcs(model_df, w, c)\n",
    "print(model_compare)\n",
    "\n",
    "print(\"\\nCombined Data Analysis:\")\n",
    "combined_compare = compare_transfer_calcs(combined_df, w, c)\n",
    "print(combined_compare)\n",
    "\n",
    "# Add temporal sequence analysis\n",
    "print(\"\\n=== Temporal Sequence Analysis ===\")\n",
    "print(\"\\nTraining Data Timeline:\")\n",
    "train_seq = check_transfer_sequence(train_df, w, c)\n",
    "print(train_seq)\n",
    "\n",
    "print(\"\\nModeling Data Timeline:\")\n",
    "model_seq = check_transfer_sequence(model_df, w, c)\n",
    "print(model_seq)\n",
    "\n",
    "print(\"\\nCombined Data Timeline:\")\n",
    "combined_seq = check_transfer_sequence(combined_df, w, c)\n",
    "print(combined_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw period data\n",
    "profits_df_raw, market_data_df_raw = wtd.retrieve_raw_datasets(\n",
    "        wallets_config['training_data']['modeling_period_start'],\n",
    "        wallets_config['training_data']['modeling_period_end'])\n",
    "\n",
    "u.cw_filter_df(profits_df_raw,c,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if coin_cohort is not None:\n",
    "    # Filter to existing cohort before processing\n",
    "    profits_df = profits_df_raw[profits_df_raw['coin_id'].isin(coin_cohort)]\n",
    "    market_data_df = market_data_df_raw[market_data_df_raw['coin_id'].isin(coin_cohort)]\n",
    "\n",
    "    print('x')\n",
    "\n",
    "u.cw_filter_df(profits_df,c,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Format and optionally save the datasets\n",
    "profits_df_formatted, market_data_df_formatted = wtd.format_and_save_datasets(\n",
    "    profits_df,\n",
    "    market_data_df,\n",
    "    wallets_config['training_data']['modeling_period_start'],\n",
    "    None\n",
    ")\n",
    "\n",
    "u.cw_filter_df(profits_df_formatted,c,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallets_config['training_data']['training_period_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define cohort and clean training datasets (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "\n",
    "# Add Indicators to Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Load relevant parquet dfs with pre-training history\n",
    "training_market_data_df_full = pd.read_parquet(\"temp/wallet_modeling_dfs/training_market_data_df_full.parquet\")\n",
    "\n",
    "# Generate indicators and save file\n",
    "wmo.generate_training_indicators_df(training_market_data_df_full,wallets_metrics_config)\n",
    "\n",
    "# Identify Wallet Cohort\n",
    "# ----------------------------------------------------------\n",
    "# Identify the date we need starting balances from\n",
    "training_period_start = datetime.strptime(wallets_config['training_data']['training_period_start'],'%Y-%m-%d')\n",
    "training_starting_balance_date = training_period_start - timedelta(days=1)\n",
    "\n",
    "# Remove market data from prior to the starting balance date\n",
    "training_market_data_df = training_market_data_df_full[training_market_data_df_full['date']\n",
    "                                                       >=training_starting_balance_date]\n",
    "del training_market_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "# Retrieve full profits history\n",
    "training_profits_df_full = pd.read_parquet(\"temp/wallet_modeling_dfs/training_profits_df_full.parquet\")\n",
    "\n",
    "# Define wallet cohort\n",
    "training_wallet_cohort = wmo.define_wallet_cohort(training_profits_df_full,training_market_data_df)\n",
    "\n",
    "\n",
    "\n",
    "# Generate Cohort-Filtered Profits Data for Training Windows\n",
    "# ----------------------------------------------------------\n",
    "# Generate wallet_cohort-filtered profits_df for all training windows\n",
    "training_profits_df, training_windows_profits_dfs = wmo.split_training_window_profits_dfs(training_profits_df_full,\n",
    "                                                                         training_market_data_df,training_wallet_cohort)\n",
    "del training_profits_df_full,training_market_data_df\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "# Retrieve Transfers Data\n",
    "# ----------------------------------------------------------\n",
    "# Transfers data retrieval for the wallet_ids in temp.wallet_modeling_training_cohort\n",
    "training_transfers_sequencing_df = wts.retrieve_transfers_sequencing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Generate Features for the Full Training Period\n",
    "# ----------------------------------------------------------\n",
    "logger.info(\"Generating features for full training period...\")\n",
    "training_market_indicators_data_df = pd.read_parquet(\"temp/wallet_modeling_dfs/training_market_indicators_data_df.parquet\")\n",
    "training_wallet_features_df = wfo.calculate_wallet_features(training_profits_df,\n",
    "                                                            training_market_indicators_data_df,\n",
    "                                                            training_transfers_sequencing_df,\n",
    "                                                            training_wallet_cohort)\n",
    "\n",
    "# Define the start of training_data_df appending a suffix for the window\n",
    "training_data_df = training_wallet_features_df.add_suffix(\"_all_windows\")\n",
    "\n",
    "del training_profits_df,training_wallet_features_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature boundary dev space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = training_profits_df.copy()\n",
    "market_indicators_data_df = training_market_indicators_data_df.copy()\n",
    "transfers_sequencing_df = training_transfers_sequencing_df.copy()\n",
    "wallet_cohort = training_wallet_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize output dataframe\n",
    "wallet_features_df = pd.DataFrame(index=wallet_cohort)\n",
    "wallet_features_df.index.name = 'wallet_address'\n",
    "feature_column_names = {}\n",
    "\n",
    "# Trading features (inner join)\n",
    "# Requires both starting_balance_date and period_end_date imputed rows\n",
    "# -----------------------------------------------------------------------\n",
    "profits_df = wtf.add_cash_flow_transfers_logic(profits_df)\n",
    "trading_features_df = wtf.calculate_wallet_trading_features(profits_df)\n",
    "trading_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallets_config['training_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_balance_date = datetime.strptime(wallets_config['training_data']['training_starting_balance_date'],'%Y-%m-%d')\n",
    "profits_df = training_profits_df.copy()\n",
    "\n",
    "\n",
    "# Apply the filter and update the values\n",
    "profits_df.loc[profits_df['date'] == starting_balance_date, ['is_imputed', 'usd_net_transfers', 'usd_inflows']] = [True, 0, 0]\n",
    "profits_df[profits_df['date'] == starting_balance_date].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "profits_df = wtf.add_cash_flow_transfers_logic(profits_df)\n",
    "trading_features_df = wtf.calculate_wallet_trading_features(profits_df)\n",
    "trading_features_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "trading_features_df_new = wtf.calculate_wallet_trading_features_new(profits_df)\n",
    "trading_features_df_new.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 56836\n",
    "profits_df[profits_df['wallet_address']==w].sort_values(by=['coin_id','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Features for Each Individual Window\n",
    "# ----------------------------------------------------------\n",
    "# Generate features for each window\n",
    "for i, window_profits_df in enumerate(training_windows_profits_dfs, 1):\n",
    "    logger.info(\"Generating features for window %s...\", i)\n",
    "\n",
    "    # Generate the features\n",
    "    window_wallet_features_df = wfo.calculate_wallet_features(window_profits_df, training_market_indicators_data_df,\n",
    "                                                             training_transfers_sequencing_df, training_wallet_cohort)\n",
    "\n",
    "    # Check for NaN values and identify problematic columns\n",
    "    nan_columns = window_wallet_features_df.columns[window_wallet_features_df.isna().any()].tolist()\n",
    "    if nan_columns:\n",
    "        raise ValueError(f\"NaN values detected in window {i} in columns: {nan_columns}\")\n",
    "\n",
    "    # Add column suffix and join to training_data_df\n",
    "    window_wallet_features_df = window_wallet_features_df.add_suffix(f'_w{i}')\n",
    "    training_data_df = training_data_df.join(window_wallet_features_df, how='left')\n",
    "\n",
    "    # Check for NaN values and identify problematic columns\n",
    "    nan_columns = training_data_df.columns[training_data_df.isna().any()].tolist()\n",
    "    if nan_columns:\n",
    "        raise ValueError(f\"NaN values detected in training_data_df after window {i} in columns: {nan_columns}\")\n",
    "\n",
    "\n",
    "del window_profits_df,window_wallet_features_df,training_market_indicators_data_df,training_transfers_sequencing_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Clusters Using All Other Features\n",
    "# ----------------------------------------------------------\n",
    "# Append clustering features based on all numeric features in the base training data\n",
    "training_cluster_features_df = wcl.create_basic_cluster_features(training_data_df)\n",
    "training_cluster_features_df = training_cluster_features_df.add_prefix('cluster_')\n",
    "training_data_df = training_data_df.join(training_cluster_features_df, how='inner')\n",
    "\n",
    "\n",
    "\n",
    "# Save TRAINING_DATA_DF\n",
    "# ----------------------------------------------------------\n",
    "# Verify all input wallets exist in final output\n",
    "missing_wallets = set(training_wallet_cohort) - set(training_data_df.index)\n",
    "if missing_wallets:\n",
    "    raise ValueError(f\"Lost {len(missing_wallets)} wallets from original cohort during feature generation. First few missing: {list(missing_wallets)[:5]}\")\n",
    "\n",
    "# Save and clear from memory\n",
    "training_data_df.to_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\",index=True)\n",
    "del training_data_df,training_cluster_features_df\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "logger.info(\"Feature generation complete.\")\n",
    "logger.info(f\"Current large object memory usage: {u.obj_mem()['size_mb'].sum():.1f} MB\")\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve modeling datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve Modeling Profits and Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve full historical through modeling period datasets\n",
    "wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['modeling_period_start'],\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    parquet_prefix = 'modeling'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Load parquet files\n",
    "modeling_market_data_df_full = pd.read_parquet(\"temp/wallet_modeling_dfs/modeling_market_data_df_full.parquet\")\n",
    "modeling_profits_df_full = pd.read_parquet(\"temp/wallet_modeling_dfs/modeling_profits_df_full.parquet\")\n",
    "\n",
    "\n",
    "# Remove pre-modeling period prices\n",
    "modeling_market_data_df = modeling_market_data_df_full[modeling_market_data_df_full['date']\n",
    "                                                       >=wallets_config['training_data']['modeling_period_start']]\n",
    "del modeling_market_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Filter to only training wallet cohort\n",
    "training_wallet_cohort = pd.read_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\", columns=[]).index.values\n",
    "modeling_profits_df = modeling_profits_df_full[modeling_profits_df_full['wallet_address'].isin(training_wallet_cohort)]\n",
    "del modeling_profits_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Impute rows for period end\n",
    "modeling_profits_df = pri.impute_profits_for_multiple_dates(modeling_profits_df,\n",
    "                                                            modeling_market_data_df,\n",
    "                                                            [wallets_config['training_data']['modeling_period_end']],\n",
    "                                                            n_threads=24)\n",
    "\n",
    "\n",
    "# Assert period, save files, remove from memory\n",
    "u.assert_period(wallets_config,modeling_profits_df,'modeling')\n",
    "u.assert_period(wallets_config,modeling_market_data_df,'modeling')\n",
    "modeling_profits_df.to_parquet(\"temp/wallet_modeling_dfs/modeling_profits_df.parquet\",index=False)\n",
    "modeling_market_data_df.to_parquet(\"temp/wallet_modeling_dfs/modeling_market_data_df.parquet\",index=False)\n",
    "del modeling_profits_df,modeling_market_data_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define modeling cohort and features (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create training_cohort-Indexed modeling_wallet_features_df\n",
    "# -----------------------------------------------------------\n",
    "# Create a DataFrame with training wallet cohort as the index\n",
    "training_wallet_cohort = pd.read_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\", columns=[]).index.values\n",
    "modeling_wallet_features_df = pd.DataFrame(index=training_wallet_cohort)\n",
    "modeling_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "modeling_wallet_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Create training_cohort-Indexed modeling_wallet_features_df\n",
    "# -----------------------------------------------------------\n",
    "# Create a DataFrame with training wallet cohort as the index\n",
    "training_wallet_cohort = pd.read_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\", columns=[]).index.values\n",
    "modeling_wallet_features_df = pd.DataFrame(index=training_wallet_cohort)\n",
    "modeling_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "# Store feature sets with their prefixes for bulk renaming\n",
    "feature_column_names = {}\n",
    "\n",
    "\n",
    "# Identify Modeling Period Cohort\n",
    "# -----------------------------------------------------------\n",
    "# Retrieve modeling wallet cohort after applying modeling period activity filters\n",
    "modeling_profits_df = pd.read_parquet(\"temp/wallet_modeling_dfs/modeling_profits_df.parquet\")\n",
    "modeling_wallet_cohort_trading_features_df = wmo.identify_modeling_cohort(modeling_profits_df)\n",
    "modeling_wallet_features_df = modeling_wallet_features_df.join(modeling_wallet_cohort_trading_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in modeling_wallet_cohort_trading_features_df.columns})\n",
    "\n",
    "\n",
    "# Generate Modeling Period Performance Features\n",
    "# -----------------------------------------------------------\n",
    "# Calculate performance metrics for the modeling cohort only\n",
    "modeling_modeling_cohort_performance_features_df = (wpf.calculate_performance_features(\n",
    "    modeling_wallet_features_df[modeling_wallet_features_df['in_modeling_cohort']==1])\n",
    "    .copy()\n",
    "    .drop(['max_investment', 'total_net_flows'], axis=1))\n",
    "\n",
    "# Calculate performance metrics for the training cohort (wallets with 0 activity still impact rank orders)\n",
    "modeling_training_cohort_performance_features_df = (wpf.calculate_performance_features(\n",
    "    modeling_wallet_features_df)\n",
    "    .copy()\n",
    "    .drop(['max_investment', 'total_net_flows'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_wallet_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = modeling_wallet_features_df[['max_investment','total_net_flows','cash_net_flows']].copy().round(6)\n",
    "returns_winsorization = wallets_config['modeling']['returns_winsorization']\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Calculate base return, including unrealized price change impacts\n",
    "metrics_df['return'] = np.where(abs(metrics_df['max_investment']) == 0,0,\n",
    "                                metrics_df['total_net_flows'] / metrics_df['max_investment'])\n",
    "\n",
    "# Calculate realized return, based on actual cash flows only\n",
    "metrics_df['realized_return'] = np.where(abs(metrics_df['max_investment']) == 0,0,\n",
    "                                metrics_df['cash_net_flows'] / metrics_df['max_investment'])\n",
    "\n",
    "# Apply winsorization\n",
    "if returns_winsorization > 0:\n",
    "    metrics_df['return_unwinsorized'] = metrics_df['return']\n",
    "    metrics_df['return'] = u.winsorize(metrics_df['return'],returns_winsorization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_wallet_cohort_trading_features_df.loc[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 8619465\n",
    "adj_profits_df = wtf.add_cash_flow_transfers_logic(modeling_profits_df.copy())\n",
    "adj_profits_df[adj_profits_df['wallet_address']==w].sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.sort_values(by='realized_return',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_training_cohort_performance_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_modeling_cohort_performance_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names['modeling_cohort_'] = modeling_cohort_performance_features_df.columns\n",
    "feature_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_wallet_cohort_trading_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_wallet_cohort_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_wallet_cohort_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Join trading features and in_modeling_cohort boolean\n",
    "modeling_wallet_features_df = modeling_wallet_features_df.join(modeling_wallet_cohort_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in modeling_wallet_cohort_features_df.columns})\n",
    "\n",
    "# Join performance features\n",
    "modeling_wallet_features_df = modeling_wallet_features_df.join(modeling_performance_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in modeling_performance_features_df.columns})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_profits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select target variable and build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create MODELING_DF and Construct Wallet Model\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "training_data_df = pd.read_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\")\n",
    "\n",
    "# Filter training data to only the modeling cohort through inner join to target variable\n",
    "modeling_cohort_target_var_df = modeling_wallet_features_df[['in_modeling_cohort', wallets_config['modeling']['target_variable']]]\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config)\n",
    "model_results = wallet_model.run_experiment(training_data_df,modeling_cohort_target_var_df)\n",
    "del training_data_df\n",
    "gc.collect()\n",
    "\n",
    "# Extract the trained model\n",
    "model = model_results['pipeline'].named_steps['regressor']\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, evaluator, wallet_scores_df = wmr.generate_and_save_model_artifacts(\n",
    "    model_results=model_results,\n",
    "    base_path='../wallet_modeling'\n",
    ")\n",
    "u.notify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_cohort_target_var_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess wallet model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Reload evaluator\n",
    "evaluator = wime.RegressionEvaluator(\n",
    "    y_train=model_results['y_train'],\n",
    "    y_true=model_results['y_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    training_cohort_pred=model_results['training_cohort_pred'],\n",
    "    training_cohort_actuals=model_results['training_cohort_actuals'],\n",
    "    model=model,\n",
    "    feature_names=model_results['X_train'].columns.tolist()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(evaluator.summary_report())\n",
    "evaluator.plot_evaluation()\n",
    "\n",
    "evaluator.importance_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_results['training_cohort_pred']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# List of the x features with the highest importance in the model\n",
    "x_features = 8\n",
    "top_feature_metrics = list((pd.DataFrame(evaluator.metrics['importances'])\n",
    "                      .sort_values(by='importance',ascending=False)\n",
    "                      .head(x_features)['feature']))\n",
    "all_metrics = list(set(top_feature_metrics))\n",
    "\n",
    "# Cluster numbers\n",
    "n_clusters=4\n",
    "\n",
    "styled_df = wime.create_cluster_report(modeling_df, model_results, n_clusters, all_metrics)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Validation Period Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve Validation Profits and Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve full historical through validation period datasets\n",
    "wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['validation_period_start'],\n",
    "    wallets_config['training_data']['validation_period_end'],\n",
    "    parquet_prefix = 'validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Load parquet files\n",
    "validation_market_data_df_full = pd.read_parquet(\"temp/wallet_modeling_dfs/validation_market_data_df_full.parquet\")\n",
    "validation_profits_df_full = pd.read_parquet(\"temp/wallet_modeling_dfs/validation_profits_df_full.parquet\")\n",
    "\n",
    "# Remove pre-validation period prices\n",
    "validation_market_data_df = validation_market_data_df_full[validation_market_data_df_full['date']\n",
    "                                                       >=wallets_config['training_data']['validation_period_start']]\n",
    "del validation_market_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Filter to only training wallet cohort\n",
    "training_wallet_cohort = pd.read_parquet(\"temp/wallet_modeling_dfs/training_data_df.parquet\", columns=[]).index.values\n",
    "validation_profits_df = validation_profits_df_full[validation_profits_df_full['wallet_address'].isin(training_wallet_cohort)]\n",
    "del validation_profits_df_full\n",
    "gc.collect()\n",
    "\n",
    "# Impute rows for period end\n",
    "validation_profits_df = pri.impute_profits_for_multiple_dates(validation_profits_df,\n",
    "                                                              validation_market_data_df,\n",
    "                                                              [wallets_config['training_data']['validation_period_end']],\n",
    "                                                              n_threads=24)\n",
    "\n",
    "\n",
    "# Assert period, save files, remove from memory\n",
    "u.assert_period(wallets_config,validation_profits_df,'validation')\n",
    "u.assert_period(wallets_config,validation_market_data_df,'validation')\n",
    "validation_profits_df.to_parquet(\"temp/wallet_modeling_dfs/validation_profits_df.parquet\",index=False)\n",
    "validation_market_data_df.to_parquet(\"temp/wallet_modeling_dfs/validation_market_data_df.parquet\",index=False)\n",
    "del validation_profits_df,validation_market_data_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate wallet_validation_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Load parquet\n",
    "validation_profits_df = pd.read_parquet(\"temp/wallet_modeling_dfs/modeling_profits_df.parquet\")\n",
    "validation_market_data_df = pd.read_parquet(\"temp/wallet_modeling_dfs/validation_market_data_df.parquet\")\n",
    "\n",
    "\n",
    "# Create a DataFrame with all wallets that should exist\n",
    "validation_wallet_features_df = pd.DataFrame(index=training_wallet_cohort)\n",
    "validation_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "\n",
    "# Calculate modeling period wallet metrics\n",
    "validation_profits_df = wtf.add_cash_flow_transfers_logic(validation_profits_df)\n",
    "trading_features_df = wtf.calculate_wallet_trading_features(validation_profits_df)\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(trading_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in trading_features_df.columns})\n",
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features_df = (wpf.calculate_performance_features(validation_wallet_features_df)\n",
    "                                .drop(['max_investment', 'total_net_flows'], axis=1))  # already exist as trading features\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(performance_features_df, how='inner')\n",
    "validation_wallet_features_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wallet validation period trading/performance by score quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create analysis by prediction bands\n",
    "metrics = [\n",
    "    'return',\n",
    "    'realized_return',\n",
    "    'return_unwinsorized',\n",
    "    'max_investment',\n",
    "    'total_net_flows',\n",
    "    'cash_net_flows',\n",
    "    'total_volume',\n",
    "]\n",
    "\n",
    "min_wallet_volume_usd = 1000\n",
    "num_quantiles = 5\n",
    "\n",
    "wiwv.create_quantile_report(\n",
    "    validation_wallet_features_df,\n",
    "    model_results['y_pred'],\n",
    "    metrics,  # Your existing metrics list\n",
    "    num_quantiles,  # Split into quintiles\n",
    "    min_wallet_volume_usd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coin-aggregated wallet metrics by coin performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate coin-level features about wallet behavior during the\n",
    "coin_wallet_features_df = wicv.calculate_coin_metrics_from_wallet_scores(\n",
    "    validation_profits_df,\n",
    "    wallet_scores_df,\n",
    "    validation_market_data_df\n",
    ")\n",
    "\n",
    "# Filter coins by market cap\n",
    "analyze_df = coin_wallet_features_df[\n",
    "    (coin_wallet_features_df['market_cap_filled'] >= wallets_config['coin_validation_analysis']['min_market_cap'])\n",
    "    & (coin_wallet_features_df['market_cap_filled'] <= wallets_config['coin_validation_analysis']['max_market_cap'])\n",
    "].copy()\n",
    "\n",
    "# Create styled performance analysis\n",
    "wicv.create_top_coins_wallet_metrics_report(analyze_df,percentile=90,method='median')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic coin model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# 1. Generate model scores (using existing wallet model results)\n",
    "wallet_scores_df = pd.DataFrame({\n",
    "    'score': model_results['y_pred']\n",
    "}, index=model_results['X_test'].index)\n",
    "\n",
    "# 2. Prepare the modeling dataset using modeling period data\n",
    "coin_modeling_df = wicm.prepare_features_and_targets(\n",
    "    coin_validation_df=coin_validation_df,\n",
    "    modeling_profits_df=modeling_profits_df,\n",
    "    modeling_market_data_df=modeling_market_data_df,\n",
    "    wallet_scores_df=wallet_scores_df\n",
    ")\n",
    "\n",
    "# 3. Train model and get evaluation\n",
    "model, evaluator = wicm.train_coin_prediction_model(coin_modeling_df)\n",
    "\n",
    "# 4. View results\n",
    "print(evaluator.summary_report())\n",
    "evaluator.plot_evaluation()\n",
    "\n",
    "# 5. Optional: Generate feature importance summary\n",
    "evaluator.importance_summary()\n",
    "\n",
    "# 6. Optional: Analyze predictions by market cap segment\n",
    "predictions_df = pd.DataFrame({\n",
    "    'y_true': evaluator.y_true,\n",
    "    'y_pred': evaluator.y_pred,\n",
    "    'market_cap': coin_modeling_df['market_cap_filled']\n",
    "})\n",
    "\n",
    "segment_results, summary_df = wicv.analyze_market_cap_segments(predictions_df)\n",
    "wicv.plot_segment_heatmap(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all wallets that should exist\n",
    "validation_wallet_features_df = pd.DataFrame(index=wallet_cohort)\n",
    "validation_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "\n",
    "# Calculate modeling period wallet metrics\n",
    "validation_profits_df = wtf.add_cash_flow_transfers_logic(validation_profits_df)\n",
    "trading_features_df = wtf.calculate_wallet_trading_features(validation_profits_df)\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(trading_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in trading_features_df.columns})\n",
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features_df = (wpf.calculate_performance_features(validation_wallet_features_df)\n",
    "                                .drop(['max_investment', 'total_net_flows'], axis=1))  # already exist as trading features\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(performance_features_df, how='inner')\n",
    "validation_wallet_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create coin_modeling_df\n",
    "coin_modeling_df = coin_wallet_features_df.copy().drop('market_cap',axis=1)\n",
    "coin_modeling_df['coin_return_unwinsorized'] = coin_modeling_df['coin_return']\n",
    "coin_modeling_df['coin_return'] = u.winsorize(coin_modeling_df['coin_return'],0.05)\n",
    "\n",
    "# Filter coins by market cap\n",
    "coin_modeling_df = coin_modeling_df[\n",
    "    (coin_modeling_df['market_cap_filled'] >= wallets_config['coin_validation_analysis']['min_market_cap'])\n",
    "    & (coin_modeling_df['market_cap_filled'] <= wallets_config['coin_validation_analysis']['max_market_cap'])\n",
    "].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_modeling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coin_modeling_df.copy()\n",
    "\n",
    "# 1. Simple feature prep and model\n",
    "X, y = wicm.prepare_features(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate with the fancy evaluator\n",
    "feature_names = df.columns.drop(['coin_return', 'market_cap_filled']).tolist()\n",
    "evaluator = wime.RegressionEvaluator(y_train, y_test, y_pred, model=model, feature_names=feature_names)\n",
    "\n",
    "# 5. Get the goods\n",
    "print(evaluator.summary_report())\n",
    "\n",
    "# 6. Plot everything\n",
    "evaluator.plot_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modeling dataset using existing pipeline\n",
    "modeling_wallets_df = wmo.filter_modeling_period_wallets(modeling_profits_df)\n",
    "target_vars_df = wpf.calculate_performance_features(modeling_wallets_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model artifacts\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# 1. Initialize dependencies\n",
    "metrics_config = {\n",
    "    'rmse': lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': r2_score\n",
    "}\n",
    "\n",
    "# 2. Define experiment sequence\n",
    "sequence_config = {\n",
    "    'run_baseline': True,\n",
    "    'parameter_variations': {\n",
    "        'modeling': {\n",
    "            'target_variable': [\n",
    "                'max_investment',\n",
    "                'total_net_flows',\n",
    "                'return',\n",
    "                'realized_return',\n",
    "                'return_unwinsorized',\n",
    "                'performance_score',\n",
    "                'size_adjusted_rank'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Create experiment manager\n",
    "exp_manager = wem.ExperimentsManager(\n",
    "    config=wallets_config.config,\n",
    "    training_data_df=training_data_df,\n",
    ")\n",
    "\n",
    "# 4. Run experiments and get results\n",
    "results_df = exp_manager.run_experiment_sequence(modeling_profits_df, sequence_config)\n",
    "\n",
    "# 5. View results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation period assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wallet_performance_df, bucketed_performance_df = wicv.calculate_validation_metrics(\n",
    "    X_test=model_results['X_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    validation_profits_df=validation_profits_df,\n",
    "    n_buckets=10,\n",
    "    method='ntiles'\n",
    ")\n",
    "\n",
    "bucketed_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coin performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare wallet metrics for the top n% of coins vs the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Partition coin features for analysis\n",
    "analyze_df = coin_wallet_features_df[\n",
    "    (coin_wallet_features_df['market_cap_filled'] >= wallets_config['coin_validation_analysis']['min_market_cap'])\n",
    "    & (coin_wallet_features_df['market_cap_filled'] <= wallets_config['coin_validation_analysis']['max_market_cap'])\n",
    "].copy()\n",
    "\n",
    "# Create styled performance analysis\n",
    "styled_df = wicv.create_top_coins_wallet_metrics_report(analyze_df,percentile=90,method='median')\n",
    "\n",
    "# Display results\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = wicv.analyze_market_cap_segments(\n",
    "    coin_wallet_features_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "wicv.plot_segment_heatmap(summary_df)\n",
    "wicv.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_validation_analysis']['top_n']\n",
    "max_market_cap = wallets_config['coin_validation_analysis']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_validation_analysis']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = wicv.validate_coin_performance(coin_wallet_features_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare performance of high vs low score coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_wallet_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wicv.print_performance_analysis(coin_wallet_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProfitsValidator:\n",
    "    \"\"\"\n",
    "    Validates profits DataFrame follows expected format and constraints.\n",
    "    Only validates training period data.\n",
    "    \"\"\"\n",
    "    def validate_all(self, profits_df, training_period_start, training_period_end):\n",
    "        \"\"\"Run all validation checks and return dict of results\"\"\"\n",
    "        dates = {\n",
    "            'training_period_start': pd.to_datetime(training_period_start),\n",
    "            'training_period_end': pd.to_datetime(training_period_end),\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'no_duplicates': self.check_no_duplicates(profits_df),\n",
    "            'period_boundaries': self.check_period_boundaries(profits_df, dates),\n",
    "            'no_negatives': self.check_no_negative_balances(profits_df),\n",
    "            'date_range': self.check_date_range(profits_df, dates),\n",
    "            'no_missing': self.check_no_missing_values(profits_df)\n",
    "        }\n",
    "\n",
    "    def check_no_duplicates(self, profits_df):\n",
    "        \"\"\"Check for duplicate records\"\"\"\n",
    "        deduped_df = profits_df[['coin_id', 'wallet_address', 'date']].drop_duplicates()\n",
    "        return len(profits_df) == len(deduped_df)\n",
    "\n",
    "    def check_period_boundaries(self, profits_df, dates):\n",
    "        \"\"\"Check records exist at period boundaries\"\"\"\n",
    "        profits_df['date'] = pd.to_datetime(profits_df['date'])\n",
    "        pairs = profits_df[['coin_id', 'wallet_address']].drop_duplicates()\n",
    "        n_pairs = len(pairs)\n",
    "\n",
    "        period_df = profits_df[profits_df['date'] == dates['training_period_end']]\n",
    "        period_pairs = period_df[['coin_id', 'wallet_address']].drop_duplicates()\n",
    "        return len(period_pairs) == n_pairs\n",
    "\n",
    "    def check_no_negative_balances(self, profits_df):\n",
    "        \"\"\"Check for negative USD balances\"\"\"\n",
    "        return (profits_df['usd_balance'] >= -0.1).all()\n",
    "\n",
    "    def check_date_range(self, profits_df, dates):\n",
    "        \"\"\"Verify date coverage\"\"\"\n",
    "        profits_df['date'] = pd.to_datetime(profits_df['date'])\n",
    "        return (profits_df['date'].min() >= dates['training_period_start'] and\n",
    "                profits_df['date'].max() == dates['training_period_end'])\n",
    "\n",
    "    def check_no_missing_values(self, profits_df):\n",
    "        \"\"\"Check for missing values\"\"\"\n",
    "        return not profits_df.isna().any().any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pylint:disable=line-too-long\n",
    "\n",
    "def test_profits_data():\n",
    "    \"\"\"\n",
    "    Returns raw profits data that can be remapped for many-to-many testing.\n",
    "    \"\"\"\n",
    "    profits_data = [\n",
    "        # w01_multiple_coins - btc & eth (multiple transactions, multiple coins)\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w01_multiple_coins', 'date': '2024-01-01', 'usd_balance': 100, 'usd_net_transfers': 100, 'is_imputed': False},\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w01_multiple_coins', 'date': '2024-05-01', 'usd_balance': 120, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w01_multiple_coins', 'date': '2024-10-01', 'usd_balance': 180, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        {'coin_id': 'eth', 'wallet_address': 'w01_multiple_coins', 'date': '2024-01-01', 'usd_balance': 200, 'usd_net_transfers': 200, 'is_imputed': False},\n",
    "        {'coin_id': 'eth', 'wallet_address': 'w01_multiple_coins', 'date': '2024-05-01', 'usd_balance': 300, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "        {'coin_id': 'eth', 'wallet_address': 'w01_multiple_coins', 'date': '2024-10-01', 'usd_balance': 280, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w02_net_loss - btc (net loss)\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w02_net_loss', 'date': '2024-01-01', 'usd_balance': 300, 'usd_net_transfers': 300, 'is_imputed': False},\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w02_net_loss', 'date': '2024-05-01', 'usd_balance': 250, 'usd_net_transfers': -100, 'is_imputed': False},\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w02_net_loss', 'date': '2024-10-01', 'usd_balance': 100, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w03_sell_all_and_rebuy\n",
    "        {'coin_id': 'eth', 'wallet_address': 'w03_sell_all_and_rebuy', 'date': '2024-01-01', 'usd_balance': 50, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "        {'coin_id': 'eth', 'wallet_address': 'w03_sell_all_and_rebuy', 'date': '2024-03-01', 'usd_balance': 0,  'usd_net_transfers': -50, 'is_imputed': False},\n",
    "        {'coin_id': 'eth', 'wallet_address': 'w03_sell_all_and_rebuy', 'date': '2024-08-01', 'usd_balance': 40, 'usd_net_transfers': 40, 'is_imputed': False},\n",
    "        {'coin_id': 'eth', 'wallet_address': 'w03_sell_all_and_rebuy', 'date': '2024-10-01', 'usd_balance': 42, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w04_only_period_end - btc (only final row)\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w04_only_period_end', 'date': '2024-10-01', 'usd_balance': 70, 'usd_net_transfers': 70, 'is_imputed': False},\n",
    "\n",
    "        # w04a_only_period_end_w_balance - btc\n",
    "        {'coin_id': 'eth', 'wallet_address': 'w04a_only_period_end_w_balance', 'date': '2024-01-01', 'usd_balance': 30, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "        {'coin_id': 'eth', 'wallet_address': 'w04a_only_period_end_w_balance', 'date': '2024-10-01', 'usd_balance': 90, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "\n",
    "        # w04b_only_period_start_buy\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w04b_only_period_start_buy', 'date': '2024-01-01', 'usd_balance': 300, 'usd_net_transfers': 300, 'is_imputed': False},\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w04b_only_period_start_buy', 'date': '2024-10-01', 'usd_balance': 900, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w04c_only_period_start_buy_w_existing_balance\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w04c_only_period_start_buy_w_existing_balance', 'date': '2024-01-01', 'usd_balance': 350, 'usd_net_transfers': 300, 'is_imputed': False},\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w04c_only_period_start_buy_w_existing_balance', 'date': '2024-10-01', 'usd_balance': 1050, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w04d_only_period_start_sell\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w04d_only_period_start_sell', 'date': '2024-01-01', 'usd_balance': 0, 'usd_net_transfers': -200, 'is_imputed': False},\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w04d_only_period_start_sell', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w04e_only_period_start_sell_partial\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w04e_only_period_start_sell_partial', 'date': '2024-01-01', 'usd_balance': 500, 'usd_net_transfers': -10, 'is_imputed': False},\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w04e_only_period_start_sell_partial', 'date': '2024-10-01', 'usd_balance': 600, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w05_only_imputed - btc (only imputed rows at start and end)\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w05_only_imputed', 'date': '2024-01-01', 'usd_balance': 50, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w05_only_imputed', 'date': '2024-10-01', 'usd_balance': 70, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w06_tiny_transactions - very small transactions relative to portfolio size\n",
    "        {'coin_id': 'myro', 'wallet_address': 'w06_tiny_transactions', 'date': '2024-01-01', 'usd_balance': 1250, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "        {'coin_id': 'myro', 'wallet_address': 'w06_tiny_transactions', 'date': '2024-02-01', 'usd_balance': 1220, 'usd_net_transfers': 1, 'is_imputed': False},\n",
    "        {'coin_id': 'myro', 'wallet_address': 'w06_tiny_transactions', 'date': '2024-08-01', 'usd_balance': 0, 'usd_net_transfers': -350, 'is_imputed': False},\n",
    "        {'coin_id': 'myro', 'wallet_address': 'w06_tiny_transactions', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w07_tiny_transactions2 - very small transactions relative to portfolio size\n",
    "        {'coin_id': 'floki', 'wallet_address': 'w07_tiny_transactions2', 'date': '2024-01-01', 'usd_balance': 400, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "        {'coin_id': 'floki', 'wallet_address': 'w07_tiny_transactions2', 'date': '2024-02-01', 'usd_balance': 1220, 'usd_net_transfers': -20, 'is_imputed': False},\n",
    "        {'coin_id': 'floki', 'wallet_address': 'w07_tiny_transactions2', 'date': '2024-08-01', 'usd_balance': 0, 'usd_net_transfers': -150, 'is_imputed': False},\n",
    "        {'coin_id': 'floki', 'wallet_address': 'w07_tiny_transactions2', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w08_offsetting_transactions - large offsetting transactions in the middle of the period\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w08_offsetting_transactions', 'date': '2024-01-01', 'usd_balance': 500, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w08_offsetting_transactions', 'date': '2024-02-01', 'usd_balance': 10400, 'usd_net_transfers': 10000, 'is_imputed': False},\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w08_offsetting_transactions', 'date': '2024-02-02', 'usd_balance': 400, 'usd_net_transfers': -10000, 'is_imputed': False},\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w08_offsetting_transactions', 'date': '2024-10-01', 'usd_balance': 750, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w09_memecoin_winner - Large swings in portfolio value\n",
    "        {'coin_id': 'floki', 'wallet_address': 'w09_memecoin_winner', 'date': '2024-01-01', 'usd_balance': 100, 'usd_net_transfers': 100, 'is_imputed': False},\n",
    "        {'coin_id': 'floki', 'wallet_address': 'w09_memecoin_winner', 'date': '2024-03-01', 'usd_balance': 250, 'usd_net_transfers': -500, 'is_imputed': False},\n",
    "        {'coin_id': 'floki', 'wallet_address': 'w09_memecoin_winner', 'date': '2024-05-01', 'usd_balance': 50, 'usd_net_transfers': -100, 'is_imputed': False},\n",
    "        {'coin_id': 'floki', 'wallet_address': 'w09_memecoin_winner', 'date': '2024-10-01', 'usd_balance': 10, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w10_memecoin_loser - Large swings in portfolio value\n",
    "        {'coin_id': 'myro', 'wallet_address': 'w10_memecoin_loser', 'date': '2024-03-01', 'usd_balance': 250, 'usd_net_transfers': 250, 'is_imputed': False},\n",
    "        {'coin_id': 'myro', 'wallet_address': 'w10_memecoin_loser', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': -20, 'is_imputed': False},\n",
    "\n",
    "        # w11_sells_early\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w11_sells_early', 'date': '2024-03-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w11_sells_early', 'date': '2024-04-01', 'usd_balance': 250, 'usd_net_transfers': 250, 'is_imputed': False},\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w11_sells_early', 'date': '2024-5-01', 'usd_balance': 0, 'usd_net_transfers': -300, 'is_imputed': False},\n",
    "        {'coin_id': 'btc', 'wallet_address': 'w11_sells_early', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "        # w12_buys_late\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w12_buys_late', 'date': '2024-03-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w12_buys_late', 'date': '2024-09-01', 'usd_balance': 500, 'usd_net_transfers': 250, 'is_imputed': False},\n",
    "        {'coin_id': 'sol', 'wallet_address': 'w12_buys_late', 'date': '2024-10-01', 'usd_balance': 550, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(profits_data)\n",
    "\n",
    "\n",
    "\n",
    "test_profits_data = test_profits_data()\n",
    "\n",
    "def test_profits_df(test_profits_data):\n",
    "    \"\"\"\n",
    "    Returns test profits DataFrame with cash flow transfers added.\n",
    "    \"\"\"\n",
    "    profits_df = test_profits_data.copy()\n",
    "    training_period_start = '2024-01-01'\n",
    "    training_period_end = '2024-10-01'\n",
    "\n",
    "    # Validate test data format before proceeding\n",
    "    validator = ProfitsValidator()\n",
    "    validation_results = validator.validate_all(\n",
    "        profits_df,\n",
    "        training_period_start,\n",
    "        training_period_end\n",
    "    )\n",
    "    assert all(validation_results.values()), \"Test data failed validation checks.\"\n",
    "\n",
    "    # Remove rows with a rounded 0 balance and 0 transfers which happens in wmo.retrieve_datasets() once validation checks are passed\n",
    "    profits_df = profits_df[\n",
    "        ~((profits_df['usd_balance'] == 0) &\n",
    "        (profits_df['usd_net_transfers'] == 0))\n",
    "    ]\n",
    "\n",
    "    # Add cash flow transfers logic\n",
    "    cash_flow_profits_df = wtf.add_cash_flow_transfers_logic(profits_df)\n",
    "\n",
    "    return cash_flow_profits_df\n",
    "\n",
    "test_profits_df = test_profits_df(test_profits_data)\n",
    "\n",
    "test_trading_features_df = wtf.calculate_wallet_trading_features(test_profits_df)\n",
    "test_trading_features_df_new = wtf.calculate_wallet_trading_features_new(test_profits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test wallet with multiple coins and transactions.\n",
    "\n",
    "Scenario:\n",
    "- Two coins (BTC, ETH)\n",
    "- Multiple transactions per coin\n",
    "- Mix of real and imputed rows\n",
    "\"\"\"\n",
    "# Get w01 data\n",
    "wallet = 'w01_multiple_coins'\n",
    "w01_profits = test_profits_df[test_profits_df['wallet_address'] == wallet]\n",
    "w01_features = test_trading_features_df.loc[wallet]\n",
    "\n",
    "# Test basic metrics\n",
    "assert w01_features['transaction_days'] == 2  # Jan 1 and May 1\n",
    "assert w01_features['unique_coins_traded'] == 2  # BTC and ETH\n",
    "assert w01_features['cash_buy_inflows'] == 400  # Initial: BTC 100 + ETH 200, Add: BTC 50 + ETH 50\n",
    "\n",
    "# Test volume metrics\n",
    "assert w01_features['total_volume'] == 400  # Sum of all transfers\n",
    "assert w01_features['average_transaction'] == 100  # 400 / 4 transactions\n",
    "\n",
    "# Test imputed metrics\n",
    "assert w01_features['total_inflows'] == 400  # Initial balances\n",
    "assert w01_features['total_net_flows'] > 0  # Should be profitable given ending balances > deposits\n",
    "\n",
    "# Test activity metrics\n",
    "total_days = (w01_profits['date'].max() - w01_profits['date'].min()).days + 1\n",
    "assert w01_features['activity_density'] == pytest.approx(2 / total_days, rel=1e-10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w01_profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w01_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trading_features_df_new.loc[wallet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w01_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
