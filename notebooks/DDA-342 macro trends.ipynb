{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Custom format function for displaying numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import training_data as td\n",
    "import feature_engineering as fe\n",
    "import coin_wallet_metrics as cwm\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.model_input_flows as mf\n",
    "import utils as u\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [td, fe, cwm, m, ia, mf, u]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    importlib.reload(module)\n",
    "\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Initialize empty lists to hold concatenated data\n",
    "X_train_list, X_test_list = [], []\n",
    "y_train_list, y_test_list = [], []\n",
    "returns_test_list = []\n",
    "\n",
    "# Generate time_windows config overrides that will modify each window's config settings\n",
    "time_windows = mf.generate_time_windows(config)\n",
    "\n",
    "for n, window in enumerate(time_windows):\n",
    "\n",
    "    model_data = mf.build_time_window_model_input(n, window, config, metrics_config, modeling_config)\n",
    "\n",
    "    # Append the current window's data to the lists\n",
    "    X_train_list.append(model_data['X_train'])\n",
    "    X_test_list.append(model_data['X_test'])\n",
    "    y_train_list.append(model_data['y_train'])\n",
    "    y_test_list.append(model_data['y_test'])\n",
    "    returns_test_list.append(model_data['returns_test'])\n",
    "\n",
    "\n",
    "# Concatenate all the data for each part\n",
    "X_train = pd.concat(X_train_list, axis=0)\n",
    "X_test = pd.concat(X_test_list, axis=0)\n",
    "y_train = pd.concat(y_train_list, axis=0)\n",
    "y_test = pd.concat(y_test_list, axis=0)\n",
    "returns_test = pd.concat(returns_test_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    importlib.reload(module)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "model, model_id = m.train_model(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    modeling_folder,\n",
    "                    modeling_config)\n",
    "\n",
    "# 3.5 Evaluate and save the model performance on the test set to a CSV\n",
    "metrics_dict, y_pred, y_pred_prob = m.evaluate_model(model, X_test, y_test, model_id, returns_test, modeling_config)\n",
    "\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    importlib.reload(module)\n",
    "\n",
    "\n",
    "# Select y_pred_prob from the classifier, or y_pred from a regressor\n",
    "predictions = y_pred_prob or y_pred\n",
    "returns = returns_test['returns']\n",
    "winsorization_cutoff = modeling_config[\"evaluation\"][\"winsorization_cutoff\"]\n",
    "\n",
    "\n",
    "ia.generate_profitability_curves(predictions, returns, winsorization_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Winsorize the returns (apply caps to the top n % of values)\n",
    "returns_winsorized = m.winsorize(returns, winsorization_cutoff)\n",
    "\n",
    "# Merge datasets\n",
    "df = pd.DataFrame({\n",
    "    'predictions': predictions,\n",
    "    'returns': returns_winsorized,\n",
    "})\n",
    "\n",
    "# Sort by actual returns to obtain optimal performance\n",
    "df_sorted = df.sort_values('returns', ascending=False)\n",
    "cumulative_best_returns = np.cumsum(df_sorted['returns'])\n",
    "cumulative_best_avg_returns = df_sorted['returns'].expanding().mean()\n",
    "\n",
    "# Sort by model score to obtain modeled performance\n",
    "df_sorted = df.sort_values('predictions', ascending=False)\n",
    "cumulative_model_returns = np.cumsum(df_sorted['returns'])\n",
    "cumulative_model_avg_returns = df_sorted['returns'].expanding().mean()\n",
    "\n",
    "# Create subplots for side-by-side plots\n",
    "_, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# First plot: Cumulative Returns Performance\n",
    "axes[0].plot(cumulative_best_returns.values, label='Optimal Performance')\n",
    "axes[0].plot(cumulative_model_returns.values, label='Model Performance')\n",
    "axes[0].set_title('Cumulative Returns Performance')\n",
    "axes[0].set_ylabel('Cumulative Returns')\n",
    "axes[0].set_xlabel('Rank Number')\n",
    "axes[0].legend()\n",
    "\n",
    "# Second plot: Average Returns Performance\n",
    "axes[1].plot(cumulative_best_avg_returns.values, label='Optimal Avg Performance')\n",
    "axes[1].plot(cumulative_model_avg_returns.values, label='Model Avg Performance')\n",
    "axes[1].set_title('Average Returns Performance')\n",
    "axes[1].set_ylabel('Average Returns')\n",
    "axes[1].set_xlabel('Rank Number')\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = None\n",
    "\n",
    "if profits_df:\n",
    "    print('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two cumulative return series\n",
    "plt.plot(cumulative_best_returns.values, label='Optimal Performance')\n",
    "plt.plot(cumulative_model_returns.values, label='Model Performance')\n",
    "\n",
    "# Set the labels\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.xlabel('Rank Number')  # No label on the x-axis\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('returns', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values('predictions', ascending=False)\n",
    "\n",
    "df_sorted['cumulative_returns'] = np.cumsum(df_sorted['returns'])\n",
    "\n",
    "df_sorted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "google_trends_df = td.retrieve_google_trends_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "training_data_tuples = []\n",
    "\n",
    "# 1. Generate and merge features for all datasets\n",
    "# -------------------------------------\n",
    "# Time series features\n",
    "dataset_name = 'market_data'  # update to loop through all time series\n",
    "market_data_tuples, _ = fe.generate_time_series_features(\n",
    "        dataset_name,\n",
    "        market_data_df,\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )\n",
    "training_data_tuples.extend(market_data_tuples)\n",
    "\n",
    "# Wallet cohort features\n",
    "wallet_cohort_tuples, _ = fe.generate_wallet_cohort_features(\n",
    "        profits_df,\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )\n",
    "training_data_tuples.extend(wallet_cohort_tuples)\n",
    "\n",
    "# Google trends features\n",
    "dataset_name = 'google_trends'  # update to loop through all macro trends\n",
    "google_trends_tuples, _ = fe.generate_macro_trends_features(\n",
    "        dataset_name,\n",
    "        google_trends_df,\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )\n",
    "training_data_tuples.extend(google_trends_tuples)\n",
    "\n",
    "# Merge all the features\n",
    "training_data_df, _ = fe.create_training_data_df(\n",
    "                        modeling_config['modeling']['modeling_folder'],\n",
    "                        training_data_tuples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = config['datasets']['macro_trends'][dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# set parameters\n",
    "dataset_name = 'google_trends'\n",
    "dataset_df = google_trends_df\n",
    "config,\n",
    "metrics_config,\n",
    "modeling_config\n",
    "\n",
    "training_data_tuples, training_data_dfs = fe.generate_macro_trends_features(\n",
    "        dataset_name,\n",
    "        dataset_df,\n",
    "        config,\n",
    "        metrics_config,\n",
    "        modeling_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_config['macro_trends'][dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = config['datasets']['macro_trends'][dataset_name]\n",
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten metrics\n",
    "flattened_features = fe.flatten_date_features(value_column_metrics_df,dataset_metrics_config)\n",
    "flattened_google_trends_df = pd.DataFrame([flattened_features])\n",
    "\n",
    "# save flattened metrics\n",
    "flattened_google_trends_df, flattened_google_trends_filepath = fe.save_flattened_outputs(\n",
    "    flattened_google_trends_df,\n",
    "    os.path.join(\n",
    "        modeling_config['modeling']['modeling_folder'],  # Folder to store flattened outputs\n",
    "        'outputs/flattened_outputs'\n",
    "    ),\n",
    "    value_column_config['description'],  # Descriptive metadata for the dataset\n",
    "    config['training_data']['modeling_period_start']  # Ensure data starts from modeling period\n",
    ")\n",
    "\n",
    "# preprocess metrics\n",
    "google_trends_preprocessed_df, google_trends_preprocessed_filepath = fe.preprocess_coin_df(\n",
    "    flattened_google_trends_filepath\n",
    "    ,modeling_config\n",
    "    ,value_column_config\n",
    "    ,value_column_metrics_config\n",
    ")\n",
    "\n",
    "google_trends_tuple = (google_trends_preprocessed_filepath.split('preprocessed_outputs/')[1], value_column_config['fill_method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['datasets']['macro_trends'][dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# set up config variables\n",
    "dataset_category = 'macro_trends'\n",
    "dataset_name = 'google_trends'\n",
    "dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "dataset_metrics_config = metrics_config[dataset_category][dataset_name]\n",
    "\n",
    "# load dataset\n",
    "google_trends_df = td.retrieve_google_trends_data()\n",
    "\n",
    "\n",
    "# calculate and merge all metrics in the config\n",
    "all_metrics = []\n",
    "for key in list(dataset_metrics_config.keys()):\n",
    "    value_column_metrics_config = metrics_config[dataset_category][dataset_name][key]\n",
    "    metric_df = google_trends_df[['date',key]]\n",
    "\n",
    "    # check if there are any time series indicators to add, e.g. sma, ema, etc\n",
    "    if 'indicators' in value_column_metrics_config:\n",
    "        value_column_metrics_df, _ = cwm.generate_time_series_indicators(\n",
    "            metric_df,\n",
    "            config,\n",
    "            value_column_metrics_config,\n",
    "            key,\n",
    "            id_column=None\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # if no indicators are needed, pass through coins with complete date coverage\n",
    "        logging.getLogger().setLevel(logging.WARNING)\n",
    "        value_column_metrics_df, _ = cwm.split_dataframe_by_coverage(\n",
    "            value_column_df,\n",
    "            config['training_data']['training_period_start'],\n",
    "            config['training_data']['training_period_end'],\n",
    "            id_column='coin_id'\n",
    "        )\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    all_metrics.append(metric_df)\n",
    "\n",
    "all_metrics_df = all_metrics[0]\n",
    "for metrics_df in all_metrics[1:]:\n",
    "    all_metrics_df = pd.merge(all_metrics_df, metrics_df, on='date', how='outer')\n",
    "\n",
    "\n",
    "# flatten metrics\n",
    "flattened_features = fe.flatten_date_features(all_metrics_df,dataset_metrics_config)\n",
    "flattened_google_trends_df = pd.DataFrame([flattened_features])\n",
    "\n",
    "# save flattened metrics\n",
    "flattened_google_trends_df, flattened_google_trends_filepath = fe.save_flattened_outputs(\n",
    "    flattened_google_trends_df,\n",
    "    os.path.join(modeling_config['modeling']['modeling_folder'],'outputs/flattened_outputs'),\n",
    "    dataset_config['description'],\n",
    "    config['training_data']['modeling_period_start']\n",
    ")\n",
    "\n",
    "# preprocess metrics\n",
    "google_trends_preprocessed_df, google_trends_preprocessed_filepath = fe.preprocess_coin_df(\n",
    "    flattened_google_trends_filepath\n",
    "    ,modeling_config\n",
    "    ,dataset_config\n",
    "    ,dataset_metrics_config\n",
    ")\n",
    "\n",
    "google_trends_tuple = (google_trends_preprocessed_filepath.split('preprocessed_outputs/')[1], dataset_config['fill_method'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "start_date = config['training_data']['training_period_start']\n",
    "end_date = config['training_data']['modeling_period_end']\n",
    "\n",
    "# Retrieve market data\n",
    "market_data_df = td.retrieve_market_data()\n",
    "market_data_df, _ = cwm.split_dataframe_by_coverage(market_data_df, start_date, end_date, id_column='coin_id')\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "# Retrieve profits data if necessary\n",
    "if 'profits_df' not in globals():\n",
    "    profits_df = None\n",
    "profits_df = i.rebuild_profits_df_if_necessary(\n",
    "                config,\n",
    "                modeling_folder,\n",
    "                prices_df,\n",
    "                profits_df)\n",
    "\n",
    "# Filter market_data rows without transfers if configured to do so\n",
    "if config['data_cleaning']['exclude_coins_without_transfers']:\n",
    "    market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n",
    "    prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
