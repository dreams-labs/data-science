{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['ALERT_SOUND_FILEPATH']=\"../../../Local/assets/sounds/mixkit-alert-bells-echo-765.wav\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_orchestrator as wo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_modeling.model_reporting as wmr\n",
    "import wallet_modeling.wallet_model_experiment as wme\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.clustering_features as wcl\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.performance_features as wp\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.wallet_features as wf\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.wallet_model_evaluation as wime\n",
    "import wallet_insights.validation_analysis as wiv\n",
    "import wallet_insights.coin_forecasting as wicf\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp,\n",
    "           wo, wtd, wmr, wme,\n",
    "           wcl, wmc, wmt, wp, wtf, wts, wf,\n",
    "           wime, wiv, wicf]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "wallets_config = WalletsConfig.load_from_yaml('../config/wallets_config.yaml')\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "u.export_code(code_directories=['wallet_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training Data Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve datasets\n",
    "profits_df,market_data_df = wo.retrieve_datasets()\n",
    "\n",
    "# # Define wallet cohort after cleaning\n",
    "# training_wallet_metrics_df,wallet_cohort = wo.define_wallet_cohort(profits_df,market_data_df)\n",
    "\n",
    "# # Generate profits_df for all training windows and the modeling period\n",
    "# training_profits_df, training_windows_profits_dfs, modeling_profits_df, validation_profits_df = wo.split_profits_df(profits_df,\n",
    "#                                                                                market_data_df,wallet_cohort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df_full = profits_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define wallet cohort after cleaning\n",
    "training_wallet_metrics_df,wallet_cohort = wo.define_wallet_cohort(profits_df,market_data_df)\n",
    "\n",
    "# # Generate profits_df for all training windows and the modeling period\n",
    "# training_profits_df, training_windows_profits_dfs, modeling_profits_df, validation_profits_df = wo.split_profits_df(profits_df,\n",
    "#                                                                                market_data_df,wallet_cohort)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_profits_df[(training_profits_df['usd_balance']==0) & training_profits_df['usd_net_transfers']==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the training period end (training period start is pre-imputed into profits_df generation)\n",
    "training_period_end = [wallets_config['training_data']['training_period_end']]\n",
    "imputed_profits_df = pri.impute_profits_for_multiple_dates(profits_df, market_data_df,\n",
    "                                                        training_period_end, n_threads=24)\n",
    "\n",
    "# Create a training period only profits_df\n",
    "training_profits_df = imputed_profits_df[\n",
    "    imputed_profits_df['date']<=wallets_config['training_data']['training_period_end']\n",
    "    ].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cash flows logic column\n",
    "training_profits_df = wtf.add_cash_flow_transfers_logic(training_profits_df)\n",
    "\n",
    "# # Compute wallet level metrics over duration of training period\n",
    "# training_wallet_metrics_df = wtf.calculate_wallet_trading_features(training_profits_df)\n",
    "\n",
    "# # Apply filters based on wallet behavior during the training period\n",
    "# filtered_training_wallet_metrics_df = wtd.apply_wallet_thresholds(training_wallet_metrics_df)\n",
    "\n",
    "# # Identify cohort\n",
    "# wallet_cohort = filtered_training_wallet_metrics_df.index.values\n",
    "\n",
    "# # Upload the cohort to BigQuery for additional complex feature generation\n",
    "# wtd.upload_wallet_cohort(wallet_cohort)\n",
    "\n",
    "# logger.info(\"Cohort defined as %s wallets after %.2f seconds.\",\n",
    "#             len(wallet_cohort), time.time()-start_time)\n",
    "\n",
    "# return filtered_training_wallet_metrics_df,wallet_cohort\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.export_code(code_directories=['wallet_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_profits_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features for the full training dataset\n",
    "training_wallet_features_df = wf.calculate_wallet_features(training_profits_df, market_indicators_data_df,\n",
    "                                                           transfers_sequencing_df, wallet_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_profits_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_wallet_features_df = wf.calculate_wallet_features(window_profits_df, market_indicators_data_df,\n",
    "                                                            transfers_sequencing_df, wallet_cohort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df2 = window_profits_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "profits_df2 = window_profits_df.copy()\n",
    "\n",
    "# Create a DataFrame with all wallets that should exist\n",
    "wallet_features_df = pd.DataFrame(index=wallet_cohort)\n",
    "wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "# Trading features (inner join, custom fill)\n",
    "profits_df2 = wtf.add_cash_flow_transfers_logic(profits_df2)\n",
    "trading_features = wtf.calculate_wallet_trading_features(profits_df2)\n",
    "trading_features = wtf.fill_trading_features_data(trading_features, wallet_cohort)\n",
    "wallet_features_df = wallet_features_df.join(trading_features, how='inner')\n",
    "\n",
    "# Market timing features (fill zeros)\n",
    "timing_features = wmt.calculate_market_timing_features(profits_df2, market_indicators_data_df)\n",
    "wallet_features_df = wallet_features_df.join(timing_features, how='left')\\\n",
    "    .fillna({col: 0 for col in timing_features.columns})\n",
    "\n",
    "# Market cap features (fill zeros)\n",
    "market_features = wmc.calculate_market_cap_features(profits_df2, market_indicators_data_df)\n",
    "wallet_features_df = wallet_features_df.join(market_features, how='left')\\\n",
    "    .fillna({col: 0 for col in market_features.columns})\n",
    "\n",
    "# Transfers features (fill -1)\n",
    "transfers_features = wts.calculate_transfers_sequencing_features(profits_df2, transfers_sequencing_df)\n",
    "wallet_features_df = wallet_features_df.join(transfers_features, how='left')\\\n",
    "    .fillna({col: -1 for col in transfers_features.columns})\n",
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features = wp.calculate_performance_features(wallet_features_df)\n",
    "wallet_features_df = wallet_features_df.join(\n",
    "    performance_features.drop(['invested', 'net_gain'], axis=1),\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trading_features['invested'].min() < 0:\n",
    "    raise ValueError(f\"Found {len(trading_features[trading_features['invested']<0])} wallets \"\n",
    "                     \"with negative invested values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 33872418\n",
    "profits_df2[profits_df2['wallet_address']==w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallets_df = wallet_features_df.copy()\n",
    "\n",
    "metrics_df = wallets_df[['invested','net_gain']].copy().round(6)\n",
    "returns_winsorization = wallets_config['modeling']['returns_winsorization']\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Calculate base return\n",
    "metrics_df['return'] = np.where(abs(metrics_df['invested']) == 0,0,\n",
    "                                metrics_df['net_gain'] / metrics_df['invested'])\n",
    "\n",
    "# Apply winsorization\n",
    "if returns_winsorization > 0:\n",
    "    metrics_df['return'] = u.winsorize(metrics_df['return'],returns_winsorization)\n",
    "\n",
    "# Risk-Adjusted Dollar Return\n",
    "metrics_df['risk_adj_return'] = metrics_df['net_gain'] * \\\n",
    "    (1 + np.log10(metrics_df['invested'] + epsilon))\n",
    "\n",
    "# # Normalize returns\n",
    "# metrics_df['norm_return'] = (metrics_df['return'] - metrics_df['return'].min()) / \\\n",
    "#     (metrics_df['return'].max() - metrics_df['return'].min())\n",
    "\n",
    "# # Normalize logged investments\n",
    "# log_invested = np.log10(metrics_df['invested'] + epsilon)\n",
    "# metrics_df['norm_invested'] = (log_invested - log_invested.min()) / \\\n",
    "#     (log_invested.max() - log_invested.min())\n",
    "\n",
    "# # Performance score\n",
    "# metrics_df['performance_score'] = (0.6 * metrics_df['norm_return'] +\n",
    "#                                     0.4 * metrics_df['norm_invested'])\n",
    "\n",
    "# # Log-weighted return\n",
    "# metrics_df['log_weighted_return'] = metrics_df['return'] * \\\n",
    "#     np.log10(metrics_df['invested'] + epsilon)\n",
    "\n",
    "# # Hybrid score (combining absolute and relative performance)\n",
    "# max_gain = metrics_df['net_gain'].abs().max()\n",
    "# metrics_df['norm_gain'] = metrics_df['net_gain'] / max_gain\n",
    "# metrics_df['hybrid_score'] = (metrics_df['norm_gain'] +\n",
    "#                             metrics_df['norm_return']) / 2\n",
    "\n",
    "# # Size-adjusted rank\n",
    "# # Create mask for zero values\n",
    "# zero_mask = metrics_df['invested'] == 0\n",
    "\n",
    "# # Create quartiles series initialized with 'q0' for zero values\n",
    "# quartiles = pd.Series('q0', index=metrics_df.index)\n",
    "\n",
    "# # Calculate quartiles for non-zero values\n",
    "# non_zero_quartiles = pd.qcut(metrics_df['invested'][~zero_mask],\n",
    "#                             q=4,\n",
    "#                             labels=['q1', 'q2', 'q3', 'q4'])\n",
    "\n",
    "# # Assign the quartiles to non-zero values\n",
    "# quartiles[~zero_mask] = non_zero_quartiles\n",
    "\n",
    "# # Calculate size-adjusted rank within each quartile\n",
    "# metrics_df['size_adjusted_rank'] = metrics_df.groupby(quartiles)['return'].rank(pct=True)\n",
    "\n",
    "\n",
    "# # Clean up intermediate columns\n",
    "# cols_to_drop = ['norm_return', 'norm_invested', 'norm_gain']\n",
    "# metrics_df = metrics_df.drop(columns=[c for c in cols_to_drop\n",
    "#                                     if c in metrics_df.columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Append clustering features based on all numeric features in the base training data\n",
    "cluster_features = wcl.create_basic_cluster_features(base_training_data_df)\n",
    "training_data_df = base_training_data_df.join(cluster_features, how='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join target variable to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Clean inactive wallets from modeling period data\n",
    "modeling_wallets_df = wo.filter_modeling_period_wallets(modeling_profits_df)\n",
    "\n",
    "# Generate target variables\n",
    "target_vars_df = wp.calculate_performance_features(modeling_wallets_df)\n",
    "\n",
    "# Merge training data and target variables?\n",
    "modeling_df = training_data_df.join(target_vars_df[wallets_config['modeling']['target_variable']],\n",
    "                                    how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create an experiment instance\n",
    "experiment = wme.WalletModel(wallets_config)\n",
    "\n",
    "# Run the experiment and get results\n",
    "model_results = experiment.run_experiment(modeling_df)\n",
    "\n",
    "# Extract the trained model\n",
    "model = model_results['pipeline'].named_steps['regressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model artifacts\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, evaluator, wallet_scores_df, coin_validation_df = wmr.generate_and_save_model_artifacts(\n",
    "    model_results=model_results,\n",
    "    validation_profits_df=validation_profits_df,\n",
    "    base_path='../wallet_modeling'\n",
    ")\n",
    "u.play_notification()\n",
    "\n",
    "# Print results\n",
    "evaluator.plot_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation period assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wallet_performance_df, bucketed_performance_df = wiv.calculate_validation_metrics(\n",
    "    X_test=model_results['X_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    validation_profits_df=validation_profits_df,\n",
    ")\n",
    "\n",
    "bucketed_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coin performance predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create coin_validation_df with metrics and returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Consolidate wallet scores at the coin level\n",
    "wallet_scores_df = pd.DataFrame({'score': model_results['y_pred']}, index=model_results['y_test'].index)\n",
    "coin_wallet_metrics_df = wicf.calculate_coin_metrics_from_wallet_scores(validation_profits_df, wallet_scores_df)\n",
    "\n",
    "# Calculate coin performance during the validation period\n",
    "coin_performance_df = wicf.calculate_coin_performance(market_data_df,\n",
    "                                                     wallets_config['training_data']['validation_period_start'],\n",
    "                                                     wallets_config['training_data']['validation_period_end'])\n",
    "\n",
    "# Join aggregated wallet metrics with actual coin performance\n",
    "coin_validation_df = coin_wallet_metrics_df.join(coin_performance_df, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = wicf.analyze_market_cap_segments(\n",
    "    coin_validation_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "wicf.plot_segment_heatmap(summary_df)\n",
    "# wicf.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_forecasting']['top_n']\n",
    "max_market_cap = wallets_config['coin_forecasting']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_forecasting']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = wicf.validate_coin_performance(coin_validation_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare performance of high vs low score coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wicf.print_performance_analysis(coin_validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "def analyze_coin_metrics(df):\n",
    "    \"\"\"\n",
    "    Analyze relationships between coin metrics and returns\n",
    "    \"\"\"\n",
    "    # Calculate correlations with coin_return\n",
    "    metrics_of_interest = [\n",
    "        'weighted_avg_score',\n",
    "        'composite_score',\n",
    "        'score_confidence',\n",
    "        'top_wallet_balance_pct',\n",
    "        'top_wallet_count_pct',\n",
    "        'total_wallets',\n",
    "        'avg_wallet_balance',\n",
    "        'market_cap'\n",
    "    ]\n",
    "\n",
    "    # Calculate correlations\n",
    "    correlations = {}\n",
    "    for metric in metrics_of_interest:\n",
    "        correlation = df[metric].corr(df['coin_return'])\n",
    "        correlations[metric] = correlation\n",
    "\n",
    "    # Sort correlations by absolute value\n",
    "    correlations_sorted = {k: v for k, v in sorted(correlations.items(),\n",
    "                                                 key=lambda x: abs(x[1]),\n",
    "                                                 reverse=True)}\n",
    "\n",
    "    # Calculate basic statistics for coins with positive vs negative returns\n",
    "    positive_returns = df[df['coin_return'] > 0]\n",
    "    negative_returns = df[df['coin_return'] <= 0]\n",
    "\n",
    "    comparison_stats = {}\n",
    "    for metric in metrics_of_interest:\n",
    "        pos_mean = positive_returns[metric].mean()\n",
    "        neg_mean = negative_returns[metric].mean()\n",
    "        # Perform t-test\n",
    "        t_stat, p_value = stats.ttest_ind(positive_returns[metric],\n",
    "                                        negative_returns[metric])\n",
    "\n",
    "        comparison_stats[metric] = {\n",
    "            'positive_mean': pos_mean,\n",
    "            'negative_mean': neg_mean,\n",
    "            'difference': pos_mean - neg_mean,\n",
    "            'p_value': p_value\n",
    "        }\n",
    "\n",
    "    # Identify potential success indicators\n",
    "    success_indicators = {\n",
    "        metric: stats for metric, stats in comparison_stats.items()\n",
    "        if (abs(stats['difference']) > 0.1 * stats['negative_mean'] and\n",
    "            stats['p_value'] < 0.05)\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'correlations': correlations_sorted,\n",
    "        'comparison_stats': comparison_stats,\n",
    "        'success_indicators': success_indicators\n",
    "    }\n",
    "\n",
    "# Create summary statistics\n",
    "def print_analysis_results(results):\n",
    "    \"\"\"\n",
    "    Print formatted analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Correlation Analysis ===\")\n",
    "    print(\"\\nCorrelations with coin return (sorted by strength):\")\n",
    "    for metric, corr in results['correlations'].items():\n",
    "        print(f\"{metric:25} : {corr:0.4f}\")\n",
    "\n",
    "    print(\"\\n=== Positive vs Negative Returns Analysis ===\")\n",
    "    print(\"\\nMetrics comparison for positive vs negative returns:\")\n",
    "    for metric, stats in results['comparison_stats'].items():\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Positive returns mean: {stats['positive_mean']:0.4f}\")\n",
    "        print(f\"  Negative returns mean: {stats['negative_mean']:0.4f}\")\n",
    "        print(f\"  Difference: {stats['difference']:0.4f}\")\n",
    "        print(f\"  P-value: {stats['p_value']:0.4f}\")\n",
    "\n",
    "    print(\"\\n=== Strong Success Indicators ===\")\n",
    "    print(\"\\nMetrics showing significant difference between positive and negative returns:\")\n",
    "    for metric, stats in results['success_indicators'].items():\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Mean difference: {stats['difference']:0.4f}\")\n",
    "        print(f\"  P-value: {stats['p_value']:0.4f}\")\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "def main():\n",
    "    # Read the data\n",
    "    df = pd.read_csv('coin_wallet_metrics.csv')\n",
    "\n",
    "    # Run analysis\n",
    "    results = analyze_coin_metrics(df)\n",
    "\n",
    "    # Print results\n",
    "    print_analysis_results(results)\n",
    "\n",
    "    # Create visualizations\n",
    "    create_visualizations(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorize the returns (apply caps to the top n % of values)\n",
    "returns_winsorized = u.winsorize(returns, winsorization_cutoff)\n",
    "\n",
    "# Merge datasets\n",
    "df = pd.DataFrame({\n",
    "    'predictions': predictions,\n",
    "    'returns': returns_winsorized,\n",
    "})\n",
    "\n",
    "# Sort by actual returns to obtain optimal performance\n",
    "df_sorted = df.sort_values('returns', ascending=False)\n",
    "cumulative_best_returns = np.cumsum(df_sorted['returns'])\n",
    "cumulative_best_avg_returns = df_sorted['returns'].expanding().mean()\n",
    "\n",
    "# Sort by model score to obtain modeled performance\n",
    "df_sorted = df.sort_values('predictions', ascending=False)\n",
    "cumulative_model_returns = np.cumsum(df_sorted['returns'])\n",
    "cumulative_model_avg_returns = df_sorted['returns'].expanding().mean()\n",
    "\n",
    "# Calculate average return across all data\n",
    "average_return = np.mean(returns_winsorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_model_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_forecasting']['top_n']\n",
    "max_market_cap = wallets_config['coin_forecasting']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_forecasting']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = wicf.validate_coin_performance(coin_validation_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# List the coins that would have been picked at the start of the validation period\n",
    "top_coins_df = coin_validation_df[\n",
    "    (coin_validation_df['market_cap_filled']<=max_market_cap)\n",
    "    & (coin_validation_df['market_cap_filled']>=min_market_cap)\n",
    "].copy()\n",
    "\n",
    "sort_column = wallets_config['coin_forecasting']['sort_method']\n",
    "\n",
    "top_coins_df.sort_values(sort_column,ascending=False).head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ProfitsValidator:\n",
    "    \"\"\"\n",
    "    Validates profits DataFrame follows expected format and constraints.\n",
    "    Only validates training period data.\n",
    "    \"\"\"\n",
    "    def validate_all(self, profits_df, training_period_start, training_period_end):\n",
    "        \"\"\"Run all validation checks and return dict of results\"\"\"\n",
    "        dates = {\n",
    "            'training_period_start': pd.to_datetime(training_period_start),\n",
    "            'training_period_end': pd.to_datetime(training_period_end),\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'no_duplicates': self.check_no_duplicates(profits_df),\n",
    "            'period_boundaries': self.check_period_boundaries(profits_df, dates),\n",
    "            'no_negatives': self.check_no_negative_balances(profits_df),\n",
    "            'date_range': self.check_date_range(profits_df, dates),\n",
    "            'no_missing': self.check_no_missing_values(profits_df)\n",
    "        }\n",
    "\n",
    "    def check_no_duplicates(self, profits_df):\n",
    "        \"\"\"Check for duplicate records\"\"\"\n",
    "        deduped_df = profits_df[['coin_id', 'wallet_address', 'date']].drop_duplicates()\n",
    "        return len(profits_df) == len(deduped_df)\n",
    "\n",
    "    def check_period_boundaries(self, profits_df, dates):\n",
    "        \"\"\"Check records exist at period boundaries\"\"\"\n",
    "        profits_df['date'] = pd.to_datetime(profits_df['date'])\n",
    "        pairs = profits_df[['coin_id', 'wallet_address']].drop_duplicates()\n",
    "        n_pairs = len(pairs)\n",
    "\n",
    "        period_df = profits_df[profits_df['date'] == dates['training_period_end']]\n",
    "        period_pairs = period_df[['coin_id', 'wallet_address']].drop_duplicates()\n",
    "        return len(period_pairs) == n_pairs\n",
    "\n",
    "    def check_no_negative_balances(self, profits_df):\n",
    "        \"\"\"Check for negative USD balances\"\"\"\n",
    "        return (profits_df['usd_balance'] >= -0.1).all()\n",
    "\n",
    "    def check_date_range(self, profits_df, dates):\n",
    "        \"\"\"Verify date coverage\"\"\"\n",
    "        profits_df['date'] = pd.to_datetime(profits_df['date'])\n",
    "        return (profits_df['date'].min() >= dates['training_period_start'] and\n",
    "                profits_df['date'].max() == dates['training_period_end'])\n",
    "\n",
    "    def check_no_missing_values(self, profits_df):\n",
    "        \"\"\"Check for missing values\"\"\"\n",
    "        return not profits_df.isna().any().any()\n",
    "\n",
    "\n",
    "class TestPeriods:\n",
    "    \"\"\"Test period dates\"\"\"\n",
    "    TRAINING_PERIOD_START: str = '2024-01-01'\n",
    "    TRAINING_PERIOD_END: str = '2024-01-10'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytest\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# @pytest.mark.unit\n",
    "# def test_complex_scenarios():\n",
    "\"\"\"\n",
    "Test multiple complex business scenarios in a single profits_df.\n",
    "\n",
    "Scenarios covered:\n",
    "- Many-to-many relationships between wallets and coins.\n",
    "- A wallet with only imputed rows at start and end (no real trades).\n",
    "- A wallet with only 1 row at training period end.\n",
    "- A wallet ending with a net loss.\n",
    "- A wallet that sells full balance mid-period and repurchases later.\n",
    "- Additionally tested: incremental investments, multiple coins, and ensuring\n",
    "    that all coin-wallet pairs appear at the training period end.\n",
    "\"\"\"\n",
    "\n",
    "# Training period\n",
    "training_period_start = '2024-01-01'\n",
    "training_period_end = '2024-01-10'\n",
    "\n",
    "# Construct the sample profits_df\n",
    "profits_data = [\n",
    "    # w1_multiple_coins - btc & eth (multiple transactions, multiple coins)\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w1_multiple_coins', 'date': '2024-01-01', 'usd_balance': 100, 'usd_net_transfers': 100, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w1_multiple_coins', 'date': '2024-01-05', 'usd_balance': 150, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w1_multiple_coins', 'date': '2024-01-10', 'usd_balance': 180, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w1_multiple_coins', 'date': '2024-01-01', 'usd_balance': 200, 'usd_net_transfers': 200, 'is_imputed': False},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w1_multiple_coins', 'date': '2024-01-05', 'usd_balance': 250, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w1_multiple_coins', 'date': '2024-01-10', 'usd_balance': 280, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w2_net_loss - btc (net loss)\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w2_net_loss', 'date': '2024-01-01', 'usd_balance': 300, 'usd_net_transfers': 300, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w2_net_loss', 'date': '2024-01-05', 'usd_balance': 250, 'usd_net_transfers': -100, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w2_net_loss', 'date': '2024-01-10', 'usd_balance': 100, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w3_sell_all_and_rebuy - ada (sell full balance mid-way and repurchase)\n",
    "    {'coin_id': 'ada', 'wallet_address': 'w3_sell_all_and_rebuy', 'date': '2024-01-01', 'usd_balance': 50, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "    {'coin_id': 'ada', 'wallet_address': 'w3_sell_all_and_rebuy', 'date': '2024-01-03', 'usd_balance': 0,  'usd_net_transfers': -50, 'is_imputed': False},\n",
    "    {'coin_id': 'ada', 'wallet_address': 'w3_sell_all_and_rebuy', 'date': '2024-01-08', 'usd_balance': 40, 'usd_net_transfers': 40, 'is_imputed': False},\n",
    "    {'coin_id': 'ada', 'wallet_address': 'w3_sell_all_and_rebuy', 'date': '2024-01-10', 'usd_balance': 42, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w4_only_period_end - btc (only final row)\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w4_only_period_end', 'date': '2024-01-10', 'usd_balance': 70, 'usd_net_transfers': 70, 'is_imputed': False},\n",
    "\n",
    "    # w5_only_imputed - btc (only imputed rows at start and end)\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w5_only_imputed', 'date': '2024-01-01', 'usd_balance': 50, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w5_only_imputed', 'date': '2024-01-10', 'usd_balance': 50, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w6_tiny_transactions - very small transactions relative to portfolio size\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w6_multiple_coins', 'date': '2024-01-01', 'usd_balance': 1250, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w6_multiple_coins', 'date': '2024-01-02', 'usd_balance': 1220, 'usd_net_transfers': 1, 'is_imputed': False},\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w6_multiple_coins', 'date': '2024-01-05', 'usd_balance': 1280, 'usd_net_transfers': -2, 'is_imputed': False},\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w6_multiple_coins', 'date': '2024-01-10', 'usd_balance': 0, 'usd_net_transfers': -1240, 'is_imputed': False},\n",
    "\n",
    "    # w7_memecoin_winner - Large swings in portfolio value\n",
    "    {'coin_id': 'pepe', 'wallet_address': 'w7_memecoin_winner', 'date': '2024-01-01', 'usd_balance': 100, 'usd_net_transfers': 100, 'is_imputed': False},\n",
    "    {'coin_id': 'pepe', 'wallet_address': 'w7_memecoin_winner', 'date': '2024-01-03', 'usd_balance': 250, 'usd_net_transfers': -500, 'is_imputed': False},\n",
    "    {'coin_id': 'pepe', 'wallet_address': 'w7_memecoin_winner', 'date': '2024-01-05', 'usd_balance': 50, 'usd_net_transfers': -100, 'is_imputed': False},\n",
    "    {'coin_id': 'pepe', 'wallet_address': 'w7_memecoin_winner', 'date': '2024-01-10', 'usd_balance': 10, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w8_memecoin_loser - Large swings in portfolio value\n",
    "    {'coin_id': 'wojak', 'wallet_address': 'w8_memecoin_loser', 'date': '2024-01-03', 'usd_balance': 250, 'usd_net_transfers': 250, 'is_imputed': False},\n",
    "    {'coin_id': 'wojak', 'wallet_address': 'w8_memecoin_loser', 'date': '2024-01-10', 'usd_balance': 0, 'usd_net_transfers': -20, 'is_imputed': False},\n",
    "]\n",
    "\n",
    "profits_df = pd.DataFrame(profits_data)\n",
    "\n",
    "# Validate test data format before proceeding\n",
    "validator = ProfitsValidator()\n",
    "validation_results = validator.validate_all(\n",
    "    profits_df,\n",
    "    training_period_start,\n",
    "    training_period_end\n",
    ")\n",
    "assert all(validation_results.values()), \"Test data failed validation checks.\"\n",
    "\n",
    "# ACT: Run the feature calculation code (mocking actual calls)\n",
    "# For demonstration, we assume the functions are accessible via wtf.\n",
    "# Replace wtf. references with the actual module name as needed.\n",
    "profits_df = wtf.add_cash_flow_transfers_logic(profits_df)\n",
    "trading_features_df = wtf.calculate_wallet_trading_features(profits_df)\n",
    "\n",
    "profits_df_test = profits_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallets = [\n",
    "    'w1_multiple_coins',\n",
    "    'w2_net_loss'\n",
    "]\n",
    "\n",
    "profits_df_test[profits_df_test['wallet_address'].isin(wallets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = profits_df_test.copy()\n",
    "\n",
    "# Ensure data is sorted for calculations\n",
    "profits_df = profits_df.sort_values(['wallet_address', 'coin_id', 'date'])\n",
    "\n",
    "# Calculate balance before transfers for each day\n",
    "profits_df['pre_transfer_balance'] = profits_df['usd_balance'] - profits_df['usd_net_transfers']\n",
    "\n",
    "# Calculate daily returns between cash flows\n",
    "# Note: Using shift() within groups handles multi-coin wallets\n",
    "profits_df['daily_twr'] = (profits_df.groupby(['wallet_address', 'coin_id'])\n",
    "                            ['pre_transfer_balance'].shift())\n",
    "profits_df['daily_twr'] = profits_df['usd_balance'] / profits_df['daily_twr']\n",
    "\n",
    "# Replace inf/null values with 1 (no return) for first days and zero balances\n",
    "profits_df['daily_twr'] = profits_df['daily_twr'].replace([np.inf, -np.inf], 1).fillna(1)\n",
    "\n",
    "# Calculate cumulative TWR per wallet across all coins\n",
    "twr_df = profits_df.groupby('wallet_address').agg(\n",
    "    twr=('daily_twr', lambda x: x.prod() - 1),  # -1 to convert to percent return\n",
    "    days_held=('date', lambda x: (x.max() - x.min()).days)\n",
    ")\n",
    "\n",
    "# Add annualized TWR for comparability\n",
    "twr_df['annualized_twr'] = ((1 + twr_df['twr']) ** (365 / twr_df['days_held'])) - 1\n",
    "\n",
    "# Clean up any edge cases\n",
    "twr_df = twr_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "twr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "test_data = {\n",
    "    'coin_id': ['btc'] * 3,\n",
    "    'wallet_address': ['wallet1'] * 3,\n",
    "    'date': ['2024-01-01', '2024-01-03', '2024-01-10'],\n",
    "    'usd_balance': [150, 220, 210],\n",
    "    'usd_net_transfers': [80, -30, 0],\n",
    "    'is_imputed': [False, False, True]\n",
    "}\n",
    "base_profits_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Validate test data format\n",
    "validator = ProfitsValidator()\n",
    "validation_results = validator.validate_all(\n",
    "    base_profits_df,\n",
    "    TestPeriods.TRAINING_PERIOD_START,\n",
    "    TestPeriods.TRAINING_PERIOD_END\n",
    ")\n",
    "assert all(validation_results.values()), \"Test data failed validation\"\n",
    "\n",
    "# Create profits_df and trading_features\n",
    "profits_df = wtf.add_cash_flow_transfers_logic(base_profits_df)\n",
    "trading_features_df = wtf.calculate_wallet_trading_features(profits_df)\n",
    "\n",
    "trading_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df['date'].min() - profits_df['date'].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure date is in datetime format\n",
    "profits_df['date'] = pd.to_datetime(profits_df['date'])\n",
    "\n",
    "# Sort by date and wallet_address to ensure proper cumulative calculations\n",
    "profits_df = profits_df.sort_values(['wallet_address','coin_id','date'])\n",
    "\n",
    "# Precompute necessary transformations\n",
    "profits_df['abs_usd_net_transfers'] = profits_df['usd_net_transfers'].abs()\n",
    "\n",
    "# Calculate cumsum by wallet, respecting date order\n",
    "profits_df['cumsum_cash_flow_transfers'] = profits_df.groupby('wallet_address')['cash_flow_transfers'].cumsum()\n",
    "\n",
    "# Metrics that take into account imputed rows/profits\n",
    "logger.debug(\"Calculating wallet metrics based on imputed performance...\")\n",
    "imputed_metrics_df = profits_df.groupby('wallet_address').agg(\n",
    "    invested=('cumsum_cash_flow_transfers', 'max'),\n",
    "    net_gain=('cash_flow_transfers', lambda x: -x.sum()),\n",
    "    unique_coins_traded=('coin_id', 'nunique')\n",
    ")\n",
    "\n",
    "\n",
    "imputed_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics only based on observed activity\n",
    "logger.debug(\"Calculating wallet metrics based on observed behavior...\")\n",
    "observed_metrics_df = profits_df[~profits_df['is_imputed']].groupby('wallet_address').agg(\n",
    "    transaction_days=('date', 'nunique'),  # Changed from count to nunique for actual trading days\n",
    "    total_volume=('abs_usd_net_transfers', 'sum'),\n",
    "    average_transaction=('abs_usd_net_transfers', 'mean'),\n",
    "    first_activity=('date', 'min'),\n",
    "    last_activity=('date', 'max')\n",
    ")\n",
    "\n",
    "observed_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df\n",
    "c = 'btc'\n",
    "w = 'wallet1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df\n",
    "c = 'btc'\n",
    "w = 'wallet1'\n",
    "\n",
    "wtf.calculate_wallet_trading_features(u.cw_filter_df(profits_df,c,w).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df\n",
    "c = 'eth'\n",
    "w = 'wallet1'\n",
    "\n",
    "wtf.calculate_wallet_trading_features(u.cw_filter_df(profits_df,c,w).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_features_df = trad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytest\n",
    "# import numpy as np\n",
    "\n",
    "# @pytest.mark.unit\n",
    "# def test_complex_scenarios_correctness(trading_features_df):\n",
    "\"\"\"\n",
    "Verify that the trading_features_df matches manually calculated results\n",
    "for multiple complex scenarios. Each assertion is explained with the steps\n",
    "used to compute the expected values.\n",
    "\"\"\"\n",
    "\n",
    "# wallet1 checks:\n",
    "# invested=260 (max cumsum), net_gain=260, unique_coins_traded=2,\n",
    "# transaction_days=2, total_volume=400, average_transaction=100,\n",
    "# activity_days=10, activity_density=0.2\n",
    "w1 = trading_features_df.loc['wallet1']\n",
    "# Confirm invested\n",
    "# Step: max cumsum was 260 across combined btc & eth transactions\n",
    "assert np.isclose(w1['invested'], 260), \"wallet1 invested incorrect.\"\n",
    "# net_gain\n",
    "# Step: sum of all cft for wallet1 was 260\n",
    "assert np.isclose(w1['net_gain'], 260), \"wallet1 net_gain incorrect.\"\n",
    "# unique_coins_traded=2 (btc, eth)\n",
    "assert w1['unique_coins_traded'] == 2, \"wallet1 unique_coins_traded incorrect.\"\n",
    "# transaction_days=2 (01-01 and 01-05 for observed rows)\n",
    "assert w1['transaction_days'] == 2, \"wallet1 transaction_days incorrect.\"\n",
    "# total_volume=400 (sum abs transfers on observed: btc(100+50), eth(200+50))\n",
    "assert w1['total_volume'] == 400, \"wallet1 total_volume incorrect.\"\n",
    "# average_transaction=100 (400 total /4 observed transactions)\n",
    "assert w1['average_transaction'] == 100, \"wallet1 average_transaction incorrect.\"\n",
    "# activity_days=10 (01-01 to 01-10)\n",
    "assert w1['activity_days'] == 10, \"wallet1 activity_days incorrect.\"\n",
    "# activity_density=0.2 (2/10)\n",
    "assert np.isclose(w1['activity_density'], 0.2), \"wallet1 activity_density incorrect.\"\n",
    "\n",
    "# wallet2 checks:\n",
    "# invested=-200, net_gain=-200, unique_coins_traded=1, transaction_days=1,\n",
    "# total_volume=300, average_transaction=300, activity_days=10, activity_density=0.1\n",
    "w2 = trading_features_df.loc['wallet2']\n",
    "assert np.isclose(w2['invested'], -200), \"wallet2 invested incorrect.\"\n",
    "assert np.isclose(w2['net_gain'], -200), \"wallet2 net_gain incorrect.\"\n",
    "assert w2['unique_coins_traded'] == 1, \"wallet2 unique_coins_traded incorrect.\"\n",
    "assert w2['transaction_days'] == 1, \"wallet2 transaction_days incorrect.\"\n",
    "assert w2['total_volume'] == 300, \"wallet2 total_volume incorrect.\"\n",
    "assert w2['average_transaction'] == 300, \"wallet2 average_transaction incorrect.\"\n",
    "assert w2['activity_days'] == 10, \"wallet2 activity_days incorrect.\"\n",
    "assert np.isclose(w2['activity_density'], 0.1), \"wallet2 activity_density incorrect.\"\n",
    "\n",
    "# wallet3 checks:\n",
    "# invested=-18, net_gain=-18, unique_coins_traded=1, transaction_days=3,\n",
    "# total_volume=140, average_transaction≈46.6667, activity_days=10, activity_density=0.3\n",
    "w3 = trading_features_df.loc['wallet3']\n",
    "assert np.isclose(w3['invested'], -18), \"wallet3 invested incorrect.\"\n",
    "assert np.isclose(w3['net_gain'], -18), \"wallet3 net_gain incorrect.\"\n",
    "assert w3['unique_coins_traded'] == 1, \"wallet3 unique_coins_traded incorrect.\"\n",
    "assert w3['transaction_days'] == 3, \"wallet3 transaction_days incorrect.\"\n",
    "assert w3['total_volume'] == 140, \"wallet3 total_volume incorrect.\"\n",
    "# average_transaction = 140/3 ≈46.6667\n",
    "assert np.isclose(w3['average_transaction'], 46.6667, atol=1e-4), \"wallet3 average_transaction incorrect.\"\n",
    "assert w3['activity_days'] == 10, \"wallet3 activity_days incorrect.\"\n",
    "# activity_density=3/10=0.3\n",
    "assert np.isclose(w3['activity_density'], 0.3), \"wallet3 activity_density incorrect.\"\n",
    "\n",
    "# wallet4 checks:\n",
    "# invested=70, net_gain=70, unique_coins_traded=1, transaction_days=0,\n",
    "# total_volume=0, average_transaction=0, activity_days=1, activity_density=0\n",
    "w4 = trading_features_df.loc['wallet4']\n",
    "assert np.isclose(w4['invested'], 70), \"wallet4 invested incorrect.\"\n",
    "assert np.isclose(w4['net_gain'], 70), \"wallet4 net_gain incorrect.\"\n",
    "assert w4['unique_coins_traded'] == 1, \"wallet4 unique_coins_traded incorrect.\"\n",
    "assert w4['transaction_days'] == 0, \"wallet4 transaction_days incorrect.\"\n",
    "assert w4['total_volume'] == 0, \"wallet4 total_volume incorrect.\"\n",
    "assert w4['average_transaction'] == 0, \"wallet4 average_transaction incorrect.\"\n",
    "assert w4['activity_days'] == 1, \"wallet4 activity_days incorrect.\"\n",
    "assert np.isclose(w4['activity_density'], 0.0), \"wallet4 activity_density incorrect.\"\n",
    "\n",
    "# wallet5 checks:\n",
    "# invested=0, net_gain=0, unique_coins_traded=1, transaction_days=0,\n",
    "# total_volume=0, average_transaction=0, activity_days=10, activity_density=0\n",
    "w5 = trading_features_df.loc['wallet5']\n",
    "assert np.isclose(w5['invested'], 0), \"wallet5 invested incorrect.\"\n",
    "assert np.isclose(w5['net_gain'], 0), \"wallet5 net_gain incorrect.\"\n",
    "assert w5['unique_coins_traded'] == 1, \"wallet5 unique_coins_traded incorrect.\"\n",
    "assert w5['transaction_days'] == 0, \"wallet5 transaction_days incorrect.\"\n",
    "assert w5['total_volume'] == 0, \"wallet5 total_volume incorrect.\"\n",
    "assert w5['average_transaction'] == 0, \"wallet5 average_transaction incorrect.\"\n",
    "assert w5['activity_days'] == 10, \"wallet5 activity_days incorrect.\"\n",
    "assert np.isclose(w5['activity_density'], 0.0), \"wallet5 activity_density incorrect.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
