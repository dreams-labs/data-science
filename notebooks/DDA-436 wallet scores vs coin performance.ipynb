{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['ALERT_SOUND_FILEPATH']=\"../../../Local/assets/sounds/mixkit-alert-bells-echo-765.wav\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_modeling_orchestrator as wmo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_modeling.model_reporting as wmr\n",
    "import wallet_modeling.wallet_model as wm\n",
    "import wallet_modeling.experiments_manager as wem\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.clustering_features as wcl\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.performance_features as wpf\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.features_orchestrator as wfo\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.wallet_model_evaluation as wime\n",
    "import wallet_insights.coin_validation_analysis as wica\n",
    "import wallet_insights.coin_validation_model as wicm\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp,\n",
    "           wmo, wtd, wmr, wm, wem,\n",
    "           wcl, wmc, wmt, wpf, wtf, wts, wfo,\n",
    "           wime, wica, wicm]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "wallets_config = WalletsConfig.load_from_yaml('../config/wallets_config.yaml')\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "u.export_code(\n",
    "    code_directories=[\n",
    "        'wallet_features',\n",
    "        'wallet_modeling',\n",
    "        'wallet_insights'\n",
    "    ],\n",
    "    include_config = True,\n",
    "    ipynb_notebook = 'DDA-436 wallet scores vs coin performance.ipynb'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training Data Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Retrieve datasets\n",
    "profits_df,market_data_df = wmo.retrieve_datasets()\n",
    "profits_df_full = profits_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "profits_df = profits_df_full.copy()\n",
    "\n",
    "# Define wallet cohort after cleaning\n",
    "training_wallet_metrics_df,wallet_cohort = wmo.define_wallet_cohort(profits_df,market_data_df)\n",
    "\n",
    "# Generate profits_df for all training windows and the modeling period\n",
    "training_profits_df, training_windows_profits_dfs, modeling_profits_df, validation_profits_df = wmo.split_profits_df(profits_df,\n",
    "                                                                               market_data_df,wallet_cohort)\n",
    "\n",
    "# Market data: add indicators\n",
    "# Remove all market_data records after the training period to ensure no leakage\n",
    "training_market_data_df = (market_data_df[market_data_df['date']\n",
    "                                          <= wallets_config['training_data']['training_period_end']])\n",
    "\n",
    "# Add new columns\n",
    "# Generate basic indicators\n",
    "market_indicators_data_df = ind.add_market_data_dualcolumn_indicators(training_market_data_df)\n",
    "market_indicators_data_df = ind.generate_time_series_indicators(market_indicators_data_df,\n",
    "                                                        wallets_metrics_config['time_series']['market_data'],\n",
    "                                                        'coin_id')\n",
    "\n",
    "# Transfers data retrieval for the wallet_ids in temp.wallet_modeling_cohort\n",
    "transfers_sequencing_df = wts.retrieve_transfers_sequencing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### data freshness checks on profits and market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# def check_coin_transfers_staleness(profits_df, data_cleaning_config) -> None:\n",
    "#     \"\"\"\n",
    "#     Warns if coin count changes exceed specified thresholds.\n",
    "\n",
    "#     Params:\n",
    "#     - profits_df (df): df showing coin-wallet-date records where transers exist\n",
    "#     \"\"\"\n",
    "\n",
    "data_cleaning_config = wallets_config['data_cleaning']\n",
    "\n",
    "# Extract thresholds\n",
    "count_threshold=data_cleaning_config['transfers_coverage_warning_min_coin_increase'],\n",
    "percent_threshold=data_cleaning_config['transfers_coverage_warning_min_pct_increase']\n",
    "audit_window=data_cleaning_config['coverage_decrease_audit_window']\n",
    "\n",
    "# Create counts of coins with transfers\n",
    "daily_counts = profits_df.groupby('date')['coin_id'].nunique().copy()\n",
    "latest_count = daily_counts.iloc[-1]\n",
    "latest_date = daily_counts.index[-1]\n",
    "cutoff_date = latest_date - pd.Timedelta(days=audit_window)\n",
    "week_data = daily_counts.loc[cutoff_date:]\n",
    "\n",
    "count_decrease = week_data.max() - latest_count\n",
    "min_date = week_data.idxmin()\n",
    "pct_decrease = count_decrease / week_data.max() * 100\n",
    "\n",
    "if count_decrease > count_threshold and pct_decrease > percent_threshold:\n",
    "    logging.warning(\n",
    "        f\"Transfers data coverage alert on {latest_date.date()}:\\n\"\n",
    "        f\"- Transfers coverage decreased from {week_data.max():.0f} coins ({min_date.date()}) \"\n",
    "        f\"to {latest_count:.0f} coins ({latest_date.date()}), \"\n",
    "        f\"a {pct_decrease:.1f}% decrease.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"daily_counts: {daily_counts}\")\n",
    "print(f\"latest_count: {latest_count}\")\n",
    "print(f\"latest_date: {latest_date}\")\n",
    "print(f\"cutoff_date: {cutoff_date}\")\n",
    "# print(f\"week_data: {week_data}\")\n",
    "print(f\"count_decrease: {count_decrease}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df_full.groupby('date',observed=True)['coin_id'].nunique().tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "dr.check_coin_coverage(profits_df_full,wallets_config['data_cleaning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts = profits_df_full.groupby('date')['coin_id'].nunique()\n",
    "latest_count = daily_counts.iloc[-1]\n",
    "week_max = daily_counts.iloc[-7:].max()\n",
    "pct_change = ((latest_count - week_max) / week_max * 100).round(2)\n",
    "\n",
    "print(f\"Latest count: {latest_count:,}\")\n",
    "print(f\"7-day high: {week_max:,}\")\n",
    "print(f\"Percent change: {pct_change}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate features for the full training dataset\n",
    "logger.info(\"Generating features for full training period...\")\n",
    "training_wallet_features_df = wfo.calculate_wallet_features(training_profits_df, market_indicators_data_df,\n",
    "                                                           transfers_sequencing_df, wallet_cohort)\n",
    "\n",
    "# Define the full feature set by appending a suffix for each window\n",
    "training_data_df = training_wallet_features_df.add_suffix(\"_all_windows\")\n",
    "\n",
    "# Generate features for each window\n",
    "for i, window_profits_df in enumerate(training_windows_profits_dfs, 1):\n",
    "    logger.info(\"Generating features for window %s...\", i)\n",
    "\n",
    "    # Generate the features\n",
    "    window_wallet_features_df = wfo.calculate_wallet_features(window_profits_df, market_indicators_data_df,\n",
    "                                                             transfers_sequencing_df, wallet_cohort)\n",
    "\n",
    "    # Check for NaN values and identify problematic columns\n",
    "    nan_columns = window_wallet_features_df.columns[window_wallet_features_df.isna().any()].tolist()\n",
    "    if nan_columns:\n",
    "        raise ValueError(f\"NaN values detected in window {i} in columns: {nan_columns}\")\n",
    "\n",
    "    # Add column suffix and join to training_data_df\n",
    "    window_wallet_features_df = window_wallet_features_df.add_suffix(f'_w{i}')\n",
    "    training_data_df = training_data_df.join(window_wallet_features_df, how='left')\n",
    "\n",
    "    # Check for NaN values and identify problematic columns\n",
    "    nan_columns = training_data_df.columns[training_data_df.isna().any()].tolist()\n",
    "    if nan_columns:\n",
    "        raise ValueError(f\"NaN values detected in training_data_df after window {i} in columns: {nan_columns}\")\n",
    "\n",
    "# Append clustering features based on all numeric features in the base training data\n",
    "cluster_features_df = wcl.create_basic_cluster_features(training_data_df)\n",
    "cluster_features_df = cluster_features_df.add_prefix('cluster_')\n",
    "training_data_df = training_data_df.join(cluster_features_df, how='inner')\n",
    "\n",
    "# Verify all input wallets exist in final output\n",
    "missing_wallets = set(wallet_cohort) - set(training_data_df.index)\n",
    "if missing_wallets:\n",
    "    raise ValueError(f\"Lost {len(missing_wallets)} wallets from original cohort during feature generation. First few missing: {list(missing_wallets)[:5]}\")\n",
    "\n",
    "logger.info(\"Feature generation complete.\")\n",
    "\n",
    "training_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join target variable to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Clean inactive wallets from modeling period data\n",
    "modeling_wallets_df = wmo.filter_modeling_period_wallets(modeling_profits_df)\n",
    "\n",
    "# Generate target variables\n",
    "target_vars_df = wpf.calculate_performance_features(modeling_wallets_df)\n",
    "\n",
    "# Merge training data and target variables?\n",
    "modeling_df = training_data_df.join(target_vars_df[wallets_config['modeling']['target_variable']],\n",
    "                                    how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create an experiment instance\n",
    "experiment = wm.WalletModel(wallets_config)\n",
    "\n",
    "# Run the experiment and get results\n",
    "model_results = experiment.run_experiment(modeling_df)\n",
    "\n",
    "# Extract the trained model\n",
    "model = model_results['pipeline'].named_steps['regressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess wallet model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model artifacts\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, evaluator, wallet_scores_df, coin_validation_df = wmr.generate_and_save_model_artifacts(\n",
    "    model_results=model_results,\n",
    "    validation_profits_df=validation_profits_df,\n",
    "    base_path='../wallet_modeling'\n",
    ")\n",
    "u.play_notification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model artifacts\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Reload evaluator\n",
    "evaluator = wime.RegressionEvaluator(\n",
    "    y_train=model_results['y_train'],\n",
    "    y_true=model_results['y_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    model=model,\n",
    "    feature_names=model_results['X_train'].columns.tolist()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(evaluator.summary_report())\n",
    "evaluator.plot_evaluation()\n",
    "evaluator.importance_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# List of the x features with the highest importance in the model\n",
    "x_features = 8\n",
    "top_feature_metrics = list((pd.DataFrame(evaluator.metrics['importances'])\n",
    "                      .sort_values(by='importance',ascending=False)\n",
    "                      .head(x_features)['feature']))\n",
    "all_metrics = list(set(top_feature_metrics))\n",
    "\n",
    "# Cluster numbers\n",
    "n_clusters=4\n",
    "\n",
    "styled_df = wime.create_cluster_report(modeling_df, model_results, n_clusters, all_metrics)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modeling dataset using existing pipeline\n",
    "modeling_wallets_df = wmo.filter_modeling_period_wallets(modeling_profits_df)\n",
    "target_vars_df = wpf.calculate_performance_features(modeling_wallets_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model artifacts\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# 1. Initialize dependencies\n",
    "metrics_config = {\n",
    "    'rmse': lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    'r2': r2_score\n",
    "}\n",
    "\n",
    "# 2. Define experiment sequence\n",
    "sequence_config = {\n",
    "    'run_baseline': True,\n",
    "    'parameter_variations': {\n",
    "        'modeling': {\n",
    "            'target_variable': [\n",
    "                'max_investment',\n",
    "                'total_net_flows',\n",
    "                'return',\n",
    "                'realized_return',\n",
    "                'return_unwinsorized',\n",
    "                'performance_score',\n",
    "                'size_adjusted_rank'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Create experiment manager\n",
    "exp_manager = wem.ExperimentsManager(\n",
    "    config=wallets_config.config,\n",
    "    training_data_df=training_data_df,\n",
    ")\n",
    "\n",
    "# 4. Run experiments and get results\n",
    "results_df = exp_manager.run_experiment_sequence(modeling_profits_df, sequence_config)\n",
    "\n",
    "# 5. View results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation period assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wallet_performance_df, bucketed_performance_df = wica.calculate_validation_metrics(\n",
    "    X_test=model_results['X_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    validation_profits_df=validation_profits_df,\n",
    "    n_buckets=10,\n",
    "    method='ntiles'\n",
    ")\n",
    "\n",
    "bucketed_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic coin model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create coin_validation_df with metrics and returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Consolidate wallet scores at the coin level\n",
    "wallet_scores_df = pd.DataFrame({'score': model_results['y_pred']}, index=model_results['y_test'].index)\n",
    "coin_wallet_metrics_df = wica.calculate_coin_metrics_from_wallet_scores(validation_profits_df, wallet_scores_df)\n",
    "\n",
    "# Calculate coin performance during the validation period\n",
    "coin_performance_df = wica.calculate_coin_performance(market_data_df,\n",
    "                                                     wallets_config['training_data']['validation_period_start'],\n",
    "                                                     wallets_config['training_data']['validation_period_end'])\n",
    "\n",
    "# Join aggregated wallet metrics with actual coin performance\n",
    "coin_validation_df = coin_wallet_metrics_df.join(coin_performance_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_modeling_df = coin_validation_df.copy().drop('market_cap',axis=1)\n",
    "coin_modeling_df['coin_return'] = u.winsorize(coin_modeling_df['coin_return'],0.05)\n",
    "coin_modeling_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coin_modeling_df.copy()\n",
    "\n",
    "# 1. Simple feature prep and model\n",
    "X, y = wicm.prepare_features(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate with the fancy evaluator\n",
    "feature_names = df.columns.drop(['coin_return', 'market_cap_filled']).tolist()\n",
    "evaluator = wime.RegressionEvaluator(y_train, y_test, y_pred, model=model, feature_names=feature_names)\n",
    "\n",
    "# 5. Get the goods\n",
    "print(evaluator.summary_report())\n",
    "\n",
    "# 6. Plot everything\n",
    "evaluator.plot_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coin performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = wica.analyze_market_cap_segments(\n",
    "    coin_validation_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "wica.plot_segment_heatmap(summary_df)\n",
    "wica.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_validation_analysis']['top_n']\n",
    "max_market_cap = wallets_config['coin_validation_analysis']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_validation_analysis']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = wica.validate_coin_performance(coin_validation_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare performance of high vs low score coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wica.print_performance_analysis(coin_validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coin_modeling_df.copy()\n",
    "\n",
    "# Check target distribution\n",
    "print(\"Coin return stats:\")\n",
    "print(df['coin_return'].describe())\n",
    "\n",
    "# Check for outliers/infinite values in features\n",
    "print(\"\\nInfinite values in features:\")\n",
    "print(df.isna().sum())\n",
    "print(df.isin([np.inf, -np.inf]).sum())\n",
    "\n",
    "# Look at feature correlations with target\n",
    "correlations = df.drop(['coin_return', 'market_cap_filled'], axis=1).corrwith(df['coin_return'])\n",
    "print(\"\\nTop correlations with return:\")\n",
    "print(correlations.sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_profits_df_for_cleaning():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample profits DataFrame with multiple coins per wallet.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'BTC', 'ETH', 'LTC', 'BTC', 'ETH'],\n",
    "        'wallet_address': ['wallet1', 'wallet1', 'wallet2', 'wallet2','wallet2',\n",
    "                           'wallet3', 'wallet3'],\n",
    "        'date': pd.date_range(start='2023-01-01', periods=7),\n",
    "        'profits_cumulative': [5000, 3000, 1000, 500, 500, 100, 50],\n",
    "        'usd_inflows_cumulative': [10000, 8000, 2000, 1500, 1500, 500, 250]\n",
    "    })\n",
    "sample_profits_df_for_cleaning = sample_profits_df_for_cleaning()\n",
    "\n",
    "\n",
    "def sample_data_cleaning_config():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample data cleaning configuration.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'max_wallet_coin_profits': 7500,\n",
    "        'max_wallet_inflows': 15000,\n",
    "        'price_coverage_warning_min_coin_increase': 999,\n",
    "        'price_coverage_warning_min_pct_increase': 1.0,\n",
    "        'transfers_coverage_warning_min_coin_increase': 999,\n",
    "        'transfers_coverage_warning_min_pct_increase': 1.0,\n",
    "\n",
    "    }\n",
    "\n",
    "sample_data_cleaning_config = sample_data_cleaning_config()\n",
    "\n",
    "# Call the function\n",
    "cleaned_df, exclusions_logs_df = dr.clean_profits_df(sample_profits_df_for_cleaning,\n",
    "                                                        sample_data_cleaning_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Expected results\n",
    "expected_cleaned_df = sample_profits_df_for_cleaning[\n",
    "    sample_profits_df_for_cleaning['wallet_address'].isin(['wallet2', 'wallet3'])\n",
    "].reset_index(drop=True)\n",
    "expected_exclusions = pd.DataFrame({\n",
    "    'wallet_address': ['wallet1'],\n",
    "    'profits_exclusion': [True],\n",
    "    'inflows_exclusion': [True]\n",
    "})\n",
    "\n",
    "# Assertions\n",
    "assert len(cleaned_df) == 5  # wallet2 (3 records) and wallet3 (2 records) should remain\n",
    "assert np.array_equal(cleaned_df.values, expected_cleaned_df.values)\n",
    "assert np.array_equal(exclusions_logs_df.values, expected_exclusions.values)\n",
    "\n",
    "# Check if profits and inflows are approximately correct for the remaining wallets\n",
    "# 1000 + 500 + 500 + 100 + 50\n",
    "assert pytest.approx(cleaned_df['profits_cumulative'].sum(), abs=1e-4) == 2150\n",
    "# 2000 + 1500 + 1500 + 500 + 250\n",
    "assert pytest.approx(cleaned_df['usd_inflows_cumulative'].sum(), abs=1e-4) == 5750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_cleaning_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_profits_df_for_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusions_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
