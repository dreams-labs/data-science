{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from google.cloud import bigquery\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['LOGGING_FILE']=\"../../../Local/logs/wallet_modeling.log\"\n",
    "os.environ['ALERT_SOUND_FILEPATH']=\"../../../Local/assets/sounds/mixkit-alert-bells-echo-765.wav\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.clustering_features as wcl\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.performance_features as wpf\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.wallet_features_orchestrator as wfo\n",
    "\n",
    "# Base modeling\n",
    "import base_modeling.base_model as bm\n",
    "import base_modeling.feature_selection as fs\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_modeling_orchestrator as wmo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_modeling.wallet_model_reporting as wmr\n",
    "import wallet_modeling.wallet_model as wm\n",
    "import wallet_modeling.experiments_manager as wem\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.model_evaluation as wime\n",
    "import wallet_insights.wallet_experiments_orchestrator as wimo\n",
    "import wallet_insights.wallet_validation_analysis as wiva\n",
    "import wallet_insights.wallet_cluster_analysis as wica\n",
    "\n",
    "# Coin features\n",
    "import coin_wallet_features.coin_features_orchestrator as cfo\n",
    "import coin_wallet_features.wallet_base_metrics as cwbm\n",
    "import coin_wallet_features.wallet_segmentation as cws\n",
    "\n",
    "# Coin modeling\n",
    "import coin_modeling.coin_model_reporting as cmr\n",
    "import coin_modeling.coin_model as cm\n",
    "\n",
    "# Coin insights\n",
    "import coin_insights.coin_validation_analysis as civa\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [\n",
    "    u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp,\n",
    "    wmo, wtd, wmr, wm, wem,\n",
    "    wcl, wmc, wmt, wpf, wtf, wts, wfo,\n",
    "    bm, fs,\n",
    "    wime, wimo, wiva, wica,\n",
    "    cfo, cwbm, cws,\n",
    "    cmr, cm,\n",
    "    civa,\n",
    "]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "wallets_config = WalletsConfig.load_from_yaml('../config/wallets_config.yaml')\n",
    "\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# make parquet dirs if they don't already exist\n",
    "Path(wallets_config['training_data']['parquet_folder']).mkdir(parents=True, exist_ok=True)\n",
    "Path(wallets_coin_config['wallet_segments']['parquet_folder']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set the custom error handler\n",
    "ipython = IPython.get_ipython()\n",
    "ipython.set_custom_exc((Exception,), u.notify_on_failure)\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "# logger = u.setup_local_logging(logger)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "[importlib.reload(module) for module in modules]\n",
    "# u.notify('startup')\n",
    "# u.notify('intro_3')\n",
    "u.notify('retro')\n",
    "\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.export_code(\n",
    "    code_directories=[\n",
    "        # 'training_data',\n",
    "        # 'wallet_features',\n",
    "        # 'wallet_modeling',\n",
    "        # 'wallet_insights'\n",
    "    ],\n",
    "    # include_config = True,\n",
    "    ipynb_notebook = 'DDA-434 hybrid wallet address key.ipynb'\n",
    ")\n",
    "\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wallet Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Complete Pre-Training Profits/Market Data\n",
    "# -----------------------------------------\n",
    "# Retrieve training period datasets and save them to wallets_config['training_data']['parquet_folder']\n",
    "_,_,_ = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['training_period_start'],\n",
    "    wallets_config['training_data']['training_period_end'],\n",
    "    parquet_prefix = 'training')\n",
    "\n",
    "del _\n",
    "gc.collect()\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDA-434 hybrid column replacement for normal wallet_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "if wallets_config['training_data']['hybridize_wallet_ids'] is True:\n",
    "\n",
    "    # Retrieve training_profits_df_full\n",
    "    hybridized_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_profits_df_full.parquet\")\n",
    "\n",
    "    # Hybridize and save mapping\n",
    "    hybridized_profits_df,hybrid_cw_id_map = wmo.hybridize_wallet_address(hybridized_profits_df)\n",
    "    pd.to_pickle(hybrid_cw_id_map, f\"{wallets_config['training_data']['parquet_folder']}/hybrid_cw_id_map.pkl\")\n",
    "\n",
    "    # Upload mappings to bigquery\n",
    "    wmo.upload_hybrid_wallet_mapping(hybrid_cw_id_map)\n",
    "\n",
    "    # Overwrite original\n",
    "    hybridized_profits_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_profits_df_full.parquet\",index=False)\n",
    "    del hybridized_profits_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define cohort and clean training datasets (loadable parquet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "\n",
    "# Add Indicators to Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Load relevant parquet dfs with pre-training history\n",
    "training_market_data_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_market_data_df_full.parquet\")\n",
    "\n",
    "# Generate indicators and save file\n",
    "_ = wmo.generate_training_indicators_df(training_market_data_df_full,wallets_metrics_config)\n",
    "\n",
    "\n",
    "\n",
    "# Identify Wallet Cohort\n",
    "# ----------------------------------------------------------\n",
    "# Remove market data from prior to the starting balance date\n",
    "training_market_data_df = training_market_data_df_full[training_market_data_df_full['date']\n",
    "                                        >=wallets_config['training_data']['training_starting_balance_date']]\n",
    "u.assert_period(training_market_data_df,\n",
    "                wallets_config['training_data']['training_period_start'],\n",
    "                wallets_config['training_data']['training_period_end'])\n",
    "del training_market_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "# Retrieve full profits history\n",
    "training_profits_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_profits_df_full.parquet\")\n",
    "\n",
    "# Define wallet cohort and return cohort-filtered training_profits_df\n",
    "training_profits_df, training_wallet_cohort = wmo.define_training_wallet_cohort(\n",
    "    training_profits_df_full,\n",
    "    training_market_data_df,\n",
    "    wallets_config['training_data']['hybridize_wallet_ids']\n",
    ")\n",
    "u.assert_period(training_profits_df,\n",
    "                wallets_config['training_data']['training_period_start'],\n",
    "                wallets_config['training_data']['training_period_end'])\n",
    "training_profits_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_profits_df.parquet\",index=True)\n",
    "del training_profits_df_full,training_profits_df,training_market_data_df\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Retrieve Transfers Data\n",
    "# ----------------------------------------------------------\n",
    "# Transfers data retrieval for the wallet_ids in temp.wallet_modeling_training_cohort\n",
    "training_transfers_sequencing_df = wts.retrieve_transfers_sequencing(wallets_config['training_data']['hybridize_wallet_ids'])\n",
    "training_transfers_sequencing_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_transfers_sequencing_df.parquet\",index=True)\n",
    "del training_transfers_sequencing_df,_\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate training features (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Load files\n",
    "training_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_profits_df.parquet\")\n",
    "training_market_indicators_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_market_indicators_data_df.parquet\")\n",
    "training_transfers_sequencing_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_transfers_sequencing_df.parquet\")\n",
    "training_wallet_cohort = list(set(training_profits_df['wallet_address']))\n",
    "\n",
    "\n",
    "# Generate Features for the Full Training Period\n",
    "# ----------------------------------------------------------\n",
    "logger.info(\"Generating features for full training period...\")\n",
    "training_wallet_features_df = wfo.calculate_wallet_features(training_profits_df,\n",
    "                                                            training_market_indicators_data_df,\n",
    "                                                            training_transfers_sequencing_df,\n",
    "                                                            training_wallet_cohort,\n",
    "                                                            wallets_config['training_data']['training_period_start'],\n",
    "                                                            wallets_config['training_data']['training_period_end'])\n",
    "\n",
    "# Define the start of wallet_training_data_df_full appending a suffix for the window\n",
    "wallet_training_data_df_full = training_wallet_features_df.add_suffix(\"|all_windows\").copy()\n",
    "wallet_training_data_df_full.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\",index=True)\n",
    "\n",
    "del training_wallet_features_df,wallet_training_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate training features for each segment window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Load parquet\n",
    "wallet_training_data_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\")\n",
    "\n",
    "\n",
    "# Generate Cohort-Filtered Profits Data for Training Windows\n",
    "# ----------------------------------------------------------\n",
    "# Generate wallet_cohort-filtered profits_df for all training windows\n",
    "training_windows_profits_dfs = wmo.split_training_window_profits_dfs(\n",
    "                                                        training_profits_df,\n",
    "                                                        training_market_indicators_data_df,\n",
    "                                                        training_wallet_cohort)\n",
    "del training_profits_df\n",
    "gc.collect()\n",
    "\n",
    "# Generate Features for Each Individual Window\n",
    "# ----------------------------------------------------------\n",
    "# Generate features for each window\n",
    "for i, window_profits_df in enumerate(training_windows_profits_dfs, 1):\n",
    "    logger.info(\"Generating features for window %s...\", i)\n",
    "\n",
    "    # Extract the window_df boundary dates that were validated by split_training_window_profits_dfs()\n",
    "    window_opening_balance_date = window_profits_df['date'].min()\n",
    "    window_start_date = window_opening_balance_date + timedelta(days=1)\n",
    "    window_end_date = window_profits_df['date'].max()\n",
    "\n",
    "    # Generate the features\n",
    "    window_wallet_features_df = wfo.calculate_wallet_features(\n",
    "        window_profits_df,  # profits_df is filtered to the window\n",
    "        training_market_indicators_data_df,training_transfers_sequencing_df,  # full training period dfs\n",
    "        training_wallet_cohort,  # full training cohort\n",
    "        window_start_date.strftime('%Y-%m-%d'), window_end_date.strftime('%Y-%m-%d')  # window-specific dates\n",
    "    )\n",
    "\n",
    "    # Add column suffix and join to wallet_training_data_df_full\n",
    "    window_wallet_features_df = window_wallet_features_df.add_suffix(f'|w{i}')\n",
    "    wallet_training_data_df_full = wallet_training_data_df_full.join(window_wallet_features_df, how='left')\n",
    "\n",
    "\n",
    "# Save and clear from memory\n",
    "wallet_training_data_df_full.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full_unclustered.parquet\",index=True)\n",
    "training_windows_profits_dfs.clear()  # Clear list contents\n",
    "del wallet_training_data_df_full,window_profits_df,window_wallet_features_df,training_market_indicators_data_df,training_transfers_sequencing_df,training_windows_profits_dfs\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Load Parquet\n",
    "wallet_training_data_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full_unclustered.parquet\")\n",
    "\n",
    "\n",
    "# Generate Clusters Using All Other Features\n",
    "# ----------------------------------------------------------\n",
    "# Append clustering features based on all numeric features in the base training data\n",
    "\n",
    "training_cluster_features_df = wcl.create_kmeans_cluster_features(wallet_training_data_df_full)\n",
    "training_cluster_features_df = training_cluster_features_df.add_prefix('cluster|')\n",
    "wallet_training_data_df_full = wallet_training_data_df_full.join(training_cluster_features_df, how='inner')\n",
    "\n",
    "\n",
    "# Save WALLET_TRAINING_DATA_DF\n",
    "# ----------------------------------------------------------\n",
    "# Verify all input wallets exist in final output\n",
    "missing_wallets = set(training_wallet_cohort) - set(wallet_training_data_df_full.index)\n",
    "if missing_wallets:\n",
    "    raise ValueError(f\"Lost {len(missing_wallets)} wallets from original cohort during feature generation. First few missing: {list(missing_wallets)[:5]}\")\n",
    "logger.info(\"Feature generation complete. Final training_df shape: %s\", wallet_training_data_df_full.shape)\n",
    "\n",
    "# Save and clear from memory\n",
    "wallet_training_data_df_full.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\",index=True)\n",
    "del wallet_training_data_df_full,training_cluster_features_df\n",
    "gc.collect()\n",
    "\n",
    "u.notify(3)\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Model Target Variable and Wallet Cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve modeling period datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve Modeling Profits and Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve training coin cohort to restrict modeling period data to only training period coins\n",
    "training_coin_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_market_indicators_data_df.parquet\",\n",
    "                                       columns=['coin_id'])['coin_id'].unique()\n",
    "# Retrieve full historical through modeling period datasets\n",
    "modeling_profits_df_full, modeling_market_data_df_full, modeling_coin_cohort = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['modeling_period_start'],\n",
    "    wallets_config['training_data']['modeling_period_end'],\n",
    "    coin_cohort=training_coin_cohort\n",
    ")\n",
    "\n",
    "# Remove pre-modeling period prices\n",
    "modeling_market_data_df = modeling_market_data_df_full[modeling_market_data_df_full['date']\n",
    "                                                       >=wallets_config['training_data']['modeling_starting_balance_date']]\n",
    "\n",
    "modeling_profits_df_full.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_profits_df_full.parquet\",index=False)\n",
    "\n",
    "# del modeling_market_data_df_full,modeling_profits_df_full,training_coin_cohort\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dda 434 hybridize modeling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_profits_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_profits_df_full.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "if wallets_config['training_data']['hybridize_wallet_ids'] is True:\n",
    "\n",
    "    # Hybridize\n",
    "    modeling_profits_df_full, _ = wmo.hybridize_wallet_address(modeling_profits_df_full, hybrid_cw_id_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter to only training wallet cohort\n",
    "training_wallet_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\", columns=[]).index.values\n",
    "# modeling_profits_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_profits_df_full.parquet\")\n",
    "modeling_profits_df = modeling_profits_df_full[modeling_profits_df_full['wallet_address'].isin(training_wallet_cohort)]\n",
    "del modeling_profits_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Assert period, save files, remove from memory\n",
    "u.assert_period(modeling_market_data_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n",
    "u.assert_period(modeling_profits_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n",
    "modeling_profits_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_profits_df.parquet\",index=False)\n",
    "modeling_market_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_market_data_df.parquet\",index=False)\n",
    "# del modeling_profits_df,modeling_market_data_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define modeling cohort and features (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Create training_cohort-Indexed modeling_wallet_features_df\n",
    "# -----------------------------------------------------------\n",
    "# Create a DataFrame with training wallet cohort as the index\n",
    "training_wallet_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\", columns=[]).index.values\n",
    "modeling_wallet_features_df = pd.DataFrame(index=training_wallet_cohort)\n",
    "modeling_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "# Store feature sets with their prefixes for bulk renaming\n",
    "feature_column_names = {}\n",
    "\n",
    "\n",
    "# Identify Modeling Period Cohort\n",
    "# -----------------------------------------------------------\n",
    "# Retrieve trading features for all wallets in training_cohort with boolean for in_modeling_cohort\n",
    "modeling_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_profits_df.parquet\")\n",
    "modeling_trading_features_df = wmo.identify_modeling_cohort(modeling_profits_df)\n",
    "modeling_wallet_features_df = modeling_wallet_features_df.join(modeling_trading_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in modeling_trading_features_df.columns})\n",
    "\n",
    "\n",
    "# Generate Modeling Period Performance Features\n",
    "# -----------------------------------------------------------\n",
    "# Calculate performance metrics for the training cohort (wallets with 0 activity still impact rank orders)\n",
    "modeling_performance_features_df = wpf.calculate_performance_features(\n",
    "    modeling_wallet_features_df,\n",
    "    include_twb_metrics=False)\n",
    "modeling_wallet_features_df = modeling_wallet_features_df.join(modeling_performance_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in modeling_performance_features_df.columns})\n",
    "\n",
    "\n",
    "modeling_wallet_features_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_wallet_features_df.parquet\",index=True)\n",
    "# del modeling_profits_df,modeling_wallet_features_df,modeling_trading_features_df,modeling_performance_features_df\n",
    "# gc.collect()\n",
    "\n",
    "# u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Model Construction and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dda 434 data compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load both training sets\n",
    "wallet_training_data_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full_unclustered.parquet\")\n",
    "wallet_training_data_df_base_full = pd.read_parquet(f\"temp/wallet_modeling_dfs_base/wallet_training_data_df_full_unclustered.parquet\")\n",
    "\n",
    "# Dehybridize address and join together\n",
    "wallet_training_data_df_full['wallet_address_base'] = wallet_training_data_df_full.index.values\n",
    "wallet_training_data_df_full = wmo.dehybridize_wallet_address(wallet_training_data_df_full,\n",
    "                                                              hybrid_cw_id_map,\n",
    "                                                              'wallet_address_base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(wallet_training_data_df_base_full.columns)\n",
    "\n",
    "performance_cols_df = wallet_training_data_df_base_full.loc[:, wallet_training_data_df_base_full.columns.str.startswith(('performance', 'trading|unique_coins_traded|all_windows'))]\n",
    "\n",
    "\n",
    "performance_cols_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wallet_training_data_df_full = wallet_training_data_df_full.merge(performance_cols_df,\n",
    "                                                                  left_on='wallet_address_base',\n",
    "                                                                  right_index=True,\n",
    "                                                                  suffixes=('/walletcoin', '/wallet')\n",
    "                                                                  ).drop('wallet_address_base', axis=1)\n",
    "\n",
    "wallet_training_data_df_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# # Load parquet\n",
    "wallet_training_data_df_full = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df_full.parquet\")\n",
    "modeling_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_wallet_features_df.parquet\")\n",
    "\n",
    "# Add modeling cohort boolean\n",
    "modeling_wallet_training_data_df = wallet_training_data_df_full.join(modeling_wallet_features_df['in_modeling_cohort'], how='inner')\n",
    "modeling_wallet_training_data_df = modeling_wallet_training_data_df[modeling_wallet_training_data_df['in_modeling_cohort']==1]\n",
    "modeling_wallet_training_data_df = modeling_wallet_training_data_df.drop(columns='in_modeling_cohort',axis=1)\n",
    "logger.info(\"Full training data df shape: %s\", wallet_training_data_df_full.shape)\n",
    "logger.info(\"Modeling cohort training data df shape: %s\", modeling_wallet_training_data_df.shape)\n",
    "\n",
    "# # Remove low variance features\n",
    "# modeling_wallet_training_data_df = fs.remove_low_variance_features(modeling_wallet_training_data_df,\n",
    "#                 wallets_config[''features']['feature_selection'['variance_threshold'],\n",
    "#                 wallets_config[''features']['feature_selection'['protected_features'])\n",
    "\n",
    "# # Remove correlated features\n",
    "# modeling_wallet_training_data_df = fs.remove_correlated_features(modeling_wallet_training_data_df,\n",
    "#                 wallets_config[''features']['feature_selection'['correlation_threshold'],\n",
    "#                 wallets_config[''features']['feature_selection'['protected_features'])\n",
    "\n",
    "\n",
    "# # Filter training data df to only the selected columns\n",
    "# wallet_training_data_df = wallet_training_data_df_full[modeling_wallet_training_data_df.columns]\n",
    "wallet_training_data_df = wallet_training_data_df_full\n",
    "logger.info(\"Pruned training data df shape: %s\", wallet_training_data_df.shape)\n",
    "\n",
    "# Save to parquet and delete\n",
    "wallet_training_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\",index=True)\n",
    "del wallet_training_data_df_full,modeling_wallet_training_data_df,wallet_training_data_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select target variable (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create MODELING_DF and Construct Wallet Model\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "modeling_wallet_features_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_wallet_features_df.parquet\")\n",
    "\n",
    "# Filter training data to only the modeling cohort through inner join to target variable\n",
    "modeling_cohort_target_var_df = modeling_wallet_features_df[['in_modeling_cohort', wallets_config['modeling']['target_variable']]].copy()\n",
    "\n",
    "# Winsorize dollar amount columns\n",
    "if wallets_config['modeling']['target_variable'] == 'crypto_net_gain':\n",
    "\n",
    "    modeling_cohort_target_var_df['crypto_net_gain'] = u.winsorize(\n",
    "        modeling_cohort_target_var_df[wallets_config['modeling']['target_variable']],\n",
    "        wallets_config['features']['returns_winsorization']\n",
    "    )\n",
    "\n",
    "u.notify(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orchestrate experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [importlib.reload(module) for module in modules]\n",
    "# wallets_config.reload()\n",
    "\n",
    "# # Load experiments config\n",
    "# wallets_config_experiment = yaml.safe_load(Path('../config/wallets_config_experiment.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# # Initialize orchestrator with both configs\n",
    "# orchestrator = wimo.WalletExperimentsOrchestrator(\n",
    "#     config_base=wallets_config.config,         # your base config dict\n",
    "#     config_experiment=wallets_config_experiment  # your experiment config dict\n",
    "# )\n",
    "\n",
    "# # Run experiment\n",
    "# results = orchestrator.orchestrate_wallet_experiment(\n",
    "#     training_data_df=wallet_training_data_df,\n",
    "#     modeling_wallet_features_df=modeling_wallet_features_df\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\")\n",
    "\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(wallet_training_data_df,modeling_cohort_target_var_df)\n",
    "del wallet_training_data_df\n",
    "gc.collect()\n",
    "\n",
    "# Extract the trained model\n",
    "model = wallet_model_results['pipeline'].named_steps['regressor']\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, wallet_evaluator, modeling_wallet_scores_df = wmr.generate_and_save_wallet_model_artifacts(\n",
    "    model_results=wallet_model_results,\n",
    "    base_path='../artifacts/wallet_modeling',\n",
    "    configs = {\n",
    "        'wallets_config': wallets_config.config,\n",
    "        'wallets_metrics_config': wallets_metrics_config,\n",
    "        'wallets_features_config': wallets_features_config\n",
    "    }\n",
    ")\n",
    "\n",
    "# save score\n",
    "modeling_wallet_scores_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_wallet_scores_df.parquet\",index=True)\n",
    "\n",
    "\n",
    "print(wallet_evaluator.summary_report())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dda 434 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\")\n",
    "wallet_training_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_training_data_df[wallet_training_data_df['trading|unique_coins_traded|all_windows/wallet']>=3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Retrieve training data for the full training wallet cohort\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\")\n",
    "\n",
    "\n",
    "wallet_training_data_df = wallet_training_data_df[wallet_training_data_df['trading|unique_coins_traded|all_windows/wallet']>=3]\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(wallet_training_data_df,modeling_cohort_target_var_df)\n",
    "del wallet_training_data_df\n",
    "gc.collect()\n",
    "\n",
    "# Extract the trained model\n",
    "model = wallet_model_results['pipeline'].named_steps['regressor']\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, wallet_evaluator, modeling_wallet_scores_df = wmr.generate_and_save_wallet_model_artifacts(\n",
    "    model_results=wallet_model_results,\n",
    "    base_path='../artifacts/wallet_modeling',\n",
    "    configs = {\n",
    "        'wallets_config': wallets_config.config,\n",
    "        'wallets_metrics_config': wallets_metrics_config,\n",
    "        'wallets_features_config': wallets_features_config\n",
    "    }\n",
    ")\n",
    "\n",
    "# save score\n",
    "modeling_wallet_scores_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_wallet_scores_df.parquet\",index=True)\n",
    "\n",
    "\n",
    "print(wallet_evaluator.summary_report())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve training data for the full training wallet cohort\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\")\n",
    "\n",
    "\n",
    "wallet_training_data_df = wallet_training_data_df[wallet_training_data_df['trading|unique_coins_traded|all_windows/wallet']>=3]\n",
    "\n",
    "wallet_training_data_df = wallet_training_data_df.loc[:, ~wallet_training_data_df.columns.str.endswith('/wallet')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# # Retrieve training data for the full training wallet cohort\n",
    "# wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\")\n",
    "\n",
    "\n",
    "# Run the experiment and get results\n",
    "wallet_model = wm.WalletModel(wallets_config['modeling'])\n",
    "wallet_model_results = wallet_model.construct_wallet_model(wallet_training_data_df,modeling_cohort_target_var_df)\n",
    "del wallet_training_data_df\n",
    "gc.collect()\n",
    "\n",
    "# Extract the trained model\n",
    "model = wallet_model_results['pipeline'].named_steps['regressor']\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, wallet_evaluator, modeling_wallet_scores_df = wmr.generate_and_save_wallet_model_artifacts(\n",
    "    model_results=wallet_model_results,\n",
    "    base_path='../artifacts/wallet_modeling',\n",
    "    configs = {\n",
    "        'wallets_config': wallets_config.config,\n",
    "        'wallets_metrics_config': wallets_metrics_config,\n",
    "        'wallets_features_config': wallets_features_config\n",
    "    }\n",
    ")\n",
    "\n",
    "# save score\n",
    "modeling_wallet_scores_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_wallet_scores_df.parquet\",index=True)\n",
    "\n",
    "\n",
    "print(wallet_evaluator.summary_report())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess wallet model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Reload evaluator\n",
    "wallet_evaluator = wime.RegressionEvaluator(\n",
    "    y_train=wallet_model_results['y_train'],\n",
    "    y_test=wallet_model_results['y_test'],\n",
    "    y_pred=wallet_model_results['y_pred'],\n",
    "    training_cohort_pred=wallet_model_results['training_cohort_pred'],\n",
    "    training_cohort_actuals=wallet_model_results['training_cohort_actuals'],\n",
    "    model=model,\n",
    "    feature_names=wallet_model_results['X_train'].columns.tolist()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(wallet_evaluator.summary_report())\n",
    "wallet_evaluator.plot_wallet_evaluation()\n",
    "wallet_evaluator.importance_summary(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wallet_evaluator.metrics['importances']['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_evaluator.metrics['importances']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scores for coin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # score_name = 'net_gain_winsorized_250101'\n",
    "\n",
    "# # Special save score for use in the coin model\n",
    "\n",
    "# # Create wallet scores DataFrame with both cohorts\n",
    "# modeling_wallet_scores_df = pd.DataFrame({\n",
    "#     f'score|{score_name}': wallet_model_results['training_cohort_pred'],\n",
    "#     f'actual|{score_name}': wallet_model_results['training_cohort_actuals'],\n",
    "#     'in_modeling_cohort': wallet_model_results['training_cohort_pred'].index.isin(wallet_model_results['y_test'].index)\n",
    "# })\n",
    "\n",
    "# modeling_wallet_scores_df.head()\n",
    "\n",
    "\n",
    "# # scores_df.head()\n",
    "# modeling_wallet_scores_df.to_parquet(f\"temp/wallet_modeling_score_dfs/{score_name}.parquet\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_evaluator.importance_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "feature_importances_df = wiva.analyze_wallet_model_importance(wallet_evaluator.metrics['importances'])\n",
    "\n",
    "feature_categories_filter = [\n",
    "    # 'performance',\n",
    "    'timing',\n",
    "    # 'trading',\n",
    "    # 'transfers',\n",
    "    # 'mktcap',\n",
    "    # 'cluster',\n",
    "]\n",
    "\n",
    "feature_names_filter = [\n",
    "    'price_sma_5',\n",
    "    # 'price_rsi_5',\n",
    "    # 'volume_sma_5',\n",
    "    # 'market_cap_filled',\n",
    "    # 'mktcap',\n",
    "    # 'cluster',\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    'record_type',\n",
    "    'feature_category',\n",
    "    # 'feature_name',\n",
    "    # 'feature_comparison',\n",
    "    # 'feature_aggregation',\n",
    "    # 'training_segment',\n",
    "]\n",
    "\n",
    "(feature_importances_df\n",
    "#  [feature_importances_df['feature_category'].isin(feature_categories_filter)]\n",
    "#  [feature_importances_df['feature_name'].isin(feature_names_filter)]\n",
    " .groupby(groups)\n",
    " .sum('importance')\n",
    " .sort_values(by='importance',ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Load parquet\n",
    "wallet_training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\")\n",
    "\n",
    "\n",
    "# List of the x features with the highest importance in the model\n",
    "x_features = 6\n",
    "top_feature_metrics = list((pd.DataFrame(wallet_evaluator.metrics['importances'])\n",
    "                      .sort_values(by='importance',ascending=False)\n",
    "                      .head(x_features)['feature']))\n",
    "comparison_metrics = list(set(top_feature_metrics))\n",
    "\n",
    "\n",
    "\n",
    "# Cluster numbers\n",
    "n_clusters=4\n",
    "\n",
    "styled_df,cluster_results_df = wica.create_cluster_report(wallet_training_data_df, wallet_model_results, n_clusters, comparison_metrics, 'median')\n",
    "\n",
    "del(wallet_training_data_df)\n",
    "gc.collect()\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Period Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation and modeling datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve Validation Profits and Market Data\n",
    "# ----------------------------------------------------------\n",
    "# Retrieve full historical through validation period datasets\n",
    "\n",
    "# Retrieve training coin cohort to ensure all training period coins are reflected\n",
    "# TODO: assess whether this cohort filter should be removed\n",
    "training_coin_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_market_indicators_data_df.parquet\",\n",
    "                                       columns=['coin_id'])['coin_id'].unique()\n",
    "validation_profits_df_full, validation_market_data_df_full, validation_coin_cohort = wmo.retrieve_period_datasets(\n",
    "    wallets_config['training_data']['validation_period_start'],\n",
    "    wallets_config['training_data']['validation_period_end'],\n",
    "    training_coin_cohort\n",
    ")\n",
    "\n",
    "# Remove pre-validation period prices\n",
    "validation_market_data_df = validation_market_data_df_full[validation_market_data_df_full['date']\n",
    "                                                       >=wallets_config['training_data']['validation_starting_balance_date']]\n",
    "del validation_market_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Filter to only training wallet cohort\n",
    "training_wallet_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\", columns=[]).index.values\n",
    "validation_profits_df = validation_profits_df_full[validation_profits_df_full['wallet_address'].isin(training_wallet_cohort)]\n",
    "del validation_profits_df_full\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Assert period, save files, remove from memory\n",
    "u.assert_period(validation_market_data_df,\n",
    "                wallets_config['training_data']['validation_period_start'],\n",
    "                wallets_config['training_data']['validation_period_end'])\n",
    "u.assert_period(validation_profits_df,\n",
    "                wallets_config['training_data']['validation_period_start'],\n",
    "                wallets_config['training_data']['validation_period_end'])\n",
    "validation_profits_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_profits_df.parquet\",index=False)\n",
    "validation_market_data_df.to_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_market_data_df.parquet\",index=False)\n",
    "del validation_profits_df,validation_market_data_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-wallet coin model feature generation (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]  # Reload all modules\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')  # Reload all configs\n",
    "\n",
    "# Generate features based on the coin config files\n",
    "coin_features_training_data_df, _, _ = tw.generate_all_time_windows_model_inputs(config,metrics_config,modeling_config)\n",
    "\n",
    "# Remove time window index since we aren't using that for now\n",
    "coin_features_training_data_df = coin_features_training_data_df.reset_index(level='time_window', drop=True)\n",
    "\n",
    "# Save to parquet\n",
    "coin_features_training_data_df.to_parquet(\"temp/coin_modeling_dfs/coin_features_training_data_df.parquet\",index=True)\n",
    "\n",
    "u.notify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modeling dataset files (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load coin cohort (currently carried through training/modeling/validation periods)\n",
    "training_coin_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/training_market_indicators_data_df.parquet\",\n",
    "                                       columns=['coin_id'])['coin_id'].unique()\n",
    "\n",
    "\n",
    "# Load modeling period scores and data\n",
    "modeling_wallet_scores_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_wallet_scores_df.parquet\")\n",
    "modeling_market_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_market_data_df.parquet\")\n",
    "modeling_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/modeling_profits_df.parquet\")\n",
    "u.assert_period(modeling_market_data_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n",
    "u.assert_period(modeling_profits_df,\n",
    "                wallets_config['training_data']['modeling_period_start'],\n",
    "                wallets_config['training_data']['modeling_period_end'])\n",
    "\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation dataset files (loadable parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load parquet\n",
    "validation_profits_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_profits_df.parquet\")\n",
    "validation_market_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_market_data_df.parquet\")\n",
    "training_wallet_cohort = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\", columns=[]).index.values\n",
    "u.assert_period(validation_profits_df,\n",
    "                wallets_config['training_data']['validation_period_start'],\n",
    "                wallets_config['training_data']['validation_period_end'])\n",
    "u.assert_period(validation_market_data_df,\n",
    "                wallets_config['training_data']['validation_period_start'],\n",
    "                wallets_config['training_data']['validation_period_end'])\n",
    "\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Coin Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet aggregated analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate validation wallet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Create a DataFrame with all wallets that should exist\n",
    "validation_wallet_features_df = pd.DataFrame(index=training_wallet_cohort)\n",
    "validation_wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "\n",
    "# Calculate modeling period wallet metrics\n",
    "validation_trading_features_df = wtf.calculate_wallet_trading_features(validation_profits_df,\n",
    "                                                            wallets_config['training_data']['validation_period_start'],\n",
    "                                                            wallets_config['training_data']['validation_period_end'])\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(validation_trading_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in validation_trading_features_df.columns})\n",
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features_df = wpf.calculate_performance_features(validation_wallet_features_df)\n",
    "validation_wallet_features_df = validation_wallet_features_df.join(performance_features_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_wallet_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wallet validation period trading/performance by score quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create analysis by prediction bands\n",
    "metrics = [\n",
    "    'crypto_net_gain/max_investment/winsorized',\n",
    "    'crypto_net_gain/max_investment/base',\n",
    "    'crypto_net_gain/max_investment/ntile_rank',\n",
    "    'crypto_net_gain/active_twb/winsorized',\n",
    "    'crypto_net_gain/active_twb/base',\n",
    "    'max_investment',\n",
    "    'crypto_net_gain',\n",
    "    'net_crypto_investment',\n",
    "    'total_volume',\n",
    "]\n",
    "\n",
    "min_wallet_volume_usd = 0\n",
    "num_quantiles = 5\n",
    "\n",
    "wiva.create_quantile_report(\n",
    "    validation_wallet_features_df,\n",
    "    modeling_wallet_scores_df[wallets_config['modeling']['score_name']],\n",
    "    metrics,  # Your existing metrics list\n",
    "    num_quantiles,  # Split into ntiles\n",
    "    min_wallet_volume_usd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create analysis by prediction bands\n",
    "metrics = [\n",
    "    'crypto_net_gain/max_investment/winsorized',\n",
    "    'crypto_net_gain/max_investment/base',\n",
    "    'crypto_net_gain/max_investment/ntile_rank',\n",
    "    'crypto_net_gain/active_twb/winsorized',\n",
    "    'crypto_net_gain/active_twb/base',\n",
    "    'max_investment',\n",
    "    'crypto_net_gain',\n",
    "    'net_crypto_investment',\n",
    "    'total_volume',\n",
    "]\n",
    "\n",
    "min_wallet_volume_usd = 0\n",
    "num_quantiles = 5\n",
    "\n",
    "wiva.create_quantile_report(\n",
    "    validation_wallet_features_df,\n",
    "    modeling_wallet_scores_df[wallets_config['modeling']['score_name']],\n",
    "    metrics,  # Your existing metrics list\n",
    "    num_quantiles,  # Split into ntiles\n",
    "    min_wallet_volume_usd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Wallet metrics to analyze\n",
    "wallet_metrics = [\n",
    "    'top_100pct/balance_wtd_mean_score',\n",
    "    'top_10pct/count',\n",
    "    'top_25pct/count',\n",
    "    'top_50pct/count',\n",
    "    'top_100pct/count',\n",
    "    'top_10pct/count_pct',\n",
    "    'top_10pct/balance_pct',\n",
    "    'top_25pct/count_pct',\n",
    "    'top_25pct/balance_pct',\n",
    "    'top_50pct/count_pct',\n",
    "    'top_50pct/balance_pct',\n",
    "]\n",
    "# wallet_metrics = list(validation_coin_wallet_features_df.columns)\n",
    "\n",
    "# Create styled performance analysis\n",
    "civa.create_top_coins_wallet_metrics_report(validation_coin_wallet_features_df,percentile=90,wallet_metrics=wallet_metrics,method='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = civa.analyze_market_cap_segments(\n",
    "    coin_wallet_features_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "civa.plot_segment_heatmap(summary_df)\n",
    "civa.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_validation_analysis']['top_n']\n",
    "max_market_cap = wallets_config['coin_validation_analysis']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_validation_analysis']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = civa.validate_coin_performance(coin_wallet_features_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "civa.print_performance_analysis(coin_wallet_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coin Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare coin_training_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign wallets to segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Create base df with all wallet addresses and scores\n",
    "wallet_scores_df = cfo.load_wallet_scores(wallets_coin_config['wallet_segments']['wallet_scores'],\n",
    "                                            wallets_coin_config['wallet_segments']['wallet_scores_path'])\n",
    "wallet_segmentation_df = wallet_scores_df\n",
    "\n",
    "# Add \"all\" segment for full population level aggregations\n",
    "wallet_segmentation_df['all_wallets|all'] = 'all'\n",
    "wallet_segmentation_df['all_wallets|all'] = wallet_segmentation_df['all_wallets|all'].astype('category')\n",
    "\n",
    "\n",
    "# Add score quantile assignments\n",
    "wallet_segmentation_df = cws.assign_wallet_score_quantiles(\n",
    "    wallet_segmentation_df,\n",
    "    wallets_coin_config['wallet_segments']['wallet_scores'],\n",
    "    wallets_coin_config['wallet_segmentation']['score_segment_quantiles']\n",
    ")\n",
    "\n",
    "\n",
    "# Add training period-based cluster labels\n",
    "training_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/wallet_training_data_df.parquet\")\n",
    "wallet_clusters_df = cws.assign_cluster_labels(\n",
    "    training_data_df,\n",
    "    wallets_coin_config['wallet_segmentation']['training_period_cluster_groups']\n",
    ")\n",
    "del(training_data_df)\n",
    "gc.collect\n",
    "\n",
    "\n",
    "# Join together\n",
    "wallet_segmentation_df = wallet_segmentation_df.join(wallet_clusters_df,how='inner')\n",
    "wallet_segmentation_df.columns\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate metrics for coin-wallet pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Create base df with all coin-wallet pairs\n",
    "cw_metrics_df = pd.DataFrame(\n",
    "    index=modeling_profits_df[['coin_id', 'wallet_address']]\n",
    "    .drop_duplicates()\n",
    "    .set_index(['coin_id', 'wallet_address'])\n",
    "    .index\n",
    ")\n",
    "\n",
    "# Generate balance metric\n",
    "cw_balances_df = cwbm.calculate_coin_wallet_balances(modeling_profits_df,\n",
    "                                                     wallets_config['training_data']['modeling_period_end'])\n",
    "cw_balances_df = cw_balances_df.add_prefix('balances/')\n",
    "cw_metrics_df = cw_metrics_df.join(cw_balances_df,how='left')\\\n",
    "        .fillna({col: 0 for col in cw_balances_df.columns})\n",
    "\n",
    "\n",
    "# Generate trading metrics\n",
    "cw_trading_features_df = cwbm.calculate_coin_wallet_trading_metrics(modeling_profits_df,\n",
    "                                                                    wallets_config['training_data']['modeling_period_start'],\n",
    "                                                                    wallets_config['training_data']['modeling_period_end'],\n",
    "                                                                    wallets_coin_config['wallet_features']['drop_trading_metrics'])\n",
    "cw_trading_features_df = cw_trading_features_df.add_prefix('trading/')\n",
    "cw_metrics_df = cw_metrics_df.join(cw_trading_features_df,how='left')\\\n",
    "        .fillna({col: 0 for col in cw_trading_features_df.columns})\n",
    "\n",
    "cw_metrics_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatten cw_metrics into single values for each coin-segment pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Define complete coin list and initialize df with\n",
    "coin_wallet_features_df = pd.DataFrame(index=training_coin_cohort)\n",
    "coin_wallet_features_df.index.name = 'coin_id'\n",
    "\n",
    "\n",
    "# Loop through all metrics and segmentations to generate features\n",
    "segmentation_families = wallet_segmentation_df.columns[~wallet_segmentation_df.columns.str.startswith('scores|')]\n",
    "metric_columns = cw_metrics_df.columns\n",
    "\n",
    "# Calculate all features for each metric column\n",
    "i = 0\n",
    "logger.info(\"Calculating segment features for each metric column...\")\n",
    "for metric_column in metric_columns:\n",
    "\n",
    "    # Calculate metric column features for each segment family\n",
    "    for segment_family in segmentation_families:\n",
    "\n",
    "        # Generate coin-level features based on modeling period end wallet scores and balances\n",
    "        coin_segment_family_features_df = cfo.flatten_cw_to_coin_features(\n",
    "            cw_metrics_df,\n",
    "            metric_column,\n",
    "            wallet_segmentation_df,\n",
    "            segment_family,\n",
    "            training_coin_cohort\n",
    "        )\n",
    "        coin_wallet_features_df = coin_wallet_features_df.join(coin_segment_family_features_df, how='inner')\n",
    "\n",
    "    i+=1\n",
    "    logger.info(\"Completed metric %s/%s: %s...\",\n",
    "                i, len(metric_columns), metric_column)\n",
    "\n",
    "logger.info(\"Calculated all metric-segment-aggregation features. Final output shape: %s\",\n",
    "            coin_wallet_features_df.shape )\n",
    "\n",
    "del cw_metrics_df,cw_trading_features_df,cw_balances_df,wallet_scores_df,wallet_segmentation_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge to coin_training_data_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from coin features pipeline\n",
    "coin_features_training_data_df = pd.read_parquet(\"temp/coin_modeling_dfs/coin_features_training_data_df.parquet\")\n",
    "\n",
    "# Confirm overlap\n",
    "coin_features_ids = coin_features_training_data_df.index\n",
    "coin_wallet_features_ids = coin_wallet_features_df.index\n",
    "wallet_features_only_ids = set(coin_wallet_features_ids) - set(coin_features_ids)\n",
    "\n",
    "if len(wallet_features_only_ids) == 0:\n",
    "    logger.info(\"All %s coins with wallet features were found in the base features set.\",\n",
    "                len(coin_wallet_features_ids))\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Wallet features contain {len(wallet_features_only_ids)} coins not in the other coin features\")\n",
    "\n",
    "\n",
    "# Join together\n",
    "coin_training_data_df_full = coin_wallet_features_df.join(coin_features_training_data_df,how='inner')\n",
    "logger.info(\"Final features shape: %s\",coin_training_data_df_full.shape)\n",
    "\n",
    "# Save to parquet and delete\n",
    "coin_training_data_df_full.to_parquet(\"temp/coin_modeling_dfs/coin_training_data_df_full.parquet\",index=True)\n",
    "del coin_training_data_df_full,coin_wallet_features_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare coin_modeling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply coin filters (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load parquet\n",
    "coin_training_data_df_full = pd.read_parquet(\"temp/coin_modeling_dfs/coin_training_data_df_full.parquet\")\n",
    "logger.info(\"Starting coins: %s\", len(coin_training_data_df_full))\n",
    "\n",
    "# Filter based on holdings\n",
    "min_cohort_wallets = wallets_coin_config['coin_modeling']['min_cohort_wallets']\n",
    "min_cohort_balance = wallets_coin_config['coin_modeling']['min_cohort_balance']\n",
    "\n",
    "coin_training_data_df = coin_training_data_df_full[\n",
    "    (coin_training_data_df_full['all_wallets|all/all|balances/usd_balance_241120|aggregations/count'] >= min_cohort_wallets)\n",
    "    & (coin_training_data_df_full['all_wallets|all/all|balances/usd_balance_241120|aggregations/sum'] >= min_cohort_balance)\n",
    "]\n",
    "\n",
    "logger.info(\"Coins after balance filters: %s\", len(coin_training_data_df))\n",
    "del coin_training_data_df_full\n",
    "gc.collect()\n",
    "\n",
    "# # Filter based on market cap\n",
    "# min_market_cap = wallets_coin_config['coin_modeling']['min_market_cap']\n",
    "# max_market_cap = wallets_coin_config['coin_modeling']['max_market_cap']\n",
    "\n",
    "# coin_training_data_df = coin_training_data_df[\n",
    "#     (coin_training_data_df['time_series|market_data|market_cap_last'] >= min_market_cap)\n",
    "#     & (coin_training_data_df['time_series|market_data|market_cap_last'] <= max_market_cap)\n",
    "# ]\n",
    "# logger.info(\"Coins after market cap filters: %s\", len(coin_training_data_df))\n",
    "\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply feature selection to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Remove low variance features\n",
    "coin_training_data_df = fs.remove_low_variance_features(coin_training_data_df,\n",
    "                wallets_coin_config['coin_'features']['feature_selection'['variance_threshold'])\n",
    "\n",
    "# Remove correlated features\n",
    "coin_training_data_df = fs.remove_correlated_features(coin_training_data_df,\n",
    "                wallets_coin_config['coin_'features']['feature_selection'['correlation_threshold'])\n",
    "\n",
    "logger.info(\"Final training data df shape: %s\", coin_training_data_df.shape)\n",
    "\n",
    "\n",
    "# Save to parquet and delete\n",
    "coin_training_data_df.to_parquet(\"temp/coin_modeling_dfs/coin_training_data_df.parquet\",index=True)\n",
    "del coin_training_data_df\n",
    "gc.collect()\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare target variable (parquet loadable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# Load market data\n",
    "validation_market_data_df = pd.read_parquet(f\"{wallets_config['training_data']['parquet_folder']}/validation_market_data_df.parquet\")\n",
    "coin_training_data_df = pd.read_parquet(\"temp/coin_modeling_dfs/coin_training_data_df.parquet\")\n",
    "\n",
    "\n",
    "# Target variable claculations\n",
    "# ----------------------------\n",
    "# Calculate coin return performance during validation period\n",
    "validation_coin_performance_df = civa.calculate_coin_performance(\n",
    "    validation_market_data_df,\n",
    "    wallets_config['training_data']['validation_period_start'],\n",
    "    wallets_config['training_data']['validation_period_end']\n",
    ")\n",
    "\n",
    "# Drop columns with np.nan coin_return values, which indicate a 0 starting price\n",
    "validation_coin_performance_df = validation_coin_performance_df.dropna()\n",
    "\n",
    "# Add winsorized return\n",
    "validation_coin_performance_df['coin_return_winsorized'] = u.winsorize(\n",
    "        validation_coin_performance_df['coin_return'],\n",
    "        wallets_coin_config['coin_modeling']['returns_winsorization'])\n",
    "\n",
    "\n",
    "# Add full percentile (meaning it's a percentile of all coins prior to any population filtering)\n",
    "validation_coin_performance_df['coin_return_pctile_full'] = validation_coin_performance_df['coin_return'].rank(pct=True,ascending=True)\n",
    "\n",
    "\n",
    "# Validation: check if any coin_ids missing from final features\n",
    "missing_coins = set(coin_training_data_df.index) - set(validation_coin_performance_df.index)\n",
    "if missing_coins:\n",
    "    raise ValueError(f\"Found {len(missing_coins)} coin_ids in training_data_df without validation period target variables.\")\n",
    "\n",
    "\n",
    "# Target variable attachment\n",
    "# --------------------------\n",
    "# Identify target variable column\n",
    "target_var_column = wallets_coin_config['coin_modeling']['target_variable']\n",
    "\n",
    "# Calculate the percentile among the coin_training_data_df coins\n",
    "if target_var_column == 'coin_return_pctile':\n",
    "    coin_modeling_df = coin_training_data_df.join(validation_coin_performance_df[['coin_return']])\n",
    "    coin_modeling_df['coin_return_pctile'] = coin_modeling_df['coin_return'].rank(pct=True,ascending=True)\n",
    "    coin_modeling_df = coin_modeling_df.drop('coin_return',axis=1)\n",
    "else:\n",
    "    coin_modeling_df = coin_training_data_df.join(validation_coin_performance_df[[target_var_column]])\n",
    "del coin_training_data_df,validation_coin_performance_df\n",
    "gc.collect\n",
    "\n",
    "\n",
    "# Convert the index to string to avoid serialization/export categorical series issues\n",
    "coin_modeling_df.index = coin_modeling_df.index.astype(str)\n",
    "\n",
    "\n",
    "u.obj_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build coin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Initialize and run model\n",
    "coin_model = cm.CoinModel(modeling_config=wallets_coin_config['coin_modeling'])\n",
    "coin_model_results = coin_model.construct_coin_model(feature_df=coin_modeling_df)\n",
    "del coin_modeling_df\n",
    "gc.collect()\n",
    "\n",
    "# Extract the trained model\n",
    "coin_model = coin_model_results['pipeline'].named_steps['regressor']\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "coin_model_id, coin_evaluator, coin_scores_df = cmr.generate_and_save_coin_model_artifacts(\n",
    "    model_results=coin_model_results,\n",
    "    base_path='../artifacts/coin_modeling',\n",
    "    configs = {\n",
    "        'wallets_coin_config': wallets_coin_config,\n",
    "        'wallets_config': wallets_config.config\n",
    "    }\n",
    ")\n",
    "\n",
    "# save score\n",
    "coin_scores_df.to_parquet(\"temp/coin_modeling_dfs/coin_scores_df.parquet\",index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "coin_evaluator = wime.RegressionEvaluator(\n",
    "    y_test=coin_model_results['y_test'],\n",
    "    y_pred=coin_model_results['y_pred'],\n",
    "    model=coin_model,\n",
    "    feature_names=coin_model_results['X_train'].columns.tolist()\n",
    ")\n",
    "\n",
    "# Generate reports\n",
    "print(coin_evaluator.summary_report())\n",
    "coin_evaluator.plot_coin_evaluation()\n",
    "display(coin_evaluator.importance_summary(levels=1))\n",
    "\n",
    "u.notify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "coin_evaluator = wime.RegressionEvaluator(\n",
    "    y_test=coin_model_results['y_test'],\n",
    "    y_pred=coin_model_results['y_pred'],\n",
    "    model=coin_model,\n",
    "    feature_names=coin_model_results['X_train'].columns.tolist()\n",
    ")\n",
    "\n",
    "# Generate reports\n",
    "print(coin_evaluator.summary_report())\n",
    "coin_evaluator.plot_coin_evaluation()\n",
    "display(coin_evaluator.importance_summary(levels=1))\n",
    "\n",
    "u.notify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "coin_evaluator = wime.RegressionEvaluator(\n",
    "    y_test=coin_model_results['y_test'],\n",
    "    y_pred=coin_model_results['y_pred'],\n",
    "    model=coin_model,\n",
    "    feature_names=coin_model_results['X_train'].columns.tolist()\n",
    ")\n",
    "\n",
    "# Generate reports\n",
    "print(coin_evaluator.summary_report())\n",
    "coin_evaluator.plot_coin_evaluation()\n",
    "display(coin_evaluator.importance_summary(levels=1))\n",
    "\n",
    "u.notify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load importances\n",
    "feature_importance_df = pd.DataFrame(coin_evaluator.metrics['importances'])\n",
    "\n",
    "# Split on pipe delimiters\n",
    "split_df = feature_importance_df['feature'].str.split('|', expand=True)\n",
    "split_df.columns = ['segment_category','segment_family','metric','transformation']\n",
    "\n",
    "# Split nested components\n",
    "segment_families = split_df['segment_family'].str.split('/', expand=True)\n",
    "segment_families.columns = ['segment_family', 'segment_value']\n",
    "\n",
    "metrics = split_df['metric'].str.split('/', expand=True)\n",
    "metrics.columns = ['metric', 'metric_detail']\n",
    "\n",
    "transformations = split_df['transformation'].str.split('/', expand=True)\n",
    "transformations.columns = ['transformation', 'transformation_method']\n",
    "\n",
    "# Combine all components\n",
    "feature_details_df = pd.concat([\n",
    "    split_df['segment_category'],\n",
    "    segment_families,\n",
    "    metrics,\n",
    "    transformations,\n",
    "    feature_importance_df['importance']\n",
    "], axis=1)\n",
    "\n",
    "feature_details_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    'segment_category',\n",
    "    'segment_family',\n",
    "    # 'segment_value',\n",
    "    # 'metric',\n",
    "    # 'metric_detail',\n",
    "    # 'transformation',\n",
    "    # 'transformation_method',\n",
    "]\n",
    "\n",
    "feature_details_df.groupby(groups).sum('importance').sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    'segment_category',\n",
    "    # 'segment_family',\n",
    "    'segment_value',\n",
    "    # 'metric',\n",
    "    # 'metric_detail',\n",
    "    # 'transformation',\n",
    "    # 'transformation_method',\n",
    "]\n",
    "\n",
    "feature_details_df.groupby(groups).sum('importance').sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    # 'segment_category',\n",
    "    # 'segment_family',\n",
    "    # 'segment_value',\n",
    "    'metric',\n",
    "    'metric_detail',\n",
    "    # 'transformation',\n",
    "    # 'transformation_method',\n",
    "]\n",
    "\n",
    "feature_details_df.groupby(groups).sum('importance').sort_values(by='importance',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    # 'segment_category',\n",
    "    # 'segment_family',\n",
    "    # 'segment_value',\n",
    "    # 'metric',\n",
    "    # 'metric_detail',\n",
    "    'transformation',\n",
    "    'transformation_method',\n",
    "]\n",
    "\n",
    "feature_details_df.groupby(groups).sum('importance').sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = split_df.copy()\n",
    "result_df = split_df.copy()\n",
    "\n",
    "# Process columns that need splitting\n",
    "for col in ['segment_parent', 'metric', 'transformation']:\n",
    "    # Split on '/' and create incrementing level columns\n",
    "    split_cols = df[col].str.split('/', expand=True)\n",
    "\n",
    "    # First component stays in original column\n",
    "    result_df[col] = split_cols[0]\n",
    "\n",
    "    # Additional components get level numbers\n",
    "    for i in range(1, len(split_cols.columns)):\n",
    "        result_df[f'{col}_l{i}'] = split_cols[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named `df`\n",
    "# Calculate correlations\n",
    "correlation_matrix = coin_modeling_df.corr()\n",
    "\n",
    "# Extract correlations with the target variable\n",
    "target_correlations = correlation_matrix[target_var_column].sort_values(ascending=False)\n",
    "\n",
    "# Display the top features correlated with the target\n",
    "target_correlations[:15]\n",
    "# target_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "\n",
    "# # Wallet metrics to analyze\n",
    "# wallet_metrics = [\n",
    "# ]\n",
    "\n",
    "wallet_metrics = coin_modeling_df.columns\n",
    "wallet_metrics = target_correlations[:15].index.values\n",
    "\n",
    "# number of score buckets\n",
    "n_quantiles = 5\n",
    "\n",
    "analyze_df = civa.analyze_metric_segments(\n",
    "    coin_modeling_df,\n",
    "    wallet_metrics,\n",
    "    n_quantiles,\n",
    "    target_var_column,\n",
    ")\n",
    "civa.style_metric_segments(analyze_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_coin_config = yaml.safe_load(Path('../config/wallets_coin_config.yaml').read_text(encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
