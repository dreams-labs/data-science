{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# import local files if necessary\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "import utils as u\n",
    "importlib.reload(u)\n",
    "\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "\n",
    "# Load all configs as global variables\n",
    "global CONFIG, METRICS_CONFIG, MODELING_CONFIG, EXPERIMENTS_CONFIG, MODELING_FOLDER\n",
    "\n",
    "CONFIG = u.load_config('../config/config.yaml')\n",
    "METRICS_CONFIG = u.load_config('../config/metrics_config.yaml')\n",
    "MODELING_CONFIG = u.load_config('../config/modeling_config.yaml')\n",
    "EXPERIMENTS_CONFIG = u.load_config('../config/experiments_config.yaml')\n",
    "MODELING_FOLDER = MODELING_CONFIG['modeling']['modeling_folder']\n",
    "modeling_folder = MODELING_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "start_date = config['training_data']['training_period_start']\n",
    "end_date = config['training_data']['modeling_period_end']\n",
    "\n",
    "# Retrieve market data\n",
    "market_data_df = td.retrieve_market_data()\n",
    "market_data_df, _ = cwm.split_dataframe_by_coverage(market_data_df, start_date, end_date, id_column='coin_id')\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "# retrieve profits data\n",
    "profits_df = td.retrieve_profits_data(start_date, end_date)\n",
    "profits_df, _ = cwm.split_dataframe_by_coverage(profits_df, start_date, end_date, id_column='coin_id')\n",
    "profits_df, _ = td.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n",
    "# remove records from market_data_df that don't have transfers if configured to do so\n",
    "if config['data_cleaning']['exclude_coins_without_transfers']:\n",
    "    market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_to_impute = [\n",
    "    config['training_data']['training_period_end'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end'],\n",
    "]\n",
    "profits_df = td.impute_profits_for_multiple_dates(profits_df, prices_df, dates_to_impute, n_threads=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# 3.3 Build the configured model input data (train/test data)\n",
    "X_train, X_test, y_train, y_test = i.build_configured_model_input(profits_df, market_data_df, config, metrics_config, modeling_config)\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "model, model_id = m.train_model(X_train, y_train, modeling_folder, modeling_config['modeling']['model_params'])\n",
    "\n",
    "# 3.5 Evaluate and save the model's performance on the test set to a CSV\n",
    "evals = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_config['time_series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_profits_df = profits_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "target_date = config['training_data']['training_period_end']\n",
    "new_rows_df = td.impute_profits_df_rows(profits_df, prices_df, target_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = full_profits_df.copy(deep=True)\n",
    "profits_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "dates_to_impute = [\n",
    "    config['training_data']['training_period_end'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end'],\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def impute_profits_for_multiple_dates(profits_df, prices_df, dates, n_threads):\n",
    "    \"\"\"\n",
    "    Wrapper function to impute profits for multiple dates using multithreaded processing.\n",
    "\n",
    "    Args:\n",
    "        profits_df (pd.DataFrame): DataFrame containing dated profits data for coin-wallet pairs\n",
    "        prices_df (pd.DataFrame): DataFrame containing price information\n",
    "        dates (list): List of dates (str or datetime) for which to impute rows\n",
    "        n_threads (int): The number of threads to use for imputation\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated profits_df with imputed rows for all specified dates\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    start_time = time.time()\n",
    "    logger.info(\"Starting profits_df imputation for %s dates...\", len(dates))\n",
    "\n",
    "    new_rows_list = []\n",
    "\n",
    "    for date in dates:\n",
    "        new_rows_df = td.multithreaded_impute_profits_rows(profits_df, prices_df, date, n_threads)\n",
    "        new_rows_list.append(new_rows_df)\n",
    "\n",
    "    # Concatenate all new rows at once\n",
    "    all_new_rows = pd.concat(new_rows_list, ignore_index=True)\n",
    "\n",
    "    # Append all new rows to profits_df\n",
    "    updated_profits_df = pd.concat([profits_df, all_new_rows], ignore_index=True)\n",
    "\n",
    "    logger.info(\"Completed new row generation after %.2f seconds. Total rows after imputation: %s\",\n",
    "                time.time() - start_time,\n",
    "                updated_profits_df.shape[0])\n",
    "\n",
    "    return updated_profits_df\n",
    "\n",
    "update_profits_df = impute_profits_for_multiple_dates(profits_df, prices_df, dates_to_impute, n_threads=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "optimal_thread_count = multiprocessing.cpu_count()\n",
    "optimal_thread_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create efficient columns\n",
    "profits_df['coin_id'] = profits_df['coin_id'].astype('category')\n",
    "coin_id_mapping = dict(enumerate(profits_df['coin_id'].cat.categories))\n",
    "profits_df['coin_id'] = profits_df['coin_id'].cat.codes.astype('int16')\n",
    "\n",
    "# Convert date column to store the difference in days relative to target_date\n",
    "profits_df['date'] = (profits_df['date'] - target_date).dt.days.astype('int16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vars\n",
    "# target_date = '2024-08-31'\n",
    "# # new_rows_df = generate_new_row(profits_df, prices_df, target_date)\n",
    "\n",
    "# target_date = pd.to_datetime(target_date)\n",
    "\n",
    "# # # Create efficient indexes\n",
    "# # profits_df = profits_df.set_index(['coin_id', 'wallet_address', 'date']).copy(deep=True)\n",
    "# # prices_df = prices_df.set_index(['coin_id', 'date']).copy(deep=True)\n",
    "\n",
    "# # # Identify pairs needing new rows\n",
    "# # logger.debug('Identifying pairs that need a row for %s...', target_date)\n",
    "# # all_pairs = profits_df.index.droplevel('date').unique()\n",
    "# # existing_pairs = profits_df.loc(axis=0)[:, :, target_date].index.droplevel('date')\n",
    "# # pairs_needing_rows = all_pairs.difference(existing_pairs)\n",
    "# # logger.debug('Identified %s pairs that will need rows imputed.', len(pairs_needing_rows))\n",
    "\n",
    "\n",
    "# new_rows = []\n",
    "\n",
    "# logger.debug('Imputing new rows...')\n",
    "# for coin_id, wallet_address in pairs_needing_rows:\n",
    "#     # Get most recent record\n",
    "#     recent_record = profits_df.loc[coin_id, wallet_address].loc[:target_date].iloc[-1]\n",
    "\n",
    "#     # Get prices\n",
    "#     price_previous = prices_df.loc[(coin_id, recent_record.name), 'price']\n",
    "#     price_current = prices_df.loc[(coin_id, target_date), 'price']\n",
    "\n",
    "#     # Calculate new values\n",
    "#     price_ratio = price_current / price_previous\n",
    "#     new_usd_balance = recent_record['usd_balance'] * price_ratio\n",
    "#     profits_change = new_usd_balance - recent_record['usd_balance']\n",
    "#     profits_cumulative = recent_record['profits_cumulative'] + profits_change\n",
    "\n",
    "#     new_row = {\n",
    "#         'coin_id': coin_id,\n",
    "#         'wallet_address': wallet_address,\n",
    "#         'date': target_date,\n",
    "#         'profits_change': profits_change,\n",
    "#         'profits_cumulative': profits_cumulative,\n",
    "#         'usd_balance': new_usd_balance,\n",
    "#         'usd_net_transfers': 0,\n",
    "#         'usd_inflows': 0,\n",
    "#         'usd_inflows_cumulative': recent_record['usd_inflows_cumulative'],\n",
    "#         'total_return': profits_cumulative / max(recent_record['usd_inflows_cumulative'], 0.01)\n",
    "#     }\n",
    "\n",
    "#     new_rows.append(new_row)\n",
    "\n",
    "# new_rows_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# logger.debug('Generated new_rows_df with shape %s.', new_rows_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most recent data for pairs needing rows\n",
    "most_recent_data = profits_df.loc[pairs_needing_rows]\n",
    "most_recent_data = most_recent_data.groupby(level=['coin_id', 'wallet_address']).last().reset_index()\n",
    "\n",
    "# Ensure the date column is properly formatted\n",
    "most_recent_data['date'] = pd.to_datetime(most_recent_data['date'])\n",
    "\n",
    "# Reset index of prices_df for the merge operation\n",
    "prices_df_reset = prices_df.reset_index()\n",
    "\n",
    "# Perform asof merge to get the most recent price before or on the date of each record\n",
    "merged_data = pd.merge_asof(most_recent_data.sort_values('date'),\n",
    "                            prices_df_reset.sort_values('date'),\n",
    "                            on='date',\n",
    "                            by='coin_id',\n",
    "                            direction='backward')\n",
    "\n",
    "# Now get the price at the target date\n",
    "target_prices = prices_df.loc(axis=0)[:, target_date].reset_index()\n",
    "target_prices = target_prices.rename(columns={'price': 'target_price'})\n",
    "\n",
    "# Merge the target prices\n",
    "merged_data = pd.merge(merged_data, target_prices[['coin_id', 'target_price']], on='coin_id', how='left')\n",
    "\n",
    "# Calculate price ratio\n",
    "merged_data['price_ratio'] = merged_data['target_price'] / merged_data['price']\n",
    "\n",
    "logger.debug('Merged data shape: %s', merged_data.shape)\n",
    "logger.debug('Merged data columns: %s', merged_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most recent row for each pair needing a new row\n",
    "most_recent_data = profits_df.loc[profits_df.index.isin(pairs_needing_rows, level=['coin_id', 'wallet_address'])]\n",
    "# most_recent_data = most_recent_data.groupby(level=['coin_id', 'wallet_address']).last().reset_index()\n",
    "\n",
    "# # Ensure the date column is properly formatted\n",
    "# most_recent_data['date'] = pd.to_datetime(most_recent_data['date'])\n",
    "# prices_df['date'] = pd.to_datetime(prices_df['date'])\n",
    "\n",
    "# # Perform asof merge to get the most recent price before or on the date of each record\n",
    "# merged_data = pd.merge_asof(most_recent_data.sort_values('date'),\n",
    "#                             prices_df[['date', 'coin_id', 'price']].sort_values('date'),\n",
    "#                             on='date',\n",
    "#                             by='coin_id',\n",
    "#                             direction='backward')\n",
    "\n",
    "# # Now get the price at the target date\n",
    "# target_prices = prices_df[prices_df['date'] == target_date][['coin_id', 'price']]\n",
    "# target_prices = target_prices.rename(columns={'price': 'target_price'})\n",
    "\n",
    "# # Merge the target prices\n",
    "# merged_data = pd.merge(merged_data, target_prices, on='coin_id', how='left')\n",
    "\n",
    "# # Calculate price ratio\n",
    "# merged_data['price_ratio'] = merged_data['target_price'] / merged_data['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
