{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# import local files if necessary\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "\n",
    "config = load_config('config.yaml')\n",
    "metrics_config = load_config('metrics_config.yaml')\n",
    "\n",
    "# retrieve and clean prices data\n",
    "prices_df = td.retrieve_prices_data()\n",
    "prices_df,_ = td.fill_prices_gaps(prices_df,config['data_cleaning']['max_gap_days'])\n",
    "logger.info(f\"Prices data shape: {prices_df.shape}\")\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n",
    "# identify sharks\n",
    "shark_coins_df = td.classify_shark_coins(profits_df, config['training_data'])\n",
    "shark_wallets_df = td.classify_shark_wallets(shark_coins_df,config['training_data'])\n",
    "\n",
    "# generate and flatten buysell_metrics\n",
    "cohort_wallets = shark_wallets_df[shark_wallets_df['is_shark']==True]['wallet_address'].unique()\n",
    "cohort_coins = shark_coins_df['coin_id'].unique()\n",
    "buysell_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets,cohort_coins)\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(buysell_metrics_df,metrics_config,config['training_data']['training_period_end'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "\n",
    "\n",
    "# generate and flatten buysell_metrics\n",
    "cohort_wallets = shark_wallets_df[shark_wallets_df['is_shark']==True]['wallet_address'].unique()\n",
    "cohort_coins = shark_coins_df['coin_id'].unique()\n",
    "buysell_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets,cohort_coins)\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(buysell_metrics_df,metrics_config,config['training_data']['training_period_end'])\n",
    "\n",
    "buysell_metrics_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buysell_metrics_df_test = pd.read_csv('../tests/fixtures/buysell_metrics_df.csv')\n",
    "buysell_metrics_df_test['date'] = pd.to_datetime(buysell_metrics_df_test['date']).astype('datetime64[ns]')\n",
    "\n",
    "buysell_metrics_df_test.head()\n",
    "\n",
    "buysell_metrics_df = buysell_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_activity_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buysell_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_buysell_metrics_df['total_bought_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Introduce an outlier in the buysell_metrics_df for total_bought\n",
    "outlier_df = buysell_metrics_df.copy()\n",
    "outlier_df.loc[0, 'total_bought'] = 1e12  # Extreme value\n",
    "\n",
    "# Flatten the modified DataFrame\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(outlier_df, metrics_config, config['training_data']['training_period_end'])\n",
    "\n",
    "# Ensure the extreme value is handled and aggregated correctly\n",
    "assert flattened_buysell_metrics_df['total_bought_sum'].max() >= 1e12, \"Outlier in total_bought not handled correctly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store missing dates\n",
    "missing_dates_dict = {}\n",
    "\n",
    "# Iterate over unique coin_ids\n",
    "for coin_id in df['coin_id'].unique():\n",
    "    # Filter data for the current coin_id\n",
    "    coin_df = df[df['coin_id'] == coin_id]\n",
    "    \n",
    "    # Create the full date range for the coin, explicitly cast to datetime\n",
    "    full_date_range = pd.to_datetime(pd.date_range(start=coin_df['date'].min(), end=training_period_end))\n",
    "    \n",
    "    # Get the existing dates for the coin, explicitly cast to datetime\n",
    "    existing_dates = set(pd.to_datetime(coin_df['date'].unique()))\n",
    "    \n",
    "    # Find the missing dates by subtracting existing from full date range\n",
    "    missing_dates = set(full_date_range) - existing_dates\n",
    "    \n",
    "    # Store the missing dates for the current coin_id\n",
    "    missing_dates_dict[coin_id] = sorted(missing_dates)\n",
    "\n",
    "# Convert to DataFrame for easier display\n",
    "missing_dates_df = pd.DataFrame(list(missing_dates_dict.items()), columns=['coin_id', 'missing_dates'])\n",
    "missing_dates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_period_end = '2024-04-30'\n",
    "\n",
    "df = buysell_metrics_df\n",
    "missing_dates = df.groupby('coin_id')['date'].apply(\n",
    "    lambda x: pd.date_range(start=x.min(), end=training_period_end).difference(x.unique())\n",
    ")\n",
    "# missing_dates_df = missing_dates.reset_index(level=0)\n",
    "pd.DataFrame(missing_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store missing dates\n",
    "missing_dates_dict = {}\n",
    "\n",
    "# Iterate over unique coin_ids\n",
    "for coin_id in df['coin_id'].unique():\n",
    "    # Filter data for the current coin_id\n",
    "    coin_df = df[df['coin_id'] == coin_id]\n",
    "    \n",
    "    # Create the full date range for the coin, explicitly cast to pd.Timestamp\n",
    "    full_date_range = pd.to_datetime(pd.date_range(start=coin_df['date'].min(), end=training_period_end)).to_pydatetime()\n",
    "\n",
    "    # Get the existing dates for the coin, explicitly cast to pd.Timestamp\n",
    "    existing_dates = set(pd.to_datetime(coin_df['date'].unique()).to_pydatetime())\n",
    "    \n",
    "    # Find the missing dates by subtracting existing from full date range\n",
    "    missing_dates = set(full_date_range) - existing_dates\n",
    "    \n",
    "    # Store the missing dates for the current coin_id\n",
    "    missing_dates_dict[coin_id] = sorted(missing_dates)\n",
    "\n",
    "# Convert to DataFrame for easier display\n",
    "missing_dates_df = pd.DataFrame(list(missing_dates_dict.items()), columns=['coin_id', 'missing_dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store missing dates\n",
    "missing_dates_dict = {}\n",
    "\n",
    "# Iterate over unique coin_ids\n",
    "for coin_id in df['coin_id'].unique():\n",
    "    # Filter data for the current coin_id\n",
    "    coin_df = df[df['coin_id'] == coin_id]\n",
    "    \n",
    "    # Create the full date range for the coin\n",
    "    full_date_range = pd.date_range(start=coin_df['date'].min(), end=training_period_end)\n",
    "    \n",
    "    # Get the existing dates for the coin\n",
    "    existing_dates = set(coin_df['date'].unique())\n",
    "    \n",
    "    # Find the missing dates by subtracting existing from full date range\n",
    "    missing_dates = set(full_date_range) - existing_dates\n",
    "    \n",
    "    # Store the missing dates for the current coin_id\n",
    "    missing_dates_dict[coin_id] = sorted(missing_dates)\n",
    "\n",
    "# Convert to DataFrame for easier display\n",
    "missing_dates_df = pd.DataFrame(list(missing_dates_dict.items()), columns=['coin_id', 'missing_dates'])\n",
    "missing_dates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('coin_id')['date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(buysell_metrics_df, metrics_config, config['training_data']['training_period_end'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the buysell metrics DataFrame\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(buysell_metrics_df, metrics_config, config['training_data']['training_period_end'])\n",
    "\n",
    "# Example: Verify that total_bought is aggregated as a sum\n",
    "# Group original by coin_id and date for manual verification\n",
    "expected_total_bought = buysell_metrics_df.groupby(['coin_id', 'date'])['total_bought'].sum().reset_index()\n",
    "\n",
    "# Compare to the flattened result\n",
    "result_total_bought = flattened_buysell_metrics_df[['coin_id', 'date', 'total_bought']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['training_data']['training_period_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
