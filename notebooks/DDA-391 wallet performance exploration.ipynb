{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import pdb\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "from pyxirr import xirr\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "\n",
    "\n",
    "# 1. Data Retrieval, Cleaning, Indicator Calculation\n",
    "# --------------------------------------------------\n",
    "# Market data: retrieve and clean full history\n",
    "market_data_df = dr.retrieve_market_data()\n",
    "market_data_df = dr.clean_market_data(market_data_df, config)\n",
    "\n",
    "# Profits: retrieve and clean profits data spanning the earliest to latest training periods\n",
    "profits_df = dr.retrieve_profits_data(config['training_data']['training_period_start'],\n",
    "                                    config['training_data']['modeling_period_end'],\n",
    "                                    config['data_cleaning']['minimum_wallet_inflows'])\n",
    "profits_df, _ = dr.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n",
    "profits_df.head()\n",
    "\n",
    "\n",
    "# 2. Filtering based on dataset overlap\n",
    "# -------------------------------------\n",
    "# Filter market_data to only coins with transfers data if configured to\n",
    "if config['data_cleaning']['exclude_coins_without_transfers']:\n",
    "    market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n",
    "# Create prices_df: lightweight reference for other functions\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "# Filter profits_df to remove records for any coins that were removed in data cleaning\n",
    "profits_df = profits_df[profits_df['coin_id'].isin(market_data_df['coin_id'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Impute all required dates\n",
    "# ----------------------------\n",
    "# Identify all required imputation dates\n",
    "imputation_dates = [\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['training_period_end'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "]\n",
    "\n",
    "# Impute all required dates\n",
    "window_profits_df = pri.impute_profits_for_multiple_dates(profits_df, prices_df, imputation_dates, n_threads=24)\n",
    "window_profits_df = (window_profits_df[(window_profits_df['date'] >= pd.to_datetime(min(imputation_dates))) &\n",
    "                                    (window_profits_df['date'] <= pd.to_datetime(max(imputation_dates)))])\n",
    "\n",
    "window_profits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert period start and end balances to transfers for cash flows calculations\n",
    "def adjust_end_transfers(df, target_date):\n",
    "    df.loc[df['date'] == target_date, 'usd_net_transfers'] -= df.loc[df['date'] == target_date, 'usd_balance']\n",
    "    df.loc[df['date'] == target_date, 'usd_balance'] = 0\n",
    "    return df\n",
    "\n",
    "def adjust_start_transfers(df, target_date):\n",
    "    df.loc[df['date'] == target_date, 'usd_net_transfers'] = df.loc[df['date'] == target_date, 'usd_balance']\n",
    "    return df\n",
    "\n",
    "adj_profits_df = window_profits_df.copy()\n",
    "\n",
    "adj_profits_df = adjust_start_transfers(adj_profits_df,config['training_data']['training_period_start'])\n",
    "adj_profits_df = adjust_end_transfers(adj_profits_df,config['training_data']['training_period_end'])\n",
    "adj_profits_df = adjust_start_transfers(adj_profits_df,config['training_data']['modeling_period_start'])\n",
    "adj_profits_df = adjust_end_transfers(adj_profits_df,config['training_data']['modeling_period_end'])\n",
    "\n",
    "# Round final values\n",
    "adj_profits_df['usd_net_transfers'] = np.trunc(adj_profits_df['usd_net_transfers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only training period\n",
    "training_df = adj_profits_df[\n",
    "    (adj_profits_df['date'] >= pd.to_datetime(config['training_data']['training_period_start'])) &\n",
    "    (adj_profits_df['date'] <= pd.to_datetime(config['training_data']['training_period_end']))\n",
    "]\n",
    "training_df = training_df.sort_values(['wallet_address','coin_id','date'])\n",
    "training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wallet_volume = 10000\n",
    "\n",
    "# Sum cash flows on a wallet level\n",
    "wallets_df = pd.DataFrame(training_df.groupby(['wallet_address','date'])['usd_net_transfers'].sum())\n",
    "\n",
    "# Identify wallets with no transactions\n",
    "wallets_agg_df = wallets_df.groupby(level='wallet_address')['usd_net_transfers'].apply(lambda x: x.abs().sum())\n",
    "low_volume_wallets = wallets_agg_df[wallets_agg_df < min_wallet_volume].index\n",
    "\n",
    "# Remove transactionless wallets\n",
    "wallets_df_filtered = wallets_df[~wallets_df.index.get_level_values('wallet_address').isin(low_volume_wallets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallets_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by wallet_address and check for both positive and negative usd_net_transfers\n",
    "wallet_check = wallets_df_filtered.groupby('wallet_address')['usd_net_transfers'].apply(\n",
    "    lambda x: (x > 0).any() and (x < 0).any()\n",
    ")\n",
    "\n",
    "# Filter wallet addresses that do not meet the condition\n",
    "wallets_missing_both = wallet_check[~wallet_check].index\n",
    "\n",
    "print(wallets_missing_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = '0x036783df7aec54b5dfca9e1f870577bbcca95481'\n",
    "wallets_df.loc[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "profits_df[profits_df['wallet_address']==w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'zzMyrLPsQsbmeYHnQv3d626jBqwoB6k7oJSHpDUokGS'\n",
    "\n",
    "dates = wallets_df.loc[w].index.values\n",
    "cash_flows = wallets_df.loc[w]['usd_net_transfers']\n",
    "\n",
    "xirr(dates,cash_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by wallet_address (level of the MultiIndex) and calculate XIRR\n",
    "xirr_results = wallets_df.groupby(level='wallet_address').apply(\n",
    "    lambda df: xirr(df.index.get_level_values('date'), df['usd_net_transfers'])\n",
    ").reset_index(name='xirr')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(xirr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xirr(dates,cash_flows)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '77e2cf4b-d18a-4026-a2f2-f083f48fe1be'\n",
    "w = '0xaff2943cfe3e95f66142a1729079418d78e42236'\n",
    "\n",
    "# u.cw_filter_df(training_df,c,w)\n",
    "\n",
    "df = u.cw_filter_df(training_df,c,w)\n",
    "df = df.sort_values('date')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df['date']\n",
    "cash_flows = df['usd_net_transfers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyxirr import xirr\n",
    "\n",
    "xirr(dates,cash_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_flows.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate year fractions from the first date\n",
    "start_date = dates.min()  # Use the earliest date as the reference\n",
    "date_fractions = (dates - start_date).dt.days / 365.0\n",
    "date_fractions = date_fractions.values\n",
    "\n",
    "date_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_fractions = (np.datetime64(dates) - np.datetime64(dates[0])).astype('timedelta64[D]') / np.timedelta64(1, 'Y')\n",
    "date_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy_financial as npf\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_annualized_irr(df):\n",
    "    \"\"\"\n",
    "    Calculate the annualized IRR for each coin_id and wallet_address combination\n",
    "    using net transfers and dates.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns 'date', 'usd_net_transfers',\n",
    "                          'coin_id', and 'wallet_address'\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with coin_id, wallet_address, and irr columns\n",
    "    \"\"\"\n",
    "    # Function to calculate IRR for a single wallet\n",
    "    def calc_single_irr(group):\n",
    "        # Convert dates to datetime if they aren't already\n",
    "        dates = pd.to_datetime(group['date'])\n",
    "\n",
    "        # Calculate days between transactions\n",
    "        days = (dates - dates.iloc[0]).dt.days\n",
    "\n",
    "        # Get cash flows (negative of net transfers since outflow is positive in IRR calculations)\n",
    "        flows = -group['usd_net_transfers'].values\n",
    "\n",
    "        try:\n",
    "            # Calculate IRR using numpy_financial\n",
    "            # Convert days to years for the rate calculation\n",
    "            rates = days / 365.0\n",
    "            irr = npf.irr(flows)\n",
    "\n",
    "            # Convert to annualized rate\n",
    "            # Using the relationship: (1 + r)^(1/n) - 1\n",
    "            # where n is number of days/365\n",
    "            annualized_irr = (1 + irr) ** (365) - 1\n",
    "\n",
    "            return annualized_irr\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    # Group by coin_id and wallet_address and calculate IRR for each group\n",
    "    results = df.groupby(['coin_id', 'wallet_address']).apply(calc_single_irr).reset_index()\n",
    "    results.columns = ['coin_id', 'wallet_address', 'irr']\n",
    "\n",
    "    return results\n",
    "\n",
    "# Calculate IRR\n",
    "result_df = calculate_annualized_irr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wallet_irrs(grouped_df):\n",
    "    \"\"\"\n",
    "    Calculate IRR for each wallet from a MultiIndex DataFrame of cash flows.\n",
    "    Returns a DataFrame with wallet addresses and their IRRs.\n",
    "    \"\"\"\n",
    "    irrs = []\n",
    "\n",
    "    for wallet in grouped_df.index.get_level_values(0).unique():\n",
    "        cash_flows = grouped_df.loc[wallet]['usd_net_transfers'].values\n",
    "        try:\n",
    "            irr = np.irr(cash_flows)\n",
    "            irrs.append({'wallet_address': wallet, 'irr': irr})\n",
    "        except:\n",
    "            irrs.append({'wallet_address': wallet, 'irr': None})\n",
    "\n",
    "    return pd.DataFrame(irrs).set_index('wallet_address')\n",
    "\n",
    "\n",
    "irrs_df = calculate_wallet_irrs(grouped_df)\n",
    "irrs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrs_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_sql = '''\n",
    "#     with wallet_coins as (\n",
    "#         select *\n",
    "#         from (\n",
    "#             select wallet_address\n",
    "#             ,coin_id\n",
    "#             ,max(usd_inflows_cumulative) as coin_inflows\n",
    "#             from core.coin_wallet_profits\n",
    "#             group by 1,2\n",
    "#         )\n",
    "#         where coin_inflows > 500\n",
    "#     )\n",
    "\n",
    "#     ,wallets as (\n",
    "#         select *\n",
    "#         from (\n",
    "#             select wallet_address\n",
    "#             ,count(coin_id) as total_tokens\n",
    "#             ,sum(coin_inflows) as total_inflows\n",
    "#             from wallet_coins wti\n",
    "#             group by 1\n",
    "#         )\n",
    "#         where total_tokens between 3 and 50\n",
    "#         and total_inflows < 20000000\n",
    "#     )\n",
    "\n",
    "#     select cwp.wallet_address\n",
    "#     ,cwp.coin_id\n",
    "#     ,cwp.date\n",
    "#     ,round(cwp.usd_net_transfers) as usd_net_transfers\n",
    "#     ,round(cwp.usd_balance) as usd_balance\n",
    "#     ,round(cwp.usd_net_transfers/cmd.price) as token_transfers\n",
    "#     ,round(cwp.usd_balance/cmd.price) as token_balance\n",
    "#     ,cmd.price\n",
    "#     from wallets w\n",
    "#     join wallet_coins wc on wc.wallet_address = w.wallet_address\n",
    "#     join core.coin_wallet_profits cwp on cwp.wallet_address = wc.wallet_address\n",
    "#         and cwp.coin_id = wc.coin_id\n",
    "#     join core.coin_market_data cmd on cmd.coin_id = cwp.coin_id\n",
    "#         and cmd.date = cwp.date\n",
    "#     order by 1,2,3\n",
    "#     '''\n",
    "# transfers_df = dgc().run_sql(query_sql)\n",
    "\n",
    "# # Convert wallet_address to categorical, store the mapping, and convert the column to int32\n",
    "# wallet_address_categorical = transfers_df['wallet_address'].astype('category')\n",
    "# # wallet_address_mapping = wallet_address_categorical.cat.categories\n",
    "# # transfers_df['wallet_address'] = wallet_address_categorical.cat.codes.astype('uint32')\n",
    "\n",
    "\n",
    "# # Convert coin_id to categorical (original strings are preserved)\n",
    "# transfers_df['coin_id'] = transfers_df['coin_id'].astype('category')\n",
    "\n",
    "# # Convert all numerical columns to 32 bit, using safe_downcast to avoid overflow\n",
    "# transfers_df = u.safe_downcast(transfers_df, 'usd_net_transfers', 'float32')\n",
    "# transfers_df = u.safe_downcast(transfers_df, 'usd_balance', 'float32')\n",
    "# transfers_df = u.safe_downcast(transfers_df, 'token_transfers', 'float32')\n",
    "# transfers_df = u.safe_downcast(transfers_df, 'token_balance', 'float32')\n",
    "# transfers_df = u.safe_downcast(transfers_df, 'price', 'float32')\n",
    "\n",
    "# print(transfers_df.info())\n",
    "# print(u.df_mem(transfers_df))\n",
    "# transfers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_sql = '''\n",
    "#     with wallet_coins as (\n",
    "#         select *\n",
    "#         from (\n",
    "#             select wallet_address\n",
    "#             ,coin_id\n",
    "#             ,max(usd_inflows_cumulative) as coin_inflows\n",
    "#             from core.coin_wallet_profits\n",
    "#             group by 1,2\n",
    "#         )\n",
    "#         where coin_inflows > 500\n",
    "#     )\n",
    "\n",
    "#     ,wallets as (\n",
    "#         select *\n",
    "#         from (\n",
    "#             select wallet_address\n",
    "#             ,count(coin_id) as total_tokens\n",
    "#             ,sum(coin_inflows) as total_inflows\n",
    "#             from wallet_coins wti\n",
    "#             group by 1\n",
    "#         )\n",
    "#         where total_tokens between 3 and 50\n",
    "#         and total_inflows < 20000000\n",
    "#     )\n",
    "\n",
    "#     ,coins as (\n",
    "#         select wc.coin_id\n",
    "#         from wallets w\n",
    "#         join wallet_coins wc on wc.wallet_address = w.wallet_address\n",
    "#         group by 1\n",
    "#     )\n",
    "\n",
    "#     select cmd.coin_id\n",
    "#     ,cmd.date\n",
    "#     ,cmd.price\n",
    "#     ,cmd.market_cap\n",
    "#     from coins c\n",
    "#     join core.coin_market_data cmd on cmd.coin_id = c.coin_id\n",
    "#     order by 1,2\n",
    "#     '''\n",
    "# prices_df = dgc().run_sql(query_sql)\n",
    "\n",
    "# # Convert coin_id to categorical (original strings are preserved)\n",
    "# prices_df['coin_id'] = prices_df['coin_id'].astype('category')\n",
    "\n",
    "# # Convert all numerical columns to 32 bit, using safe_downcast to avoid overflow\n",
    "# prices_df = u.safe_downcast(prices_df, 'price', 'float32')\n",
    "# prices_df = u.safe_downcast(prices_df, 'market_cap', 'int32')\n",
    "\n",
    "# print(prices_df.info())\n",
    "# print(u.df_mem(prices_df))\n",
    "# prices_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
