{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# import local files if necessary\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "import utils as u\n",
    "importlib.reload(u)\n",
    "\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "\n",
    "# Load all configs as global variables\n",
    "global CONFIG, METRICS_CONFIG, MODELING_CONFIG, EXPERIMENTS_CONFIG, MODELING_FOLDER\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "CONFIG = config\n",
    "METRICS_CONFIG = metrics_config\n",
    "MODELING_CONFIG = modeling_config\n",
    "EXPERIMENTS_CONFIG = experiments_config\n",
    "MODELING_FOLDER = MODELING_CONFIG['modeling']['modeling_folder']\n",
    "modeling_folder = MODELING_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "start_date = config['training_data']['training_period_start']\n",
    "end_date = config['training_data']['modeling_period_end']\n",
    "\n",
    "# Retrieve market data\n",
    "market_data_df = td.retrieve_market_data()\n",
    "market_data_df, _ = cwm.split_dataframe_by_coverage(market_data_df, start_date, end_date, id_column='coin_id')\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'profits_df' not in globals():\n",
    "    profits_df = None\n",
    "\n",
    "profits_df = i.rebuild_profits_df_if_necessary(\n",
    "                config,\n",
    "                modeling_folder,\n",
    "                prices_df,\n",
    "                profits_df)\n",
    "\n",
    "\n",
    "# remove records from market_data_df that don't have transfers if configured to do so\n",
    "if config['data_cleaning']['exclude_coins_without_transfers']:\n",
    "    market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n",
    "    prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, performance_df = i.build_configured_model_input(\n",
    "                                    profits_df,\n",
    "                                    market_data_df,\n",
    "                                    config,\n",
    "                                    metrics_config,\n",
    "                                    modeling_config)\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "model, model_id = m.train_model(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    modeling_folder,\n",
    "                    modeling_config['modeling']['model_params'])\n",
    "\n",
    "# 3.5 Evaluate and save the model's performance on the test set to a CSV\n",
    "metrics_df = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_mooncrater_targets(performance_df, modeling_config):\n",
    "    \"\"\"\n",
    "    Calculates 'is_moon' and 'is_crater' target variables based on performance.\n",
    "\n",
    "    Parameters:\n",
    "    - performance_df: DataFrame with columns 'coin_id' and 'performance'.\n",
    "    - modeling_config: Configuration for modeling with target variable thresholds.\n",
    "\n",
    "    Returns:\n",
    "    - target_variables_df: DataFrame with columns 'coin_id', 'is_moon', and 'is_crater'.\n",
    "    \"\"\"\n",
    "    moon_threshold = modeling_config['target_variables']['moon_threshold']\n",
    "    crater_threshold = modeling_config['target_variables']['crater_threshold']\n",
    "    moon_minimum_percent = modeling_config['target_variables']['moon_minimum_percent']\n",
    "    crater_minimum_percent = modeling_config['target_variables']['crater_minimum_percent']\n",
    "\n",
    "    target_variables_df = performance_df.copy()\n",
    "    target_variables_df['is_moon'] = (target_variables_df['performance'] >= moon_threshold).astype(int)\n",
    "    target_variables_df['is_crater'] = (target_variables_df['performance'] <= crater_threshold).astype(int)\n",
    "\n",
    "    total_coins = len(target_variables_df)\n",
    "    moons = target_variables_df['is_moon'].sum()\n",
    "    craters = target_variables_df['is_crater'].sum()\n",
    "\n",
    "    # Ensure minimum percentage for moons and craters\n",
    "    if moons / total_coins < moon_minimum_percent:\n",
    "        additional_moons_needed = int(total_coins * moon_minimum_percent) - moons\n",
    "        moon_candidates = target_variables_df[target_variables_df['is_moon'] == 0].nlargest(additional_moons_needed, 'performance')\n",
    "        target_variables_df.loc[moon_candidates.index, 'is_moon'] = 1\n",
    "\n",
    "    if craters / total_coins < crater_minimum_percent:\n",
    "        additional_craters_needed = int(total_coins * crater_minimum_percent) - craters\n",
    "        crater_candidates = target_variables_df[target_variables_df['is_crater'] == 0].nsmallest(additional_craters_needed, 'performance')\n",
    "        target_variables_df.loc[crater_candidates.index, 'is_crater'] = 1\n",
    "\n",
    "    return target_variables_df[['coin_id', 'is_moon', 'is_crater']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fe)\n",
    "target_variables_df, performance_df, outcomes_df = fe.create_target_variables(market_data_df, config['training_data'], modeling_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def valid_prices_df():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample DataFrame with valid price data for multiple coins.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'] * 2,\n",
    "        'date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-12-31', '2023-12-31', '2023-12-31'],\n",
    "        'price': [30000, 2000, 0.5, 35000, 2500, 0.6]\n",
    "    })\n",
    "valid_prices_df=valid_prices_df()\n",
    "\n",
    "def valid_training_data_config():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample training data configuration.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'modeling_period_start': '2023-01-01',\n",
    "        'modeling_period_end': '2023-12-31'\n",
    "    }\n",
    "valid_training_data_config=valid_training_data_config()\n",
    "\n",
    "def no_change_prices_df():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample DataFrame with no price change for some coins.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'] * 2,\n",
    "        'date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-12-31', '2023-12-31', '2023-12-31'],\n",
    "        'price': [30000, 2000, 0.5, 30000, 2500, 0.5]\n",
    "    })\n",
    "no_change_prices_df=no_change_prices_df()\n",
    "\n",
    "def negative_performance_prices_df():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample DataFrame with negative performance for some coins.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'] * 2,\n",
    "        'date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-12-31', '2023-12-31', '2023-12-31'],\n",
    "        'price': [30000, 2000, 0.5, 25000, 2500, 0.4]\n",
    "    })\n",
    "negative_performance_prices_df=negative_performance_prices_df()\n",
    "\n",
    "def multiple_datapoints_prices_df():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample DataFrame with multiple data points between start and end dates.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'] * 4,\n",
    "        'date': ['2023-01-01', '2023-01-01', '2023-01-01',\n",
    "                 '2023-06-15', '2023-06-15', '2023-06-15',\n",
    "                 '2023-09-30', '2023-09-30', '2023-09-30',\n",
    "                 '2023-12-31', '2023-12-31', '2023-12-31'],\n",
    "        'price': [30000, 2000, 0.5,\n",
    "                  32000, 2200, 0.55,\n",
    "                  34000, 2400, 0.58,\n",
    "                  35000, 2500, 0.6]\n",
    "    })\n",
    "multiple_datapoints_prices_df=multiple_datapoints_prices_df()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Test prepare_and_compute_performance function with multiple data points between start and end dates.\n",
    "\n",
    "This test ensures that the function correctly calculates performance using only start and end dates,\n",
    "ignoring intermediate data points.\n",
    "\"\"\"\n",
    "performance_df, outcomes_df = fe.prepare_and_compute_performance(multiple_datapoints_prices_df, valid_training_data_config)\n",
    "\n",
    "expected_performance = pd.DataFrame({\n",
    "    'coin_id': ['BTC', 'ETH', 'XRP'],\n",
    "    'performance': [0.1667, 0.25, 0.2]\n",
    "})\n",
    "\n",
    "assert (np.isclose(performance_df['performance'].values, expected_performance['performance'].values, rtol=1e-4, atol=1e-4)).all()\n",
    "\n",
    "expected_outcomes = pd.DataFrame({\n",
    "    'coin_id': ['BTC', 'ETH', 'XRP'],\n",
    "    'outcome': ['performance calculated'] * 3\n",
    "})\n",
    "\n",
    "assert np.array_equal(outcomes_df.values, expected_outcomes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(performance_df['performance'].values, expected_performance['performance'].values, rtol=1e-4, atol=1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def negative_performance_prices_df():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample DataFrame with negative performance for some coins.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'] * 2,\n",
    "        'date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-12-31', '2023-12-31', '2023-12-31'],\n",
    "        'price': [30000, 2000, 0.5, 25000, 2500, 0.4]\n",
    "    })\n",
    "negative_performance_prices_df=negative_performance_prices_df()\n",
    "\n",
    "def test_prepare_and_compute_performance_negative(negative_performance_prices_df, valid_training_data_config):\n",
    "    \"\"\"\n",
    "    Test prepare_and_compute_performance function with negative performance for some coins.\n",
    "\n",
    "    This test ensures that the function correctly calculates negative performance values\n",
    "    for coins with price decreases and correct performance for others.\n",
    "    \"\"\"\n",
    "    performance_df, outcomes_df = fe.prepare_and_compute_performance(negative_performance_prices_df, valid_training_data_config)\n",
    "\n",
    "    expected_performance = pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'],\n",
    "        'performance': [-0.1667, 0.25, -0.2]\n",
    "    })\n",
    "\n",
    "    assert np.array_equal(performance_df.values, expected_performance.values)\n",
    "\n",
    "    for actual, expected in zip(performance_df['performance'], expected_performance['performance']):\n",
    "        assert actual == pytest.approx(expected, abs=1e-4)\n",
    "\n",
    "@pytest.fixture\n",
    "def multiple_datapoints_prices_df():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample DataFrame with multiple data points between start and end dates.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'] * 4,\n",
    "        'date': ['2023-01-01', '2023-01-01', '2023-01-01',\n",
    "                 '2023-06-15', '2023-06-15', '2023-06-15',\n",
    "                 '2023-09-30', '2023-09-30', '2023-09-30',\n",
    "                 '2023-12-31', '2023-12-31', '2023-12-31'],\n",
    "        'price': [30000, 2000, 0.5,\n",
    "                  32000, 2200, 0.55,\n",
    "                  34000, 2400, 0.58,\n",
    "                  35000, 2500, 0.6]\n",
    "    })\n",
    "\n",
    "@pytest.mark.unit\n",
    "def test_prepare_and_compute_performance_multiple_datapoints(multiple_datapoints_prices_df, valid_training_data_config):\n",
    "    \"\"\"\n",
    "    Test prepare_and_compute_performance function with multiple data points between start and end dates.\n",
    "\n",
    "    This test ensures that the function correctly calculates performance using only start and end dates,\n",
    "    ignoring intermediate data points.\n",
    "    \"\"\"\n",
    "    performance_df, outcomes_df = fe.prepare_and_compute_performance(multiple_datapoints_prices_df, valid_training_data_config)\n",
    "\n",
    "    expected_performance = pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'],\n",
    "        'performance': [0.1667, 0.25, 0.2]\n",
    "    })\n",
    "\n",
    "    assert np.array_equal(performance_df.values, expected_performance.values)\n",
    "\n",
    "    for actual, expected in zip(performance_df['performance'], expected_performance['performance']):\n",
    "        assert actual == pytest.approx(expected, abs=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prepare_and_compute_performance_negative(negative_performance_prices_df, valid_training_data_config):\n",
    "    \"\"\"\n",
    "    Test prepare_and_compute_performance function with negative performance for some coins.\n",
    "\n",
    "    This test ensures that the function correctly calculates negative performance values\n",
    "    for coins with price decreases and correct performance for others.\n",
    "    \"\"\"\n",
    "    performance_df, outcomes_df = fe.prepare_and_compute_performance(negative_performance_prices_df, valid_training_data_config)\n",
    "\n",
    "    expected_performance = pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'],\n",
    "        'performance': [-0.1667, 0.25, -0.2]\n",
    "    })\n",
    "\n",
    "    assert np.array_equal(performance_df.values, expected_performance.values)\n",
    "\n",
    "    for actual, expected in zip(performance_df['performance'], expected_performance['performance']):\n",
    "        assert actual == pytest.approx(expected, abs=1e-4)\n",
    "\n",
    "@pytest.fixture\n",
    "def multiple_datapoints_prices_df():\n",
    "    \"\"\"\n",
    "    Fixture to create a sample DataFrame with multiple data points between start and end dates.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'] * 4,\n",
    "        'date': ['2023-01-01', '2023-01-01', '2023-01-01',\n",
    "                 '2023-06-15', '2023-06-15', '2023-06-15',\n",
    "                 '2023-09-30', '2023-09-30', '2023-09-30',\n",
    "                 '2023-12-31', '2023-12-31', '2023-12-31'],\n",
    "        'price': [30000, 2000, 0.5,\n",
    "                  32000, 2200, 0.55,\n",
    "                  34000, 2400, 0.58,\n",
    "                  35000, 2500, 0.6]\n",
    "    })\n",
    "\n",
    "@pytest.mark.unit\n",
    "def test_prepare_and_compute_performance_multiple_datapoints(multiple_datapoints_prices_df, valid_training_data_config):\n",
    "    \"\"\"\n",
    "    Test prepare_and_compute_performance function with multiple data points between start and end dates.\n",
    "\n",
    "    This test ensures that the function correctly calculates performance using only start and end dates,\n",
    "    ignoring intermediate data points.\n",
    "    \"\"\"\n",
    "    performance_df, outcomes_df = fe.prepare_and_compute_performance(multiple_datapoints_prices_df, valid_training_data_config)\n",
    "\n",
    "    expected_performance = pd.DataFrame({\n",
    "        'coin_id': ['BTC', 'ETH', 'XRP'],\n",
    "        'performance': [0.1667, 0.25, 0.2]\n",
    "    })\n",
    "\n",
    "    assert np.array_equal(performance_df.values, expected_performance.values)\n",
    "\n",
    "    for actual, expected in zip(performance_df['performance'], expected_performance['performance']):\n",
    "        assert actual == pytest.approx(expected, abs=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
