{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "import progressbar\n",
    "\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# import local files if necessary\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "import utils as u\n",
    "importlib.reload(u)\n",
    "\n",
    "# load configs\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# retreive market data\n",
    "market_data_df = td.retrieve_market_data()\n",
    "market_data_df,_ = td.fill_market_data_gaps(market_data_df,config['data_cleaning']['max_gap_days'])\n",
    "market_data_df,_,_ = cwm.split_dataframe_by_coverage(\n",
    "    market_data_df,\n",
    "    start_date=config['training_data']['training_period_start'],\n",
    "    end_date=config['training_data']['modeling_period_end'],\n",
    "    id_column='coin_id'\n",
    ")\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "importlib.reload(u)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# initial steps for this model\n",
    "filtered_market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n",
    "\n",
    "training_data_tuples = []\n",
    "training_data_dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# dataset variables\n",
    "dataset_category = 'time_series'\n",
    "dataset_name = 'market_data'\n",
    "dataset_df = filtered_market_data_df.copy()\n",
    "# declare dataset configs based on variables\n",
    "dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "dataset_metrics_config = metrics_config[dataset_category][dataset_name]\n",
    "# calculate metrics for each value column\n",
    "value_column = 'price'\n",
    "# a value_column-specific df will be used for feature generation\n",
    "value_column_config = config['datasets'][dataset_category][dataset_name][value_column]\n",
    "value_column_metrics_config = metrics_config[dataset_category][dataset_name][value_column]\n",
    "value_column_df = dataset_df[['date','coin_id',value_column]].copy()\n",
    "\n",
    "# check if there are any time series indicators to add, e.g. sma, ema, etc\n",
    "if 'indicators' in value_column_metrics_config:\n",
    "    # add the indicators as new columns in the value_column_df\n",
    "    value_column_metrics_df, _ = cwm.generate_time_series_indicators(\n",
    "        value_column_df,\n",
    "        config,\n",
    "        value_column_metrics_config['indicators'],\n",
    "        value_column,\n",
    "        id_column='coin_id'\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # if no indicators are needed, pass through coins in the original df that have values for all dates\n",
    "    value_column_metrics_df, _, _ = cwm.split_dataframe_by_coverage(\n",
    "        value_column_df,\n",
    "        config['training_data']['training_period_start'],\n",
    "        config['training_data']['training_period_end'],\n",
    "        id_column='coin_id'\n",
    "    )\n",
    "\n",
    "value_column_metrics_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Prices Features -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# dataset variables\n",
    "dataset_category = 'time_series'\n",
    "dataset_name = 'market_data'\n",
    "dataset_df = filtered_market_data_df.copy()\n",
    "\n",
    "# declare dataset configs based on variables\n",
    "dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "dataset_metrics_config = metrics_config[dataset_category][dataset_name]\n",
    "\n",
    "\n",
    "\n",
    "# calculate metrics for each value column\n",
    "for value_column in list(dataset_metrics_config.keys()):\n",
    "\n",
    "    # a value_column-specific df will be used for feature generation\n",
    "    value_column_config = config['datasets'][dataset_category][dataset_name][value_column]\n",
    "    value_column_metrics_config = metrics_config[dataset_category][dataset_name][value_column]\n",
    "    value_column_df = dataset_df[['date','coin_id',value_column]].copy()\n",
    "\n",
    "    # check if there are any time series indicators to add, e.g. sma, ema, etc\n",
    "    if 'indicators' in value_column_metrics_config:\n",
    "\n",
    "        # calculate and merge all indicators in the config\n",
    "        all_indicator_dfs = []\n",
    "        for indicator in value_column_metrics_config.keys():\n",
    "            indicator_df, _ = cwm.generate_time_series_indicators(\n",
    "                value_column_df,\n",
    "                config,\n",
    "                value_column_metrics_config['indicators'],\n",
    "                value_column,\n",
    "                id_column='coin_id'\n",
    "            )\n",
    "            all_indicator_dfs.append(indicator_df)\n",
    "\n",
    "        # join all generated indicators for the value_column together\n",
    "        value_column_indicators_df = all_indicator_dfs[0]\n",
    "        for indicator_df in all_indicator_dfs[1:]:\n",
    "            value_column_indicators_df = pd.merge(value_column_indicators_df, indicator_df, on='date', how='outer')\n",
    "\n",
    "    else:\n",
    "        # if no indicators are needed, pass through coins in the original df that have values for all dates\n",
    "        value_column_metrics_df, _, _ = cwm.split_dataframe_by_coverage(\n",
    "            value_column_df,\n",
    "            config['training_data']['training_period_start'],\n",
    "            config['training_data']['training_period_end'],\n",
    "            id_column='coin_id'\n",
    "        )\n",
    "\n",
    "    # generate features from the metrics\n",
    "    value_column_features_df, value_column_tuple = fe.convert_dataset_metrics_to_features(\n",
    "        value_column_metrics_df,\n",
    "        value_column_config,\n",
    "        dataset_metrics_config,\n",
    "        config,\n",
    "        modeling_config\n",
    "    )\n",
    "\n",
    "    logger.info('Generated features for %s.%s.%s',\n",
    "                dataset_category, dataset_name, value_column)\n",
    "\n",
    "    training_data_tuples.append(value_column_tuple)\n",
    "    training_data_dfs.append(value_column_features_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# dataset variables\n",
    "dataset_category = 'wallet_cohorts'\n",
    "\n",
    "\n",
    "for cohort_name in metrics_config[dataset_category]:\n",
    "\n",
    "    # load configs\n",
    "    dataset_metrics_config = metrics_config[dataset_category][cohort_name]\n",
    "    dataset_config = config['datasets'][dataset_category][cohort_name]\n",
    "    cohort_description = dataset_config['description']\n",
    "\n",
    "    # identify wallets in the cohort\n",
    "    cohort_summary_df = cwm.classify_wallet_cohort(profits_df, dataset_config)\n",
    "    cohort_wallets = cohort_summary_df[cohort_summary_df['in_cohort']==True]['wallet_address']\n",
    "\n",
    "    # If no cohort members were identified, continue\n",
    "    if len(cohort_wallets) == 0:\n",
    "        logger.info(\"No wallets identified as members of cohort '%s'\", cohort_name)\n",
    "        continue\n",
    "\n",
    "    # generate cohort buysell_metrics\n",
    "    cohort_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets)\n",
    "\n",
    "    # generate features from the metrics\n",
    "    dataset_features_df, dataset_tuple = fe.convert_dataset_metrics_to_features(\n",
    "        cohort_metrics_df,\n",
    "        dataset_config,\n",
    "        dataset_metrics_config,\n",
    "        config,\n",
    "        modeling_config\n",
    "    )\n",
    "\n",
    "    logger.info('Generated features for %s.%s',\n",
    "                dataset_category, cohort_name)\n",
    "\n",
    "    training_data_tuples.append(dataset_tuple)\n",
    "    training_data_dfs.append(dataset_features_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_tuples = [\n",
    "    ('price_2024-09-26_00-37_model_period_2024-09-01_preprocessed.csv', 'drop_records'),\n",
    "    ('volume_2024-09-26_00-37_model_period_2024-09-01_preprocessed.csv', 'drop_records'),\n",
    "    ('market_cap_2024-09-26_00-37_model_period_2024-09-01_preprocessed.csv', 'drop_records'),\n",
    "    ('cohort_10k_2024-09-26_00-48_model_period_2024-09-01_preprocessed.csv', 'fill_zeros'),\n",
    "    ('cohort_50k_2024-09-26_00-48_model_period_2024-09-01_preprocessed.csv', 'fill_zeros'),\n",
    "    ('cohort_whales_2024-09-26_00-49_model_period_2024-09-01_preprocessed.csv', 'fill_zeros'),\n",
    "    ('cohort_normies_2024-09-26_00-50_model_period_2024-09-01_preprocessed.csv', 'fill_zeros')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_category = 'coin_facts'\n",
    "dataset_name = 'coin_metadata'\n",
    "\n",
    "\n",
    "# load configs\n",
    "dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "\n",
    "\n",
    "# generate features\n",
    "metadata_df = td.retrieve_metadata_data()\n",
    "metadata_features_df = td.generate_coin_metadata_features(metadata_df, config)\n",
    "metadata_features_df.head()\n",
    "\n",
    "# save flattened output\n",
    "flattened_output_directory = os.path.join(modeling_config['modeling']['modeling_folder'],'outputs/flattened_outputs')\n",
    "flattened_metadata_df, flattened_metadata_filepath = fe.save_flattened_outputs(\n",
    "    metadata_features_df,\n",
    "    flattened_output_directory,\n",
    "    dataset_config['description'],\n",
    "    config['training_data']['modeling_period_start']\n",
    ")\n",
    "\n",
    "# check preprocessed file\n",
    "preprocessed_metadata_df, preprocessed_metadata_output_path = fe.preprocess_coin_df(\n",
    "    flattened_metadata_filepath,\n",
    "    modeling_config,\n",
    "    dataset_config\n",
    ")\n",
    "\n",
    "metadata_tuple = (preprocessed_metadata_output_path.split('preprocessed_outputs/')[1], dataset_config['fill_method'])\n",
    "\n",
    "\n",
    "training_data_tuples.append(metadata_tuple)\n",
    "training_data_dfs.append(preprocessed_metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = u.load_config('../config/config.yaml')\n",
    "metrics_config = u.load_config('../config/metrics_config.yaml')\n",
    "modeling_config = u.load_config('../config/modeling_config.yaml')\n",
    "experiments_config = u.load_config('../config/experiments_config.yaml')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# merge training data\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "training_data_df, merge_logs_df = fe.create_training_data_df(modeling_folder, training_data_tuples)\n",
    "\n",
    "# create the target variable df\n",
    "target_variable_df,_ = fe.create_target_variables_mooncrater(filtered_market_data_df, config['training_data'], modeling_config)\n",
    "\n",
    "# merge the two into the final model input df\n",
    "model_input_df = fe.prepare_model_input_df(training_data_df, target_variable_df, modeling_config['modeling']['target_column'])\n",
    "\n",
    "# split the df into train and test sets\n",
    "X_train, X_test, y_train, y_test = m.split_model_input(\n",
    "    model_input_df,\n",
    "    modeling_config['modeling']['target_column'],\n",
    "    modeling_config['modeling']['train_test_split'],\n",
    "    modeling_config['modeling']['random_state']\n",
    ")\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "model, model_id = m.train_model(X_train, y_train, modeling_folder, modeling_config['modeling']['model_params'])\n",
    "\n",
    "# 3.5 Evaluate the model's performance on the test set\n",
    "metrics = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
    "\n",
    "# 3.6 Log the experiment results for this configuration\n",
    "m.log_trial_results(modeling_folder, model_id)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `model` is your trained model and `feature_names` is a list of your feature names\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X_train.columns  # Replace with the correct source of your feature names if different\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance (optional)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importance\n",
    "feature_importance_df.sort_values('importance',ascending=False)\n",
    "# feature_importance_df.sort_values('feature',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gap_days = 2\n",
    "\n",
    "# Input data\n",
    "prices_df_gaps_below_max = pd.DataFrame({\n",
    "    'coin_id': ['coin1', 'coin1', 'coin1', 'coin2', 'coin2'],\n",
    "    'date': pd.to_datetime(['2024-01-01', '2024-01-03', '2024-01-04',\n",
    "                            '2024-01-01', '2024-01-03']),\n",
    "    'price': [100, 102, 103, 200, 202]\n",
    "})\n",
    "\n",
    "# Expected data after filling\n",
    "expected_data = {\n",
    "    'date': pd.to_datetime(['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04',  # coin1\n",
    "                            '2024-01-01', '2024-01-02', '2024-01-03']),  # coin2\n",
    "    'coin_id': ['coin1', 'coin1', 'coin1', 'coin1',\n",
    "                'coin2', 'coin2', 'coin2'],\n",
    "    'price': [100.0, 100, 102, 103,\n",
    "                200, 200, 202]\n",
    "}\n",
    "expected_df = pd.DataFrame(expected_data)[['date', 'coin_id', 'price']]\n",
    "\n",
    "# Run the function\n",
    "prices_filled_df, outcomes_df = td.fill_market_data_gaps(prices_df_gaps_below_max, max_gap_days)\n",
    "\n",
    "# Reorder columns for comparison\n",
    "prices_filled_df = prices_filled_df[['date', 'coin_id', 'price']]\n",
    "\n",
    "# Assertions\n",
    "pd.testing.assert_frame_equal(prices_filled_df, expected_df)\n",
    "assert all(outcomes_df['outcome'] == 'gaps below threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(prices_filled_df.values,expected_df.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df_gaps_below_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
