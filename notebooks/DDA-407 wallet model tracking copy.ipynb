{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training Data Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "\n",
    "# Retrieve datasets\n",
    "profits_df,market_data_df = wo.retrieve_datasets()\n",
    "\n",
    "# Define wallet cohort after cleaning\n",
    "training_wallet_metrics_df,wallet_cohort = wo.define_wallet_cohort(profits_df,market_data_df)\n",
    "\n",
    "# Generate profits_df for all training windows and the modeling period\n",
    "training_profits_df, training_windows_profits_dfs, modeling_profits_df, validation_profits_df = wo.split_profits_df(profits_df,\n",
    "                                                                               market_data_df,wallet_cohort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Market data: add indicators\n",
    "market_indicators_data_df = ind.generate_time_series_indicators(market_data_df,\n",
    "                                                        wallets_metrics_config['time_series']['market_data'],\n",
    "                                                        'coin_id')\n",
    "\n",
    "\n",
    "# Transfers data retrieval for the wallet_ids in temp.wallet_modeling_cohort\n",
    "transfers_data_df = wcf.retrieve_transfers_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate features for the full training dataset\n",
    "training_wallet_features_df = wf.calculate_wallet_features(training_profits_df, market_indicators_data_df,\n",
    "                                                           transfers_data_df, wallet_cohort)\n",
    "\n",
    "# Define the full feature set by appending a suffix for each window\n",
    "training_data_df = training_wallet_features_df.add_suffix(\"_all_windows\")\n",
    "\n",
    "# Generate features for each window\n",
    "for i, window_profits_df in enumerate(training_windows_profits_dfs, 1):\n",
    "    # Generate the features\n",
    "    window_wallet_features_df = wf.calculate_wallet_features(window_profits_df, market_indicators_data_df,\n",
    "                                                             transfers_data_df, wallet_cohort)\n",
    "\n",
    "    # Add column suffix and join to training_data_df\n",
    "    window_wallet_features_df = window_wallet_features_df.add_suffix(f'_w{i}')\n",
    "    training_data_df = training_data_df.join(window_wallet_features_df, how='left')\n",
    "\n",
    "\n",
    "training_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join target variable to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Clean inactive wallets from modeling period data\n",
    "modeling_wallets_df = wo.filter_modeling_period_wallets(modeling_profits_df)\n",
    "\n",
    "# Generate target variables\n",
    "target_vars_df = wm.generate_target_variables(modeling_wallets_df)\n",
    "\n",
    "# Merge training data and target variables?\n",
    "modeling_df = training_data_df.join(target_vars_df[wallets_config['modeling']['target_variable']],\n",
    "                                    how='inner')\n",
    "\n",
    "modeling_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crude Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop columns if specified to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# make df\n",
    "df = modeling_df.copy()\n",
    "\n",
    "if wallets_config['modeling']['drop_columns']:\n",
    "    # Get list of columns to drop from config\n",
    "    columns_to_drop = wallets_config['modeling']['drop_columns']\n",
    "\n",
    "    # Only drop columns that actually exist in the DataFrame\n",
    "    existing_columns = [col for col in columns_to_drop if col in df.columns]\n",
    "\n",
    "    # Drop the columns if any exist\n",
    "    if existing_columns:\n",
    "        df = df.drop(columns=existing_columns)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming your dataframe is called 'df'\n",
    "# Separate features and target\n",
    "X = df.drop(wallets_config['modeling']['target_variable'], axis=1)\n",
    "y = df[wallets_config['modeling']['target_variable']]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create preprocessing steps\n",
    "numeric_features = X.columns.tolist()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ])\n",
    "\n",
    "# Define the gradient boosting regressor with key parameters\n",
    "gbr = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    max_features=1.0,\n",
    "    min_samples_leaf=0.01,\n",
    "    min_samples_split=0.01,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', gbr)\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "model=pipeline.named_steps['regressor']  # Pass the actual model object\n",
    "# model=grid_search.best_estimator_.named_steps['regressor']\n",
    "\n",
    "# Example usage with your existing code:\n",
    "evaluation = wm.evaluate_regression_model(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    model=model,\n",
    "    feature_names=X.columns.tolist()\n",
    ")\n",
    "\n",
    "# Print summary report\n",
    "print(evaluation['summary_report'])\n",
    "\n",
    "# Access specific metrics\n",
    "print(f\"R² Score: {evaluation['r2']:.3f}\")\n",
    "\n",
    "# The figure can be displayed or saved\n",
    "if evaluation['figures'] is not None:\n",
    "    plt.show()  # or evaluation['figures'].savefig('model_evaluation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#     Model Performance Summary:\n",
    "#     -------------------------\n",
    "#     R² Score: 0.340\n",
    "#     RMSE: 0.093\n",
    "#     MAE: 0.062\n",
    "#     MAPE: 26.0%\n",
    "\n",
    "#     Residuals Analysis:\n",
    "#     ------------------\n",
    "#     Mean of Residuals: -0.001\n",
    "#     Standard Deviation of Residuals: 0.093\n",
    "#     95% Prediction Interval: ±0.183\n",
    "\n",
    "# R² Score: 0.340\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profits validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate validation period wallet metrics\n",
    "validation_profits_df = wcf.add_cash_flow_transfers_logic(validation_profits_df)\n",
    "wallet_trading_features_df = wf.calculate_wallet_trading_features(validation_profits_df)\n",
    "validation_wallets_df = wm.generate_target_variables(wallet_trading_features_df)\n",
    "\n",
    "# Attach validation period performance to modeling period scores\n",
    "validation_df = pd.DataFrame()\n",
    "validation_df['wallet_address'] = X_test.index.values\n",
    "validation_df['score'] = y_pred\n",
    "validation_df['score_rounded'] = np.ceil(validation_df['score']*20)/20\n",
    "validation_df = validation_df.set_index('wallet_address')\n",
    "validation_df = validation_df.join(validation_wallets_df,how='left')\n",
    "\n",
    "# Group wallets by score bucket and assess performance\n",
    "grouped_val = validation_df.groupby('score_rounded').agg(\n",
    "    wallets=('score','count'),\n",
    "    mean_invested=('invested','mean'),\n",
    "    mean_net_gain=('net_gain','mean'),\n",
    "    median_invested=('invested','median'),\n",
    "    median_net_gain=('net_gain','median'),\n",
    ")\n",
    "grouped_val['mean_return'] = grouped_val['mean_net_gain']/grouped_val['mean_invested']\n",
    "grouped_val['median_return'] = grouped_val['median_net_gain']/grouped_val['median_invested']\n",
    "grouped_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coin performance predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Consolidate wallet scores at the coin level\n",
    "wallet_scores_df = pd.DataFrame({'score': y_pred}, index=validation_df.index)\n",
    "coin_wallet_metrics_df = cf.calculate_coin_metrics_from_wallet_scores(validation_profits_df, wallet_scores_df)\n",
    "\n",
    "# Calculate coin performance during the validation period\n",
    "coin_performance_df = cf.calculate_coin_performance(market_data_df,\n",
    "                                                     wallets_config['training_data']['validation_period_start'],\n",
    "                                                     wallets_config['training_data']['validation_period_end'])\n",
    "\n",
    "# Join aggregated wallet metrics with actual coin performance\n",
    "coin_forecasting_df = coin_wallet_metrics_df.join(coin_performance_df, how='inner')\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_forecasting']['top_n']\n",
    "max_market_cap = wallets_config['coin_forecasting']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_forecasting']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = cf.validate_coin_performance(coin_forecasting_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def analyze_top_performing_coins(df, return_percentile=75):\n",
    "    \"\"\"\n",
    "    Analyzes how wallet and scoring metrics differ between top performing coins and others.\n",
    "    Top performers defined as coins with returns >= 75th percentile.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with coin metrics including 'coin_return' and scoring metrics\n",
    "        return_percentile: Threshold for defining top performers (default 75)\n",
    "\n",
    "    Returns:\n",
    "        Dict containing statistical comparison of metrics between top performers and others\n",
    "    \"\"\"\n",
    "    # Split coins into performance groups\n",
    "    return_threshold = np.percentile(df['coin_return'], return_percentile)\n",
    "    top_coins = df[df['coin_return'] >= return_threshold]\n",
    "    other_coins = df[df['coin_return'] < return_threshold]\n",
    "\n",
    "    # Keep original metric names for consistency\n",
    "    metrics_to_analyze = [\n",
    "        'weighted_avg_score',\n",
    "        'composite_score',\n",
    "        'top_wallet_balance_pct',\n",
    "        'top_wallet_count_pct',\n",
    "        'score_confidence'\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    for metric in metrics_to_analyze:\n",
    "        # Calculate group means\n",
    "        top_mean = top_coins[metric].mean()\n",
    "        other_mean = other_coins[metric].mean()\n",
    "\n",
    "        # T-test between groups\n",
    "        t_stat, p_value = stats.ttest_ind(\n",
    "            top_coins[metric].fillna(0),\n",
    "            other_coins[metric].fillna(0)\n",
    "        )\n",
    "\n",
    "        # Effect size calculation\n",
    "        pooled_std = np.sqrt((top_coins[metric].var() + other_coins[metric].var()) / 2)\n",
    "        cohens_d = (top_mean - other_mean) / pooled_std if pooled_std != 0 else 0\n",
    "\n",
    "        results[metric] = {\n",
    "            'top_quartile_mean': top_mean,  # mean for coins with returns >= 75th percentile\n",
    "            'other_mean': other_mean,       # mean for coins with returns < 75th percentile\n",
    "            'abs_diff': top_mean - other_mean,\n",
    "            'pct_diff': ((top_mean - other_mean) / other_mean * 100) if other_mean != 0 else 0,\n",
    "            'p_value': p_value,\n",
    "            'effect_size': cohens_d\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def print_performance_analysis(df):\n",
    "    \"\"\"\n",
    "    Prints formatted comparison of metrics between top performing coins and others.\n",
    "    Top performing defined as returns >= 75th percentile.\n",
    "    \"\"\"\n",
    "    results = analyze_top_performing_coins(df)\n",
    "\n",
    "    print(f\"\\n=== Metric Analysis: Returns >= {75}th percentile vs Others ===\")\n",
    "    for metric, stats in results.items():\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Top quartile mean (returns >= p75): {stats['top_quartile_mean']:.4f}\")\n",
    "        print(f\"  Other coins mean (returns < p75): {stats['other_mean']:.4f}\")\n",
    "        print(f\"  Absolute difference: {stats['abs_diff']:.4f}\")\n",
    "        print(f\"  Percent difference: {stats['pct_diff']:.1f}%\")\n",
    "        print(f\"  P-value: {stats['p_value']:.4f}\")\n",
    "        print(f\"  Effect size: {stats['effect_size']:.4f}\")\n",
    "\n",
    "# Example usage with additional metrics if needed\n",
    "def extended_analysis(df):\n",
    "    # Basic analysis\n",
    "    basic_results = analyze_top_performing_coins(df)\n",
    "\n",
    "    # Could add more specialized analyses here while maintaining consistent naming\n",
    "    return basic_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('coin_wallet_metrics.csv')\n",
    "    print_performance_analysis(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
