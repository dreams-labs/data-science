{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['ALERT_SOUND_FILEPATH']=\"../../../Local/assets/sounds/mixkit-alert-bells-echo-765.wav\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_orchestrator as wo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_modeling.model_reporting as wmr\n",
    "import wallet_modeling.wallet_model_experiment as wme\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.clustering_features as wcl\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.performance_features as wp\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.wallet_features as wf\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.wallet_model_evaluation as wime\n",
    "import wallet_insights.validation_analysis as wiv\n",
    "import wallet_insights.coin_forecasting as wicf\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp,\n",
    "           wo, wtd, wmr, wme,\n",
    "           wcl, wmc, wmt, wp, wtf, wts, wf,\n",
    "           wime, wiv, wicf]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "wallets_config = WalletsConfig.load_from_yaml('../config/wallets_config.yaml')\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "u.export_code(code_directories=['wallet_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training Data Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve datasets\n",
    "profits_df,market_data_df = wo.retrieve_datasets()\n",
    "\n",
    "# # Define wallet cohort after cleaning\n",
    "# training_wallet_metrics_df,wallet_cohort = wo.define_wallet_cohort(profits_df,market_data_df)\n",
    "\n",
    "# # Generate profits_df for all training windows and the modeling period\n",
    "# training_profits_df, training_windows_profits_dfs, modeling_profits_df, validation_profits_df = wo.split_profits_df(profits_df,\n",
    "#                                                                                market_data_df,wallet_cohort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the training period end (training period start is pre-imputed into profits_df generation)\n",
    "training_period_end = [wallets_config['training_data']['training_period_end']]\n",
    "imputed_profits_df = pri.impute_profits_for_multiple_dates(profits_df, market_data_df,\n",
    "                                                        training_period_end, n_threads=24)\n",
    "\n",
    "# Create a training period only profits_df\n",
    "training_profits_df = imputed_profits_df[\n",
    "    imputed_profits_df['date']<=wallets_config['training_data']['training_period_end']\n",
    "    ].copy()\n",
    "\n",
    "\n",
    "training_profits_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_training_profits_df = training_profits_df[training_profits_df['date']<wallets_config['training_data']['training_period_end']].copy()\n",
    "end_training_profits_df = training_profits_df[training_profits_df['date']==wallets_config['training_data']['training_period_end']].copy()\n",
    "\n",
    "# identify the last dates in the middle of the training period for each wallet address\n",
    "last_mid_dates = mid_training_profits_df.groupby(['wallet_address','coin_id'])['date'].max()\n",
    "last_mid_dates_df = last_mid_dates.reset_index()\n",
    "last_mid_dates_df.columns = ['wallet_address', 'coin_id', 'date']\n",
    "last_mid_dates_df\n",
    "# # Merge to keep only the matching rows\n",
    "# last_mid_dates_df = mid_training_profits_df.merge(last_mid_dates_df, on=['wallet_address', 'coin_id', 'date'])\n",
    "# last_mid_dates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify wallets that had a balance as of their last transaction in the middle of the period\n",
    "had_mid_balance_df = last_mid_dates_df[last_mid_dates_df['usd_balance']>0]\n",
    "had_mid_balance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_training_profits_df[end_training_profits_df['is_imputed']==True].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '0019555b-bb44-405e-a035-e868fe113ca8'\n",
    "w = 214076\n",
    "test_profits_df = u.cw_filter_df(training_profits_df,c,w).copy()\n",
    "test_profits_df\n",
    "\n",
    "u.cw_filter_df(end_training_profits_df,c,w).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_period_end = [wallets_config['training_data']['training_period_end']]\n",
    "imputed_profits_df = pri.impute_profits_for_multiple_dates(test_profits_df, market_data_df,\n",
    "                                                        training_period_end, n_threads=24)\n",
    "imputed_profits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "u.export_code(['training_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Market data: add indicators\n",
    "market_indicators_data_df = ind.generate_time_series_indicators(market_data_df,\n",
    "                                                        wallets_metrics_config['time_series']['market_data'],\n",
    "                                                        'coin_id')\n",
    "\n",
    "\n",
    "# Transfers data retrieval for the wallet_ids in temp.wallet_modeling_cohort\n",
    "transfers_sequencing_df = wts.retrieve_transfers_sequencing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate features for the full training dataset\n",
    "training_wallet_features_df = wf.calculate_wallet_features(training_profits_df, market_indicators_data_df,\n",
    "                                                           transfers_sequencing_df, wallet_cohort)\n",
    "\n",
    "# Define the full feature set by appending a suffix for each window\n",
    "training_data_df = training_wallet_features_df.add_suffix(\"_all_windows\")\n",
    "\n",
    "# Generate features for each window\n",
    "for i, window_profits_df in enumerate(training_windows_profits_dfs, 1):\n",
    "    # Generate the features\n",
    "    window_wallet_features_df = wf.calculate_wallet_features(window_profits_df, market_indicators_data_df,\n",
    "                                                             transfers_sequencing_df, wallet_cohort)\n",
    "\n",
    "    # Add column suffix and join to training_data_df\n",
    "    window_wallet_features_df = window_wallet_features_df.add_suffix(f'_w{i}')\n",
    "    training_data_df = training_data_df.join(window_wallet_features_df, how='left')\n",
    "\n",
    "\n",
    "base_training_data_df = training_data_df.copy()\n",
    "base_training_data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.export_code(code_directories=['wallet_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_profits_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features for the full training dataset\n",
    "training_wallet_features_df = wf.calculate_wallet_features(training_profits_df, market_indicators_data_df,\n",
    "                                                           transfers_sequencing_df, wallet_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_profits_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_wallet_features_df = wf.calculate_wallet_features(window_profits_df, market_indicators_data_df,\n",
    "                                                            transfers_sequencing_df, wallet_cohort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df2 = window_profits_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "profits_df2 = window_profits_df.copy()\n",
    "\n",
    "# Create a DataFrame with all wallets that should exist\n",
    "wallet_features_df = pd.DataFrame(index=wallet_cohort)\n",
    "wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "# Trading features (inner join, custom fill)\n",
    "profits_df2 = wtf.add_cash_flow_transfers_logic(profits_df2)\n",
    "trading_features = wtf.calculate_wallet_trading_features(profits_df2)\n",
    "trading_features = wtf.fill_trading_features_data(trading_features, wallet_cohort)\n",
    "wallet_features_df = wallet_features_df.join(trading_features, how='inner')\n",
    "\n",
    "# Market timing features (fill zeros)\n",
    "timing_features = wmt.calculate_market_timing_features(profits_df2, market_indicators_data_df)\n",
    "wallet_features_df = wallet_features_df.join(timing_features, how='left')\\\n",
    "    .fillna({col: 0 for col in timing_features.columns})\n",
    "\n",
    "# Market cap features (fill zeros)\n",
    "market_features = wmc.calculate_market_cap_features(profits_df2, market_indicators_data_df)\n",
    "wallet_features_df = wallet_features_df.join(market_features, how='left')\\\n",
    "    .fillna({col: 0 for col in market_features.columns})\n",
    "\n",
    "# Transfers features (fill -1)\n",
    "transfers_features = wts.calculate_transfers_sequencing_features(profits_df2, transfers_sequencing_df)\n",
    "wallet_features_df = wallet_features_df.join(transfers_features, how='left')\\\n",
    "    .fillna({col: -1 for col in transfers_features.columns})\n",
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features = wp.calculate_performance_features(wallet_features_df)\n",
    "wallet_features_df = wallet_features_df.join(\n",
    "    performance_features.drop(['invested', 'net_gain'], axis=1),\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trading_features['invested'].min() < 0:\n",
    "    raise ValueError(f\"Found {len(trading_features[trading_features['invested']<0])} wallets \"\n",
    "                     \"with negative invested values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 33872418\n",
    "profits_df2[profits_df2['wallet_address']==w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallets_df = wallet_features_df.copy()\n",
    "\n",
    "metrics_df = wallets_df[['invested','net_gain']].copy().round(6)\n",
    "returns_winsorization = wallets_config['modeling']['returns_winsorization']\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Calculate base return\n",
    "metrics_df['return'] = np.where(abs(metrics_df['invested']) == 0,0,\n",
    "                                metrics_df['net_gain'] / metrics_df['invested'])\n",
    "\n",
    "# Apply winsorization\n",
    "if returns_winsorization > 0:\n",
    "    metrics_df['return'] = u.winsorize(metrics_df['return'],returns_winsorization)\n",
    "\n",
    "# Risk-Adjusted Dollar Return\n",
    "metrics_df['risk_adj_return'] = metrics_df['net_gain'] * \\\n",
    "    (1 + np.log10(metrics_df['invested'] + epsilon))\n",
    "\n",
    "# # Normalize returns\n",
    "# metrics_df['norm_return'] = (metrics_df['return'] - metrics_df['return'].min()) / \\\n",
    "#     (metrics_df['return'].max() - metrics_df['return'].min())\n",
    "\n",
    "# # Normalize logged investments\n",
    "# log_invested = np.log10(metrics_df['invested'] + epsilon)\n",
    "# metrics_df['norm_invested'] = (log_invested - log_invested.min()) / \\\n",
    "#     (log_invested.max() - log_invested.min())\n",
    "\n",
    "# # Performance score\n",
    "# metrics_df['performance_score'] = (0.6 * metrics_df['norm_return'] +\n",
    "#                                     0.4 * metrics_df['norm_invested'])\n",
    "\n",
    "# # Log-weighted return\n",
    "# metrics_df['log_weighted_return'] = metrics_df['return'] * \\\n",
    "#     np.log10(metrics_df['invested'] + epsilon)\n",
    "\n",
    "# # Hybrid score (combining absolute and relative performance)\n",
    "# max_gain = metrics_df['net_gain'].abs().max()\n",
    "# metrics_df['norm_gain'] = metrics_df['net_gain'] / max_gain\n",
    "# metrics_df['hybrid_score'] = (metrics_df['norm_gain'] +\n",
    "#                             metrics_df['norm_return']) / 2\n",
    "\n",
    "# # Size-adjusted rank\n",
    "# # Create mask for zero values\n",
    "# zero_mask = metrics_df['invested'] == 0\n",
    "\n",
    "# # Create quartiles series initialized with 'q0' for zero values\n",
    "# quartiles = pd.Series('q0', index=metrics_df.index)\n",
    "\n",
    "# # Calculate quartiles for non-zero values\n",
    "# non_zero_quartiles = pd.qcut(metrics_df['invested'][~zero_mask],\n",
    "#                             q=4,\n",
    "#                             labels=['q1', 'q2', 'q3', 'q4'])\n",
    "\n",
    "# # Assign the quartiles to non-zero values\n",
    "# quartiles[~zero_mask] = non_zero_quartiles\n",
    "\n",
    "# # Calculate size-adjusted rank within each quartile\n",
    "# metrics_df['size_adjusted_rank'] = metrics_df.groupby(quartiles)['return'].rank(pct=True)\n",
    "\n",
    "\n",
    "# # Clean up intermediate columns\n",
    "# cols_to_drop = ['norm_return', 'norm_invested', 'norm_gain']\n",
    "# metrics_df = metrics_df.drop(columns=[c for c in cols_to_drop\n",
    "#                                     if c in metrics_df.columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Append clustering features based on all numeric features in the base training data\n",
    "cluster_features = wcl.create_basic_cluster_features(base_training_data_df)\n",
    "training_data_df = base_training_data_df.join(cluster_features, how='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join target variable to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Clean inactive wallets from modeling period data\n",
    "modeling_wallets_df = wo.filter_modeling_period_wallets(modeling_profits_df)\n",
    "\n",
    "# Generate target variables\n",
    "target_vars_df = wp.calculate_performance_features(modeling_wallets_df)\n",
    "\n",
    "# Merge training data and target variables?\n",
    "modeling_df = training_data_df.join(target_vars_df[wallets_config['modeling']['target_variable']],\n",
    "                                    how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create an experiment instance\n",
    "experiment = wme.WalletModel(wallets_config)\n",
    "\n",
    "# Run the experiment and get results\n",
    "model_results = experiment.run_experiment(modeling_df)\n",
    "\n",
    "# Extract the trained model\n",
    "model = model_results['pipeline'].named_steps['regressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model artifacts\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, evaluator, wallet_scores_df, coin_validation_df = wmr.generate_and_save_model_artifacts(\n",
    "    model_results=model_results,\n",
    "    validation_profits_df=validation_profits_df,\n",
    "    base_path='../wallet_modeling'\n",
    ")\n",
    "u.play_notification()\n",
    "\n",
    "# Print results\n",
    "evaluator.plot_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation period assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wallet_performance_df, bucketed_performance_df = wiv.calculate_validation_metrics(\n",
    "    X_test=model_results['X_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    validation_profits_df=validation_profits_df,\n",
    ")\n",
    "\n",
    "bucketed_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coin performance predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create coin_validation_df with metrics and returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Consolidate wallet scores at the coin level\n",
    "wallet_scores_df = pd.DataFrame({'score': model_results['y_pred']}, index=model_results['y_test'].index)\n",
    "coin_wallet_metrics_df = wicf.calculate_coin_metrics_from_wallet_scores(validation_profits_df, wallet_scores_df)\n",
    "\n",
    "# Calculate coin performance during the validation period\n",
    "coin_performance_df = wicf.calculate_coin_performance(market_data_df,\n",
    "                                                     wallets_config['training_data']['validation_period_start'],\n",
    "                                                     wallets_config['training_data']['validation_period_end'])\n",
    "\n",
    "# Join aggregated wallet metrics with actual coin performance\n",
    "coin_validation_df = coin_wallet_metrics_df.join(coin_performance_df, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = wicf.analyze_market_cap_segments(\n",
    "    coin_validation_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "wicf.plot_segment_heatmap(summary_df)\n",
    "# wicf.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_forecasting']['top_n']\n",
    "max_market_cap = wallets_config['coin_forecasting']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_forecasting']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = wicf.validate_coin_performance(coin_validation_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare performance of high vs low score coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wicf.print_performance_analysis(coin_validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "def analyze_coin_metrics(df):\n",
    "    \"\"\"\n",
    "    Analyze relationships between coin metrics and returns\n",
    "    \"\"\"\n",
    "    # Calculate correlations with coin_return\n",
    "    metrics_of_interest = [\n",
    "        'weighted_avg_score',\n",
    "        'composite_score',\n",
    "        'score_confidence',\n",
    "        'top_wallet_balance_pct',\n",
    "        'top_wallet_count_pct',\n",
    "        'total_wallets',\n",
    "        'avg_wallet_balance',\n",
    "        'market_cap'\n",
    "    ]\n",
    "\n",
    "    # Calculate correlations\n",
    "    correlations = {}\n",
    "    for metric in metrics_of_interest:\n",
    "        correlation = df[metric].corr(df['coin_return'])\n",
    "        correlations[metric] = correlation\n",
    "\n",
    "    # Sort correlations by absolute value\n",
    "    correlations_sorted = {k: v for k, v in sorted(correlations.items(),\n",
    "                                                 key=lambda x: abs(x[1]),\n",
    "                                                 reverse=True)}\n",
    "\n",
    "    # Calculate basic statistics for coins with positive vs negative returns\n",
    "    positive_returns = df[df['coin_return'] > 0]\n",
    "    negative_returns = df[df['coin_return'] <= 0]\n",
    "\n",
    "    comparison_stats = {}\n",
    "    for metric in metrics_of_interest:\n",
    "        pos_mean = positive_returns[metric].mean()\n",
    "        neg_mean = negative_returns[metric].mean()\n",
    "        # Perform t-test\n",
    "        t_stat, p_value = stats.ttest_ind(positive_returns[metric],\n",
    "                                        negative_returns[metric])\n",
    "\n",
    "        comparison_stats[metric] = {\n",
    "            'positive_mean': pos_mean,\n",
    "            'negative_mean': neg_mean,\n",
    "            'difference': pos_mean - neg_mean,\n",
    "            'p_value': p_value\n",
    "        }\n",
    "\n",
    "    # Identify potential success indicators\n",
    "    success_indicators = {\n",
    "        metric: stats for metric, stats in comparison_stats.items()\n",
    "        if (abs(stats['difference']) > 0.1 * stats['negative_mean'] and\n",
    "            stats['p_value'] < 0.05)\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'correlations': correlations_sorted,\n",
    "        'comparison_stats': comparison_stats,\n",
    "        'success_indicators': success_indicators\n",
    "    }\n",
    "\n",
    "# Create summary statistics\n",
    "def print_analysis_results(results):\n",
    "    \"\"\"\n",
    "    Print formatted analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Correlation Analysis ===\")\n",
    "    print(\"\\nCorrelations with coin return (sorted by strength):\")\n",
    "    for metric, corr in results['correlations'].items():\n",
    "        print(f\"{metric:25} : {corr:0.4f}\")\n",
    "\n",
    "    print(\"\\n=== Positive vs Negative Returns Analysis ===\")\n",
    "    print(\"\\nMetrics comparison for positive vs negative returns:\")\n",
    "    for metric, stats in results['comparison_stats'].items():\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Positive returns mean: {stats['positive_mean']:0.4f}\")\n",
    "        print(f\"  Negative returns mean: {stats['negative_mean']:0.4f}\")\n",
    "        print(f\"  Difference: {stats['difference']:0.4f}\")\n",
    "        print(f\"  P-value: {stats['p_value']:0.4f}\")\n",
    "\n",
    "    print(\"\\n=== Strong Success Indicators ===\")\n",
    "    print(\"\\nMetrics showing significant difference between positive and negative returns:\")\n",
    "    for metric, stats in results['success_indicators'].items():\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Mean difference: {stats['difference']:0.4f}\")\n",
    "        print(f\"  P-value: {stats['p_value']:0.4f}\")\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "def main():\n",
    "    # Read the data\n",
    "    df = pd.read_csv('coin_wallet_metrics.csv')\n",
    "\n",
    "    # Run analysis\n",
    "    results = analyze_coin_metrics(df)\n",
    "\n",
    "    # Print results\n",
    "    print_analysis_results(results)\n",
    "\n",
    "    # Create visualizations\n",
    "    create_visualizations(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winsorize the returns (apply caps to the top n % of values)\n",
    "returns_winsorized = u.winsorize(returns, winsorization_cutoff)\n",
    "\n",
    "# Merge datasets\n",
    "df = pd.DataFrame({\n",
    "    'predictions': predictions,\n",
    "    'returns': returns_winsorized,\n",
    "})\n",
    "\n",
    "# Sort by actual returns to obtain optimal performance\n",
    "df_sorted = df.sort_values('returns', ascending=False)\n",
    "cumulative_best_returns = np.cumsum(df_sorted['returns'])\n",
    "cumulative_best_avg_returns = df_sorted['returns'].expanding().mean()\n",
    "\n",
    "# Sort by model score to obtain modeled performance\n",
    "df_sorted = df.sort_values('predictions', ascending=False)\n",
    "cumulative_model_returns = np.cumsum(df_sorted['returns'])\n",
    "cumulative_model_avg_returns = df_sorted['returns'].expanding().mean()\n",
    "\n",
    "# Calculate average return across all data\n",
    "average_return = np.mean(returns_winsorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_model_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_forecasting']['top_n']\n",
    "max_market_cap = wallets_config['coin_forecasting']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_forecasting']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = wicf.validate_coin_performance(coin_validation_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# List the coins that would have been picked at the start of the validation period\n",
    "top_coins_df = coin_validation_df[\n",
    "    (coin_validation_df['market_cap_filled']<=max_market_cap)\n",
    "    & (coin_validation_df['market_cap_filled']>=min_market_cap)\n",
    "].copy()\n",
    "\n",
    "sort_column = wallets_config['coin_forecasting']['sort_method']\n",
    "\n",
    "top_coins_df.sort_values(sort_column,ascending=False).head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test the clean_profits_df function to ensure wallets with excessive inflows\n",
    "are correctly excluded and logged.\n",
    "\"\"\"\n",
    "\n",
    "# Hardcoded test data for profits_df\n",
    "profits_df = pd.DataFrame({\n",
    "    'coin_id': ['BTC', 'ETH', 'BTC', 'ETH', 'LTC', 'BTC', 'ETH'],\n",
    "    'wallet_address': ['wallet1', 'wallet1', 'wallet2', 'wallet2', 'wallet2',\n",
    "                        'wallet3', 'wallet3'],\n",
    "    'date': pd.date_range(start='2023-01-01', periods=7),\n",
    "    'usd_inflows_cumulative': [10000, 8000, 2000, 1500, 1500, 500, 250]\n",
    "})\n",
    "\n",
    "# Hardcoded data cleaning config\n",
    "data_cleaning_config = {\n",
    "    'max_wallet_inflows': 15000  # Threshold for total inflows\n",
    "}\n",
    "\n",
    "# Call the function\n",
    "cleaned_df, exclusions_logs_df = dr.clean_profits_df(profits_df, data_cleaning_config)\n",
    "\n",
    "# Expected cleaned DataFrame\n",
    "expected_cleaned_df = (profits_df[profits_df['wallet_address'].isin(['wallet2', 'wallet3'])]\n",
    "    .reset_index(drop=True)\n",
    "    .sort_values(['coin_id','wallet_address','date']))\n",
    "\n",
    "# Expected exclusions DataFrame\n",
    "expected_exclusions = pd.DataFrame({\n",
    "    'wallet_address': ['wallet1'],\n",
    "    'inflows_exclusion': [True]\n",
    "})\n",
    "\n",
    "# Assertions\n",
    "assert len(cleaned_df) == len(expected_cleaned_df)\n",
    "assert np.array_equal(cleaned_df.values, expected_cleaned_df.values)\n",
    "\n",
    "assert len(exclusions_logs_df) == len(expected_exclusions)\n",
    "assert np.array_equal(exclusions_logs_df.values, expected_exclusions.values)\n",
    "\n",
    "# Check inflows in the cleaned DataFrame\n",
    "assert cleaned_df['usd_inflows_cumulative'].sum() == 5750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_cleaned_df.sort_values(['coin_id','wallet_address','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
