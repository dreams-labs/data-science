{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "import progressbar\n",
    "\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# import local files if necessary\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df, create_progress_bar\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "import utils as u\n",
    "importlib.reload(u)\n",
    "\n",
    "# load configs\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import TypeAdapter\n",
    "sys.path.append('..//src/config_models')\n",
    "import metrics_config\n",
    "importlib.reload(metrics_config)\n",
    "\n",
    "\n",
    "metrics_config_dict = load_config('../config/metrics_config.yaml')\n",
    "print(metrics_config_dict)\n",
    "\n",
    "\n",
    "metrics_config_adapter = TypeAdapter(metrics_config.MetricsConfig)\n",
    "\n",
    "pydantic_config = metrics_config_adapter.validate_python(metrics_config_dict)\n",
    "\n",
    "print(pydantic_config.dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydantic import ValidationError\n",
    "# sys.path.append('..//src/config_models')\n",
    "# from config as pyc\n",
    "# importlib.reload(pyc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pydantic import ValidationError\n",
    "sys.path.append('..//src/config_models')\n",
    "from config import MainConfig\n",
    "\n",
    "def load_and_validate_config(config_path: str) -> MainConfig:\n",
    "    \"\"\"\n",
    "    Load the YAML configuration file and validate it against the MainConfig model.\n",
    "    \"\"\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        config_dict = yaml.safe_load(file)\n",
    "\n",
    "    try:\n",
    "        config = MainConfig(**config_dict)\n",
    "        return config\n",
    "    except ValidationError as e:\n",
    "        print(f\"Configuration validation error:\")\n",
    "        print(e)\n",
    "        raise\n",
    "\n",
    "def print_config_summary(config: MainConfig):\n",
    "    \"\"\"\n",
    "    Print a summary of the validated configuration.\n",
    "    \"\"\"\n",
    "    print(\"Configuration Summary:\")\n",
    "    print(f\"Modeling period start: {config.training_data.modeling_period_start}\")\n",
    "    print(f\"Modeling period duration: {config.training_data.modeling_period_duration} days\")\n",
    "    print(f\"Training period duration: {config.training_data.training_period_duration} days\")\n",
    "    print(f\"Number of wallet cohorts: {len(config.datasets.wallet_cohorts)}\")\n",
    "    print(f\"Time series data types: {list(config.datasets.time_series['market_data'].keys())}\")\n",
    "    print(f\"Coin facts data types: {list(config.datasets.coin_facts.keys())}\")\n",
    "    print(f\"Profitability filter: {config.data_cleaning.profitability_filter}\")\n",
    "    print(f\"Inflows filter: {config.data_cleaning.inflows_filter}\")\n",
    "    print(f\"Max gap days: {config.data_cleaning.max_gap_days}\")\n",
    "\n",
    "\n",
    "config_path = \"../config/config.yaml\"  # Update this path to your config.yaml location\n",
    "try:\n",
    "    config = load_and_validate_config(config_path)\n",
    "    print(\"Configuration validated successfully!\")\n",
    "    print_config_summary(config)\n",
    "except ValidationError:\n",
    "    print(\"Configuration validation failed. Please check the errors above and correct your config.yaml file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pydantic import ValidationError\n",
    "sys.path.append('..//src/config_models')\n",
    "from metrics_config import MetricsConfig\n",
    "importlib.reload(metrics_config)\n",
    "\n",
    "\n",
    "metrics_config_dict = load_config('../config/metrics_config.yaml')\n",
    "\n",
    "pydantic_config = MetricsConfig(**metrics_config_dict)\n",
    "pydantic_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pydantic_config = MetricsConfig(**metrics_config_dict)\n",
    "    print(pydantic_config.dict())\n",
    "except ValidationError as e:\n",
    "    print(f\"Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import TypeAdapter\n",
    "\n",
    "metrics_config_adapter = TypeAdapter(MetricsConfig)\n",
    "try:\n",
    "    pydantic_config = metrics_config_adapter.validate_python(metrics_config_dict)\n",
    "    print(pydantic_config.dict())\n",
    "except ValidationError as e:\n",
    "    print(f\"Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pydantic import TypeAdapter\n",
    "sys.path.append('..//src/config_models')\n",
    "from metrics_config import MetricsConfig, WalletCohortMetricType\n",
    "\n",
    "def load_and_validate_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config_data = yaml.safe_load(file)\n",
    "\n",
    "    metrics_config_adapter = TypeAdapter(MetricsConfig)\n",
    "    try:\n",
    "        metrics_config = metrics_config_adapter.validate_python(config_data)\n",
    "        print(\"Configuration is valid!\")\n",
    "        return metrics_config\n",
    "    except Exception as e:\n",
    "        print(f\"Configuration is invalid: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def print_config_details(config):\n",
    "    if config and config.wallet_cohorts:\n",
    "        for cohort_name, cohort in config.wallet_cohorts.cohorts.items():\n",
    "            print(f\"\\nCohort: {cohort_name}\")\n",
    "            for metric_type, metric in cohort.metrics.items():\n",
    "                print(f\"  Metric: {metric_type}\")\n",
    "                if metric.aggregations and metric.aggregations.sum:\n",
    "                    print(f\"    Scaling: {metric.aggregations.sum.scaling}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = load_and_validate_config('../config/metrics_config.yaml')\n",
    "    if config:\n",
    "        print_config_details(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "# retreive market data\n",
    "market_data_df = td.retrieve_market_data()\n",
    "market_data_df,_ = td.fill_market_data_gaps(market_data_df,config['data_cleaning']['max_gap_days'])\n",
    "prices_df = market_data_df[['coin_id','date','price']].copy()\n",
    "\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "# initial steps for this model\n",
    "filtered_market_data_df = market_data_df[market_data_df['coin_id'].isin(profits_df['coin_id'])]\n",
    "\n",
    "training_data_tuples = []\n",
    "training_data_dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "logger.setLevel(logging.DEBUG)\n",
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "# dataset variables\n",
    "dataset_category = 'time_series'\n",
    "dataset_name = 'market_data'\n",
    "dataset_df = filtered_market_data_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "# declare dataset configs based on variables\n",
    "dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "dataset_metrics_config = metrics_config[dataset_category][dataset_name]\n",
    "\n",
    "# calculate metrics for each value column\n",
    "for value_column in list(dataset_metrics_config.keys()):\n",
    "\n",
    "    # a value_column-specific df will be used for feature generation\n",
    "    value_column_config = config['datasets'][dataset_category][dataset_name][value_column]\n",
    "    value_column_metrics_config = metrics_config[dataset_category][dataset_name][value_column]\n",
    "    value_column_df = dataset_df[['date','coin_id',value_column]].copy()\n",
    "\n",
    "    # check if there are any time series metrics to add, e.g. sma, ema, etc\n",
    "    if 'metrics' in value_column_metrics_config:\n",
    "\n",
    "        # calculate and merge all metrics in the config\n",
    "        all_metrics = []\n",
    "\n",
    "        # generate metrics\n",
    "        metric_df, _ = cwm.generate_time_series_metrics(\n",
    "            metric_df,\n",
    "            config,\n",
    "            value_column_metrics_config['metrics'],\n",
    "            value_column,\n",
    "            id_column='coin_id'\n",
    "        )\n",
    "\n",
    "        all_metrics.append(metric_df)\n",
    "\n",
    "        # join all generated metrics for the value_column together\n",
    "        value_column_metrics_df = all_metrics[0]\n",
    "        for metrics_df in all_metrics[1:]:\n",
    "            value_column_metrics_df = pd.merge(value_column_metrics_df, metrics_df, on='date', how='outer')\n",
    "\n",
    "    else:\n",
    "        # if no additional metrics are needed, pass through coins in the original df that have values for all dates\n",
    "        value_column_metrics_df, _, _ = cwm.split_dataframe_by_coverage(\n",
    "            value_column_df,\n",
    "            config['training_data']['training_period_start'],\n",
    "            config['training_data']['training_period_end'],\n",
    "            id_column='coin_id'\n",
    "        )\n",
    "\n",
    "    # generate features from the metrics\n",
    "    value_column_features_df, value_column_tuple = fe.convert_coin_date_metrics_to_features(\n",
    "        value_column_metrics_df,\n",
    "        value_column_config,\n",
    "        dataset_metrics_config,\n",
    "        config,\n",
    "        modeling_config\n",
    "    )\n",
    "\n",
    "    logger.info('Generated features for %s.%s.%s',\n",
    "                dataset_category, dataset_name, value_column)\n",
    "\n",
    "    training_data_tuples.append(value_column_tuple)\n",
    "    training_data_dfs.append(value_column_features_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wallet Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# dataset variables\n",
    "dataset_category = 'wallet_cohorts'\n",
    "\n",
    "\n",
    "for cohort_name in metrics_config[dataset_category]:\n",
    "\n",
    "    # load configs\n",
    "    dataset_metrics_config = metrics_config[dataset_category][cohort_name]\n",
    "    dataset_config = config['datasets'][dataset_category][cohort_name]\n",
    "    cohort_description = dataset_config['description']\n",
    "\n",
    "    # identify wallets in the cohort\n",
    "    cohort_summary_df = cwm.classify_wallet_cohort(profits_df, dataset_config)\n",
    "    cohort_wallets = cohort_summary_df[cohort_summary_df['in_cohort']==True]['wallet_address']\n",
    "\n",
    "    # If no cohort members were identified, continue\n",
    "    if len(cohort_wallets) == 0:\n",
    "        logger.info(\"No wallets identified as members of cohort '%s'\", cohort_name)\n",
    "        continue\n",
    "\n",
    "    # generate cohort buysell_metrics\n",
    "    cohort_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets)\n",
    "\n",
    "    # generate features from the metrics\n",
    "    dataset_features_df, dataset_tuple = fe.convert_coin_date_metrics_to_features(\n",
    "        cohort_metrics_df,\n",
    "        dataset_config,\n",
    "        dataset_metrics_config,\n",
    "        config,\n",
    "        modeling_config\n",
    "    )\n",
    "\n",
    "    logger.info('Generated features for %s.%s',\n",
    "                dataset_category, cohort_name)\n",
    "\n",
    "    training_data_tuples.append(dataset_tuple)\n",
    "    training_data_dfs.append(dataset_features_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_category = 'coin_facts'\n",
    "dataset_name = 'coin_metadata'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load configs\n",
    "dataset_config = config['datasets'][dataset_category][dataset_name]\n",
    "\n",
    "\n",
    "# generate features\n",
    "metadata_df = td.retrieve_metadata_data()\n",
    "metadata_features_df = td.generate_coin_metadata_features(metadata_df, config)\n",
    "metadata_features_df.head()\n",
    "\n",
    "# save flattened output\n",
    "flattened_output_directory = os.path.join(modeling_config['modeling']['modeling_folder'],'outputs/flattened_outputs')\n",
    "flattened_metadata_df, flattened_metadata_filepath = fe.save_flattened_outputs(\n",
    "    metadata_features_df,\n",
    "    flattened_output_directory,\n",
    "    dataset_config['description'],\n",
    "    config['training_data']['modeling_period_start']\n",
    ")\n",
    "\n",
    "# check preprocessed file\n",
    "preprocessed_metadata_df, preprocessed_metadata_output_path = fe.preprocess_coin_df(\n",
    "    flattened_metadata_filepath,\n",
    "    modeling_config,\n",
    "    dataset_config\n",
    ")\n",
    "\n",
    "metadata_tuple = (preprocessed_metadata_output_path.split('preprocessed_outputs/')[1], dataset_config['fill_method'])\n",
    "\n",
    "\n",
    "training_data_tuples.append(metadata_tuple)\n",
    "training_data_dfs.append(preprocessed_metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_tuples = training_data_tuples[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "\n",
    "# merge training data\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "training_data_df, merge_logs_df = fe.create_training_data_df(modeling_folder, training_data_tuples)\n",
    "\n",
    "# create the target variable df\n",
    "target_variable_df,_ = fe.create_target_variables_mooncrater(filtered_market_data_df, config['training_data'], modeling_config)\n",
    "\n",
    "# merge the two into the final model input df\n",
    "model_input_df = fe.prepare_model_input_df(training_data_df, target_variable_df, modeling_config['modeling']['target_column'])\n",
    "\n",
    "# split the df into train and test sets\n",
    "X_train, X_test, y_train, y_test = m.split_model_input(\n",
    "    model_input_df,\n",
    "    modeling_config['modeling']['target_column'],\n",
    "    modeling_config['modeling']['train_test_split'],\n",
    "    modeling_config['modeling']['random_state']\n",
    ")\n",
    "\n",
    "# 3.4 Train the model using the current configuration and log the results\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "model, model_id = m.train_model(X_train, y_train, modeling_folder, modeling_config['modeling']['model_params'])\n",
    "\n",
    "# 3.5 Evaluate the model's performance on the test set\n",
    "metrics = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
    "\n",
    "# 3.6 Log the experiment results for this configuration\n",
    "m.log_trial_results(modeling_folder, model_id)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `model` is your trained model and `feature_names` is a list of your feature names\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X_train.columns  # Replace with the correct source of your feature names if different\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance (optional)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importance\n",
    "feature_importance_df.sort_values('importance',ascending=False)\n",
    "# feature_importance_df.sort_values('feature',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
