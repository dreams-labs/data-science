{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# import local files if necessary\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "\n",
    "# load configs\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/config_metrics.yaml')\n",
    "modeling_config = load_config('../config/config_modeling.yaml')\n",
    "experiments_config = load_config('../config/config_experiments.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/config_metrics.yaml')\n",
    "modeling_config = load_config('../config/config_modeling.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14/Sep/2024 12:25:53] INFO [dreams_core.core.retrieve_prices_data:42] retrieved prices data with shape (120763, 3)\n",
      "[14/Sep/2024 12:25:53] INFO [dreams_core.core.fill_prices_gaps:126] 382 coins had no gaps, 19 coins had gaps filled, and 38 coins were dropped due to large gaps.\n",
      "[14/Sep/2024 12:27:08] INFO [dreams_core.core.retrieve_transfers_data:333] retrieved transfers_df with shape (35657183, 5) after 74.9 seconds.\n",
      "[14/Sep/2024 12:27:08] INFO [dreams_core.core.prepare_profits_data:374] Preparing profits_df data...\n",
      "[14/Sep/2024 12:28:31] INFO [dreams_core.core.calculate_wallet_profitability:554] Generated profits df after 36.06 seconds\n",
      "[14/Sep/2024 12:29:09] INFO [dreams_core.core.clean_profits_df:625] Finished cleaning profits_df after 38.51 seconds.\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# retrieve and clean prices data\n",
    "prices_df = td.retrieve_prices_data()\n",
    "prices_df,_ = td.fill_prices_gaps(prices_df,config['data_cleaning']['max_gap_days'])\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14/Sep/2024 12:50:11] INFO [dreams_core.core.classify_shark_coins:691] creation of shark_coins_df complete.\n",
      "[14/Sep/2024 12:50:11] INFO [dreams_core.core.generate_buysell_metrics_df:33] Preparing buysell_metrics_df...\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.generate_buysell_metrics_df:99] Generated buysell_metrics_df after 3.49 seconds.\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.flatten_coin_date_df:84] Flattening columns ['buyers_new', 'total_bought', 'total_sold', 'total_buyers'] into coin-level features...\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.flatten_coin_date_df:100] Flattened input df into coin-level features with shape (89, 57) after 0.10 seconds.\n",
      "[14/Sep/2024 12:50:15] WARNING [dreams_core.core.preprocess_coin_df:412] Unknown scaling method None for column total_bought_median\n",
      "[14/Sep/2024 12:50:15] WARNING [dreams_core.core.preprocess_coin_df:412] Unknown scaling method None for column total_buyers_sum\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.preprocess_coin_df:423] Preprocessed file saved at: ..//modeling/outputs/preprocessed_outputs/buysell_metrics_0.1_2024-09-14_12-50_model_period_2024-03-01_preprocessed.csv\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.preprocess_coin_df:424] Dropped 1 columns: buyers_new_median\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.create_training_data_df:536] 1 files were successfully merged.\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.create_training_data_df:540] All specified files were found and merged successfully.\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.create_target_variables_mooncrater:618] Target variables created for 265 coins with 122/265 (46.0%) moons and 24/265 (9.1%) craters.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "importlib.reload(m) \n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/config_metrics.yaml')\n",
    "modeling_config = load_config('../config/config_modeling.yaml')\n",
    "\n",
    "\n",
    "# identify sharks\n",
    "shark_coins_df = td.classify_shark_coins(profits_df, config['training_data'])\n",
    "shark_wallets_df = td.classify_shark_wallets(shark_coins_df,config['training_data'])\n",
    "\n",
    "# generate and flatten buysell_metrics\n",
    "cohort_wallets = shark_wallets_df[shark_wallets_df['is_shark']==True]['wallet_address'].unique()\n",
    "cohort_coins = shark_coins_df['coin_id'].unique()\n",
    "buysell_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets,cohort_coins)\n",
    "\n",
    "# flatten, save, and preprocess the flattened df\n",
    "output_directory = '..//modeling/outputs/flattened_outputs/'\n",
    "metric_description = 'buysell_metrics'\n",
    "modeling_period_start = config['training_data']['modeling_period_start']\n",
    "version = '0.1'\n",
    "\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(buysell_metrics_df,metrics_config,config['training_data']['training_period_end'])\n",
    "flattened_df, flattened_filepath = fe.save_flattened_outputs(flattened_buysell_metrics_df, output_directory, metric_description, modeling_period_start, version)\n",
    "preprocessed_df, preprocessed_filepath = fe.preprocess_coin_df(flattened_filepath, modeling_config, metrics_config)\n",
    "\n",
    "# create the training data df\n",
    "input_directory = f\"{preprocessed_filepath.split('preprocessed_outputs/')[0]}preprocessed_outputs/\"\n",
    "input_filenames = [\n",
    "    preprocessed_filepath.split('preprocessed_outputs/')[1]\n",
    "]\n",
    "training_data_df = fe.create_training_data_df(input_directory, input_filenames)\n",
    "\n",
    "# create the target variable df\n",
    "target_variable_df,_ = fe.create_target_variables_mooncrater(prices_df, config['training_data'], modeling_config)\n",
    "\n",
    "# merge the two into the final model input df\n",
    "model_input_df = fe.prepare_model_input_df(training_data_df, target_variable_df, modeling_config['modeling']['target_column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6111111111111112,\n",
       " 'precision': np.float64(0.5833333333333334),\n",
       " 'recall': np.float64(0.7777777777777778),\n",
       " 'f1_score': np.float64(0.6666666666666666),\n",
       " 'roc_auc': np.float64(0.6419753086419753),\n",
       " 'log_loss': 0.6697705414644598}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "importlib.reload(m) \n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/config_metrics.yaml')\n",
    "modeling_config = load_config('../config/config_modeling.yaml')\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "\n",
    "model_input_df.shape\n",
    "\n",
    "# split train/test sets\n",
    "X_train,X_test,y_train,y_test = m.split_model_input(model_input_df, modeling_config['modeling']['target_column'], test_size=0.2, random_state=42)\n",
    "\n",
    "# # train model\n",
    "model, model_id = m.train_model(X_train, y_train, modeling_folder, model_params=None)\n",
    "\n",
    "# evaluate model\n",
    "metrics_dict = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
    "\n",
    "# log experiment results\n",
    "experiment_log = m.log_experiment_results(modeling_folder, model_id)\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Regex pattern did not match.\n Regex: 'y_train or y_test contains only one class'\n Input: 'Target is heavily imbalanced. Consider rebalancing or using specialized techniques.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pytest\u001b[38;5;241m.\u001b[39mraises(\u001b[38;5;167;01mValueError\u001b[39;00m, match\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train or y_test contains only one class\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_model_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DreamsData/GitHub/data-science/notebooks/..//src/modeling.py:72\u001b[0m, in \u001b[0;36msplit_model_input\u001b[0;34m(model_input_df, target_column, test_size, random_state)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.95\u001b[39m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is heavily imbalanced. Consider rebalancing or using specialized techniques.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Check for non-numeric features\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Target is heavily imbalanced. Consider rebalancing or using specialized techniques.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a DataFrame where the target has only one class and 10 rows\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m create_dataframe({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature1\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature2\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m13\u001b[39m]}, [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpytest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraises\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mValueError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_train or y_test contains only one class\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_model_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/_pytest/_code/code.py:728\u001b[0m, in \u001b[0;36mExceptionInfo.match\u001b[0;34m(self, regexp)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regexp \u001b[38;5;241m==\u001b[39m value:\n\u001b[1;32m    727\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Did you mean to `re.escape()` the regex?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 728\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(regexp, value), msg\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Return True to allow for \"assert excinfo.match()\".\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Regex pattern did not match.\n Regex: 'y_train or y_test contains only one class'\n Input: 'Target is heavily imbalanced. Consider rebalancing or using specialized techniques.'"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "importlib.reload(m) \n",
    "\n",
    "# Create a DataFrame where the target has only one class and 10 rows\n",
    "data = create_dataframe({'feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'feature2': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]}, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "with pytest.raises(ValueError, match=\"y_train or y_test contains only one class\"):\n",
    "    m.split_model_input(data, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  target\n",
       "0         1         4       0\n",
       "1         2         5       1\n",
       "2         3         6       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# import local files if necessary\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "\n",
    "# load configs\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/config_metrics.yaml')\n",
    "modeling_config = load_config('../config/config_modeling.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m modeling_config \u001b[38;5;241m=\u001b[39m load_config(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../config/config_modeling.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m modeling_folder \u001b[38;5;241m=\u001b[39m modeling_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodeling\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodeling_folder\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_experiment_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodeling_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DreamsData/GitHub/data-science/notebooks/..//src/modeling.py:199\u001b[0m, in \u001b[0;36mlog_experiment_results\u001b[0;34m(modeling_folder, model_id)\u001b[0m\n\u001b[1;32m    197\u001b[0m         lines \u001b[38;5;241m=\u001b[39m log_file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m--> 199\u001b[0m             key, value \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m             experiment_log[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "importlib.reload(m) \n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/config_metrics.yaml')\n",
    "modeling_config = load_config('../config/config_modeling.yaml')\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "\n",
    "\n",
    "m.log_experiment_results(modeling_folder, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_input_df():\n",
    "    \"\"\"\n",
    "    Creates a mock DataFrame and saves it as a CSV for testing.\n",
    "    The CSV file is saved in the 'tests/test_modeling/outputs/flattened_outputs' directory.\n",
    "    \n",
    "    Returns:\n",
    "    - input_path: Path to the CSV file.\n",
    "    - df: Original mock DataFrame.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'feature_1_sum': [1, 2, 3],\n",
    "        'feature_to_drop': [10, 20, 30],\n",
    "        'feature_3': [100, 200, 300]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    input_path = 'temp/mock_input.csv'\n",
    "    df.to_csv(input_path, index=False)\n",
    "    return input_path, df\n",
    "\n",
    "\n",
    "\n",
    "def mock_modeling_config():\n",
    "    \"\"\"\n",
    "    Returns a mock modeling configuration dictionary.\n",
    "    The configuration includes preprocessing options such as features to drop.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'preprocessing': {\n",
    "            'drop_features': ['feature_to_drop']\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def mock_metrics_config():\n",
    "    \"\"\"\n",
    "    Returns a mock metrics configuration dictionary.\n",
    "    This configuration includes settings for scaling different features.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'metrics': {\n",
    "            'feature_1': {\n",
    "                'aggregations': {\n",
    "                    'sum': {'scaling': 'standard'}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "input_path, df  = mock_input_df()\n",
    "mock_modeling_config = mock_modeling_config()\n",
    "mock_metrics_config = mock_metrics_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1_sum</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.22474487139</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.22474487139</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1_sum  feature_3\n",
       "0 -1.22474487139        100\n",
       "1              0        200\n",
       "2  1.22474487139        300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13/Sep/2024 22:43:46] INFO [dreams_core.core.preprocess_coin_df:422] Preprocessed file saved at: temp/mock_input_preprocessed.csv\n",
      "[13/Sep/2024 22:43:46] INFO [dreams_core.core.preprocess_coin_df:423] Dropped 1 columns: feature_to_drop\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(fe) \n",
    "\n",
    "# def test_preprocess_coin_df_scaling(mock_modeling_config, mock_metrics_config, mock_input_df):\n",
    "\"\"\"\n",
    "Tests that the preprocess_coin_df function correctly applies scaling to the specified features.\n",
    "\n",
    "Steps:\n",
    "- Preprocesses the mock DataFrame by applying standard scaling to 'feature_1'.\n",
    "- Asserts that the column is scaled correctly.\n",
    "- Cleans up the test files after execution.\n",
    "\"\"\"\n",
    "input_path, original_df = mock_input_df()\n",
    "\n",
    "# Call the function\n",
    "output_df, output_path = fe.preprocess_coin_df(input_path, mock_modeling_config, mock_metrics_config)\n",
    "\n",
    "\n",
    "# Check that 'feature_1' is scaled (mean should be near 0 and std should be near 1)\n",
    "scaled_column = output_df['feature_1_sum']\n",
    "assert abs(scaled_column.mean()) < 1e-6, \"Standard scaling not applied correctly to 'feature_1_sum'.\"\n",
    "assert abs(np.std(scaled_column) - 1) < 1e-6, \"Standard scaling not applied correctly to 'feature_1_sum'.\"\n",
    "\n",
    "# # Cleanup (remove the test files)\n",
    "# os.remove(output_path)\n",
    "# os.remove(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22474487139158894)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_column = output_df['feature_1_sum']\n",
    "# abs(scaled_column.mean())\n",
    "abs(scaled_column.std() - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1.22474487139\n",
       "1                0\n",
       "2    1.22474487139\n",
       "Name: feature_1_sum, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1_sum</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.22474487139</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.22474487139</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.612372435696</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.612372435696</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.22474487139</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_1_sum  feature_3\n",
       "count               3          3\n",
       "mean                0        200\n",
       "std     1.22474487139        100\n",
       "min    -1.22474487139        100\n",
       "25%   -0.612372435696        150\n",
       "50%                 0        200\n",
       "75%    0.612372435696        250\n",
       "max     1.22474487139        300"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22474487139158894)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_column.std() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22474487,  0.        ,  1.22474487])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_array = StandardScaler().fit_transform([[1], [2], [3]]).flatten()\n",
    "scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: metrics\n",
      "setting: {'buyers_new': {'aggregations': {'sum': {'scaling': 'standard'}, 'mean': {'scaling': 'minmax'}, 'std': {'scaling': 'standard'}}, 'rolling': {'stats': {'sum': {'scaling': 'minmax'}, 'max': {'scaling': 'standard'}}, 'comparisons': {'change': {'scaling': 'standard'}, 'pct_change': {'scaling': 'None'}}, 'window_duration': 7, 'lookback_periods': 8}}, 'total_bought': {'aggregations': {'sum': {'scaling': 'standard'}, 'median': {'scaling': 'None'}}, 'rolling': {'stats': {'sum': {'scaling': 'minmax'}}, 'comparisons': {'change': {'scaling': 'standard'}}, 'window_duration': 7, 'lookback_periods': 8}}, 'total_sold': {'aggregations': {'sum': {'scaling': 'standard'}}}, 'total_buyers': {'aggregations': {'sum': {'scaling': 'None'}}}}\n"
     ]
    }
   ],
   "source": [
    "for metric, settings in metrics_config.items():\n",
    "    print(f'metric: {metric}')\n",
    "    print(f'setting: {settings}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('metrics', {'buyers_new': {'aggregations': {'sum': {'scaling': 'standard'}, 'mean': {'scaling': 'minmax'}, 'std': {'scaling': 'standard'}}, 'rolling': {'stats': {'sum': {'scaling': 'minmax'}, 'max': {'scaling': 'standard'}}, 'comparisons': {'change': {'scaling': 'standard'}, 'pct_change': {'scaling': 'None'}}, 'window_duration': 7, 'lookback_periods': 8}}, 'total_bought': {'aggregations': {'sum': {'scaling': 'standard'}, 'median': {'scaling': 'None'}}, 'rolling': {'stats': {'sum': {'scaling': 'minmax'}}, 'comparisons': {'change': {'scaling': 'standard'}}, 'window_duration': 7, 'lookback_periods': 8}}, 'total_sold': {'aggregations': {'sum': {'scaling': 'standard'}}}, 'total_buyers': {'aggregations': {'sum': {'scaling': 'None'}}}})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_config.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.816496580927726)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Original array [1, 2, 3]\n",
    "std_original = np.std([1, 2, 3])\n",
    "\n",
    "# Scaled array [-1.2247, 0, 1.2247]\n",
    "scaled_array = [-1.22474487, 0, 1.22474487]\n",
    "std_scaled = np.std(scaled_array)\n",
    "\n",
    "std_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "1.224744871391589\n"
     ]
    }
   ],
   "source": [
    "print(np.std(scaled_column))\n",
    "\n",
    "print(scaled_column.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'std'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscaled_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'std'"
     ]
    }
   ],
   "source": [
    "scaled_array.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
