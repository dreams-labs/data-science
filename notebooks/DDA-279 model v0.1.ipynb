{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# import local files if necessary\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "\n",
    "# load configs\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14/Sep/2024 12:25:53] INFO [dreams_core.core.retrieve_prices_data:42] retrieved prices data with shape (120763, 3)\n",
      "[14/Sep/2024 12:25:53] INFO [dreams_core.core.fill_prices_gaps:126] 382 coins had no gaps, 19 coins had gaps filled, and 38 coins were dropped due to large gaps.\n",
      "[14/Sep/2024 12:27:08] INFO [dreams_core.core.retrieve_transfers_data:333] retrieved transfers_df with shape (35657183, 5) after 74.9 seconds.\n",
      "[14/Sep/2024 12:27:08] INFO [dreams_core.core.prepare_profits_data:374] Preparing profits_df data...\n",
      "[14/Sep/2024 12:28:31] INFO [dreams_core.core.calculate_wallet_profitability:554] Generated profits df after 36.06 seconds\n",
      "[14/Sep/2024 12:29:09] INFO [dreams_core.core.clean_profits_df:625] Finished cleaning profits_df after 38.51 seconds.\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# retrieve and clean prices data\n",
    "prices_df = td.retrieve_prices_data()\n",
    "prices_df,_ = td.fill_prices_gaps(prices_df,config['data_cleaning']['max_gap_days'])\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14/Sep/2024 12:50:11] INFO [dreams_core.core.classify_shark_coins:691] creation of shark_coins_df complete.\n",
      "[14/Sep/2024 12:50:11] INFO [dreams_core.core.generate_buysell_metrics_df:33] Preparing buysell_metrics_df...\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.generate_buysell_metrics_df:99] Generated buysell_metrics_df after 3.49 seconds.\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.flatten_coin_date_df:84] Flattening columns ['buyers_new', 'total_bought', 'total_sold', 'total_buyers'] into coin-level features...\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.flatten_coin_date_df:100] Flattened input df into coin-level features with shape (89, 57) after 0.10 seconds.\n",
      "[14/Sep/2024 12:50:15] WARNING [dreams_core.core.preprocess_coin_df:412] Unknown scaling method None for column total_bought_median\n",
      "[14/Sep/2024 12:50:15] WARNING [dreams_core.core.preprocess_coin_df:412] Unknown scaling method None for column total_buyers_sum\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.preprocess_coin_df:423] Preprocessed file saved at: ..//modeling/outputs/preprocessed_outputs/buysell_metrics_0.1_2024-09-14_12-50_model_period_2024-03-01_preprocessed.csv\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.preprocess_coin_df:424] Dropped 1 columns: buyers_new_median\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.create_training_data_df:536] 1 files were successfully merged.\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.create_training_data_df:540] All specified files were found and merged successfully.\n",
      "[14/Sep/2024 12:50:15] INFO [dreams_core.core.create_target_variables_mooncrater:618] Target variables created for 265 coins with 122/265 (46.0%) moons and 24/265 (9.1%) craters.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "importlib.reload(m) \n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "\n",
    "\n",
    "\n",
    "# identify sharks\n",
    "shark_coins_df = td.classify_shark_coins(profits_df, config['training_data'])\n",
    "shark_wallets_df = td.classify_shark_wallets(shark_coins_df,config['training_data'])\n",
    "\n",
    "# generate and flatten buysell_metrics\n",
    "cohort_wallets = shark_wallets_df[shark_wallets_df['is_shark']==True]['wallet_address'].unique()\n",
    "cohort_coins = shark_coins_df['coin_id'].unique()\n",
    "buysell_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets,cohort_coins)\n",
    "\n",
    "# flatten, save, and preprocess the flattened df\n",
    "output_directory = '..//modeling/outputs/flattened_outputs/'\n",
    "metric_description = 'buysell_metrics'\n",
    "modeling_period_start = config['training_data']['modeling_period_start']\n",
    "version = '0.1'\n",
    "\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(buysell_metrics_df,metrics_config,config['training_data']['training_period_end'])\n",
    "flattened_df, flattened_filepath = fe.save_flattened_outputs(flattened_buysell_metrics_df, output_directory, metric_description, modeling_period_start, version)\n",
    "preprocessed_df, preprocessed_filepath = fe.preprocess_coin_df(flattened_filepath, modeling_config, metrics_config)\n",
    "\n",
    "# create the training data df\n",
    "input_directory = f\"{preprocessed_filepath.split('preprocessed_outputs/')[0]}preprocessed_outputs/\"\n",
    "input_filenames = [\n",
    "    preprocessed_filepath.split('preprocessed_outputs/')[1]\n",
    "]\n",
    "training_data_df = fe.create_training_data_df(input_directory, input_filenames)\n",
    "\n",
    "# create the target variable df\n",
    "target_variable_df,_ = fe.create_target_variables_mooncrater(prices_df, config['training_data'], modeling_config)\n",
    "\n",
    "# merge the two into the final model input df\n",
    "model_input_df = fe.prepare_model_input_df(training_data_df, target_variable_df, modeling_config['modeling']['target_column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14/Sep/2024 13:44:39] INFO [dreams_core.core.split_model_input:84] y_train: 40/71 positives, y_test: 9/18 positives\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6111111111111112,\n",
       " 'precision': np.float64(0.5833333333333334),\n",
       " 'recall': np.float64(0.7777777777777778),\n",
       " 'f1_score': np.float64(0.6666666666666666),\n",
       " 'roc_auc': np.float64(0.6419753086419753),\n",
       " 'log_loss': 0.6697705414644598}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "importlib.reload(m)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "\n",
    "model_input_df.shape\n",
    "\n",
    "# split train/test sets\n",
    "X_train,X_test,y_train,y_test = m.split_model_input(model_input_df, modeling_config['modeling']['target_column'], test_size=0.2, random_state=42)\n",
    "\n",
    "# # train model\n",
    "model, model_id = m.train_model(X_train, y_train, modeling_folder, model_params=None)\n",
    "\n",
    "# evaluate model\n",
    "metrics_dict = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
    "\n",
    "# log experiment results\n",
    "experiment_log = m.log_experiment_results(modeling_folder, model_id)\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model ID': '3a3daba4-51bf-4b06-90f5-0361ac235081',\n",
       " 'Model parameters': {'n_estimators': 100, 'random_state': 42},\n",
       " 'accuracy': 0.6111111111111112,\n",
       " 'precision': 0.5833333333333334,\n",
       " 'recall': 0.7777777777777778,\n",
       " 'f1_score': 0.6666666666666666,\n",
       " 'roc_auc': 0.6419753086419753,\n",
       " 'log_loss': 0.6697705414644598,\n",
       " 'feature_importance': '..//modeling/outputs/feature_importance/feature_importance_3a3daba4-51bf-4b06-90f5-0361ac235081.csv'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config_folder = '../config'\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "\n",
    "\n",
    "m.log_experiment_results(modeling_folder, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "config_modeling.yaml not found in ../config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(i)\n\u001b[0;32m----> 4\u001b[0m configurations \u001b[38;5;241m=\u001b[39m \u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_experiment_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DreamsData/GitHub/data-science/notebooks/..//src/insights.py:109\u001b[0m, in \u001b[0;36mgenerate_experiment_configurations\u001b[0;34m(config_folder, method, max_evals)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03mGenerates experiment configurations based on the validated experiment config YAML file and the search method.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m- configurations (list): List of generated configurations.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Load and validate the experiment configuration\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_experiments_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Flatten the experiment configuration into a dictionary that can be used for grid/random search\u001b[39;00m\n\u001b[1;32m    112\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/DreamsData/GitHub/data-science/notebooks/..//src/insights.py:49\u001b[0m, in \u001b[0;36mvalidate_experiments_yaml\u001b[0;34m(config_folder)\u001b[0m\n\u001b[1;32m     47\u001b[0m         loaded_configs[section] \u001b[38;5;241m=\u001b[39m load_config(file_path)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Validate that each variable in experiment_config maps correctly to the loaded config files\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m section, section_values \u001b[38;5;129;01min\u001b[39;00m experiment_config\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: config_modeling.yaml not found in ../config"
     ]
    }
   ],
   "source": [
    "importlib.reload(i)\n",
    "\n",
    "\n",
    "configurations = i.generate_experiment_configurations(config_folder, method='grid', max_evals=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "importlib.reload(m) \n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "\n",
    "\n",
    "# retrieve and clean prices data\n",
    "prices_df = td.retrieve_prices_data()\n",
    "prices_df,_ = td.fill_prices_gaps(prices_df,config['data_cleaning']['max_gap_days'])\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n",
    "# identify sharks\n",
    "shark_coins_df = td.classify_shark_coins(profits_df, config['training_data'])\n",
    "shark_wallets_df = td.classify_shark_wallets(shark_coins_df,config['training_data'])\n",
    "\n",
    "# generate and flatten buysell_metrics\n",
    "cohort_wallets = shark_wallets_df[shark_wallets_df['is_shark']==True]['wallet_address'].unique()\n",
    "cohort_coins = shark_coins_df['coin_id'].unique()\n",
    "buysell_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets,cohort_coins)\n",
    "\n",
    "# flatten, save, and preprocess the flattened df\n",
    "output_directory = '..//modeling/outputs/flattened_outputs/'\n",
    "metric_description = 'buysell_metrics'\n",
    "modeling_period_start = config['training_data']['modeling_period_start']\n",
    "version = '0.1'\n",
    "\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(buysell_metrics_df,metrics_config,config['training_data']['training_period_end'])\n",
    "flattened_df, flattened_filepath = fe.save_flattened_outputs(flattened_buysell_metrics_df, output_directory, metric_description, modeling_period_start, version)\n",
    "preprocessed_df, preprocessed_filepath = fe.preprocess_coin_df(flattened_filepath, modeling_config, metrics_config)\n",
    "\n",
    "# create the training data df\n",
    "input_directory = f\"{preprocessed_filepath.split('preprocessed_outputs/')[0]}preprocessed_outputs/\"\n",
    "input_filenames = [\n",
    "    preprocessed_filepath.split('preprocessed_outputs/')[1]\n",
    "]\n",
    "training_data_df = fe.create_training_data_df(input_directory, input_filenames)\n",
    "\n",
    "# create the target variable df\n",
    "target_variable_df,_ = fe.create_target_variables_mooncrater(prices_df, config['training_data'], modeling_config)\n",
    "\n",
    "# merge the two into the final model input df\n",
    "model_input_df = fe.prepare_model_input_df(training_data_df, target_variable_df, modeling_config['modeling']['target_column'])\n",
    "\n",
    "# split train/test sets\n",
    "X_train,X_test,y_train,y_test = m.split_model_input(model_input_df, modeling_config['modeling']['target_column'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
