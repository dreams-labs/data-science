{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# import local files if necessary\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "import modeling as m\n",
    "importlib.reload(m)\n",
    "import insights as i\n",
    "importlib.reload(i)\n",
    "\n",
    "# load configs\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data (profits_df) Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15/Sep/2024 01:03:41] INFO [dreams_core.core.retrieve_prices_data:42] retrieved prices data with shape (120763, 3)\n",
      "[15/Sep/2024 01:03:41] INFO [dreams_core.core.fill_prices_gaps:126] 382 coins had no gaps, 19 coins had gaps filled, and 38 coins were dropped due to large gaps.\n",
      "[15/Sep/2024 01:04:03] INFO [dreams_core.core.retrieve_transfers_data:333] retrieved transfers_df with shape (15703125, 5) after 21.8 seconds.\n",
      "[15/Sep/2024 01:04:03] INFO [dreams_core.core.prepare_profits_data:374] Preparing profits_df data...\n",
      "[15/Sep/2024 01:04:34] INFO [dreams_core.core.calculate_wallet_profitability:554] Generated profits df after 11.98 seconds\n",
      "[15/Sep/2024 01:04:47] INFO [dreams_core.core.clean_profits_df:625] Finished cleaning profits_df after 12.68 seconds.\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# retrieve and clean prices data\n",
    "prices_df = td.retrieve_prices_data()\n",
    "prices_df,_ = td.fill_prices_gaps(prices_df,config['data_cleaning']['max_gap_days'])\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15/Sep/2024 01:50:47] INFO [dreams_core.core.classify_wallet_cohort:714] Wallet cohort classification complete. 759/68423 eligible wallets were added to the cohort.\n",
      "[15/Sep/2024 01:50:47] INFO [dreams_core.core.generate_buysell_metrics_df:32] Preparing buysell_metrics_df...\n",
      "[15/Sep/2024 01:50:49] INFO [dreams_core.core.generate_buysell_metrics_df:93] Generated buysell_metrics_df after 2.57 seconds.\n",
      "[15/Sep/2024 01:50:50] INFO [dreams_core.core.flatten_coin_date_df:84] Flattening columns ['buyers_new', 'total_bought', 'total_sold', 'total_buyers'] into coin-level features...\n",
      "[15/Sep/2024 01:50:50] INFO [dreams_core.core.flatten_coin_date_df:100] Flattened input df into coin-level features with shape (93, 57) after 0.10 seconds.\n",
      "[15/Sep/2024 01:50:50] WARNING [dreams_core.core.preprocess_coin_df:414] Unknown scaling method none for column total_bought_median\n",
      "[15/Sep/2024 01:50:50] WARNING [dreams_core.core.preprocess_coin_df:414] Unknown scaling method none for column total_buyers_sum\n",
      "[15/Sep/2024 01:50:50] INFO [dreams_core.core.preprocess_coin_df:425] Preprocessed file saved at: ..//modeling/outputs/preprocessed_outputs/sharks_cohort_2024-09-15_01-50_model_period_2024-03-01_preprocessed.csv\n",
      "[15/Sep/2024 01:50:50] INFO [dreams_core.core.create_training_data_df:536] 1 files were successfully merged.\n",
      "[15/Sep/2024 01:50:50] INFO [dreams_core.core.create_training_data_df:540] All specified files were found and merged successfully.\n",
      "[15/Sep/2024 01:50:50] INFO [dreams_core.core.create_target_variables_mooncrater:618] Target variables created for 265 coins with 151/265 (57.0%) moons and 24/265 (9.1%) craters.\n",
      "[15/Sep/2024 01:50:50] INFO [dreams_core.core.split_model_input:84] y_train: 52/74 positives, y_test: 8/19 positives\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = i.build_configured_model_input(profits_df, prices_df, config, metrics_config, modeling_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/outputs/flattened_outputs/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_config[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..//modeling\n",
      "/outputs/flattened_outputs/\n"
     ]
    }
   ],
   "source": [
    "print(modeling_config['modeling']['modeling_folder'])\n",
    "print(os.path.join(modeling_config['modeling']['modeling_folder'],'/outputs/flattened_outputs/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sharks cohort'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_config['modeling']['train_test_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15/Sep/2024 01:04:53] INFO [dreams_core.core.classify_wallet_cohort:714] Wallet cohort classification complete. 759/68423 eligible wallets were added to the cohort.\n",
      "[15/Sep/2024 01:04:53] INFO [dreams_core.core.generate_buysell_metrics_df:32] Preparing buysell_metrics_df...\n",
      "[15/Sep/2024 01:04:56] INFO [dreams_core.core.generate_buysell_metrics_df:93] Generated buysell_metrics_df after 2.60 seconds.\n",
      "[15/Sep/2024 01:04:56] INFO [dreams_core.core.flatten_coin_date_df:84] Flattening columns ['buyers_new', 'buyers_repeat', 'sellers_new', 'sellers_repeat', 'total_bought', 'total_sold', 'total_net_transfers', 'total_holders', 'total_balance'] into coin-level features...\n",
      "[15/Sep/2024 01:04:56] INFO [dreams_core.core.flatten_coin_date_df:100] Flattened input df into coin-level features with shape (93, 204) after 0.24 seconds.\n",
      "[15/Sep/2024 01:04:56] WARNING [dreams_core.core.preprocess_coin_df:412] Unknown scaling method None for column total_net_transfers_median\n",
      "[15/Sep/2024 01:04:56] INFO [dreams_core.core.preprocess_coin_df:423] Preprocessed file saved at: ..//modeling/outputs/preprocessed_outputs/buysell_metrics_0.1_2024-09-15_01-04_model_period_2024-03-01_preprocessed.csv\n",
      "[15/Sep/2024 01:04:56] INFO [dreams_core.core.create_training_data_df:534] 1 files were successfully merged.\n",
      "[15/Sep/2024 01:04:56] INFO [dreams_core.core.create_training_data_df:538] All specified files were found and merged successfully.\n",
      "[15/Sep/2024 01:04:56] INFO [dreams_core.core.create_target_variables_mooncrater:616] Target variables created for 265 coins with 151/265 (57.0%) moons and 24/265 (9.1%) craters.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "\n",
    "\n",
    "# identify cohort\n",
    "cohort_summary_df = td.classify_wallet_cohort(profits_df, config['wallet_cohorts']['sharks'])\n",
    "\n",
    "# generate and flatten buysell_metrics\n",
    "cohort_wallets = cohort_summary_df[cohort_summary_df['in_cohort']==True]['wallet_address']\n",
    "buysell_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets)\n",
    "\n",
    "# flatten, save, and preprocess the flattened df\n",
    "flattened_output_directory = os.path.join(modeling_config['modeling']['modeling_folder'],'/outputs/flattened_outputs/')\n",
    "cohort_name = list(config['wallet_cohorts'].keys())[0]\n",
    "metric_description = f\"{cohort_name}_cohort\"\n",
    "\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(buysell_metrics_df,metrics_config,config['training_data']['training_period_end'])\n",
    "flattened_df, flattened_filepath = fe.save_flattened_outputs(flattened_buysell_metrics_df, flattened_output_directory, metric_description, config['training_data']['modeling_period_start'])\n",
    "preprocessed_df, preprocessed_filepath = fe.preprocess_coin_df(flattened_filepath, modeling_config, metrics_config)\n",
    "\n",
    "# create the training data df\n",
    "input_directory = f\"{preprocessed_filepath.split('preprocessed_outputs/')[0]}preprocessed_outputs/\"\n",
    "input_filenames = [\n",
    "    preprocessed_filepath.split('preprocessed_outputs/')[1]\n",
    "]\n",
    "training_data_df = fe.create_training_data_df(input_directory, input_filenames)\n",
    "\n",
    "# create the target variable df\n",
    "target_variable_df,_ = fe.create_target_variables_mooncrater(prices_df, config['training_data'], modeling_config)\n",
    "\n",
    "# merge the two into the final model input df\n",
    "model_input_df = fe.prepare_model_input_df(training_data_df, target_variable_df, modeling_config['modeling']['target_column'])\n",
    "\n",
    "# split the df into train and test sets\n",
    "X_train, X_test, y_train, y_test = m.split_model_input(\n",
    "    model_input_df,\n",
    "    modeling_config['modeling']['target_column'],\n",
    "    modeling_config['modeling']['train_test_split'],\n",
    "    modeling_config['modeling']['train_test_split']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15/Sep/2024 11:19:24] INFO [dreams_core.core.retrieve_prices_data:42] retrieved prices data with shape (120763, 3)\n",
      "[15/Sep/2024 11:19:24] INFO [dreams_core.core.fill_prices_gaps:126] 382 coins had no gaps, 19 coins had gaps filled, and 38 coins were dropped due to large gaps.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89adaf095c0f4bd8907f27696beaa1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Experiments:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15/Sep/2024 11:19:45] INFO [dreams_core.core.retrieve_transfers_data:333] retrieved transfers_df with shape (15703125, 5) after 20.3 seconds.\n",
      "[15/Sep/2024 11:19:47] INFO [dreams_core.core.retrieve_prices_data:42] retrieved prices data with shape (120763, 3)\n",
      "[15/Sep/2024 11:19:47] INFO [dreams_core.core.fill_prices_gaps:126] 382 coins had no gaps, 19 coins had gaps filled, and 38 coins were dropped due to large gaps.\n",
      "[15/Sep/2024 11:19:48] INFO [dreams_core.core.prepare_profits_data:374] Preparing profits_df data...\n",
      "[15/Sep/2024 11:20:21] INFO [dreams_core.core.calculate_wallet_profitability:554] Generated profits df after 12.43 seconds\n",
      "[15/Sep/2024 11:20:37] INFO [dreams_core.core.clean_profits_df:625] Finished cleaning profits_df after 16.39 seconds.\n",
      "[15/Sep/2024 11:20:44] INFO [dreams_core.core.classify_wallet_cohort:714] Wallet cohort classification complete. 535/29142 eligible wallets were added to the cohort.\n",
      "[15/Sep/2024 11:20:44] INFO [dreams_core.core.generate_buysell_metrics_df:32] Preparing buysell_metrics_df...\n",
      "[15/Sep/2024 11:20:47] INFO [dreams_core.core.generate_buysell_metrics_df:93] Generated buysell_metrics_df after 2.92 seconds.\n",
      "[15/Sep/2024 11:20:47] INFO [dreams_core.core.flatten_coin_date_df:84] Flattening columns ['buyers_new', 'total_bought', 'total_sold', 'total_buyers'] into coin-level features...\n",
      "[15/Sep/2024 11:20:47] INFO [dreams_core.core.flatten_coin_date_df:100] Flattened input df into coin-level features with shape (92, 57) after 0.11 seconds.\n",
      "[15/Sep/2024 11:20:47] WARNING [dreams_core.core.preprocess_coin_df:413] Unknown scaling method None for column total_bought_median\n",
      "[15/Sep/2024 11:20:47] WARNING [dreams_core.core.preprocess_coin_df:413] Unknown scaling method none for column total_buyers_sum\n",
      "[15/Sep/2024 11:20:47] INFO [dreams_core.core.preprocess_coin_df:424] Preprocessed file saved at: ..//modeling/outputs/preprocessed_outputs/sharks_cohort_2024-09-15_11-20_model_period_2024-03-01_preprocessed.csv\n",
      "[15/Sep/2024 11:20:47] INFO [dreams_core.core.create_training_data_df:535] 1 files were successfully merged.\n",
      "[15/Sep/2024 11:20:47] INFO [dreams_core.core.create_training_data_df:539] All specified files were found and merged successfully.\n",
      "[15/Sep/2024 11:20:47] INFO [dreams_core.core.create_target_variables_mooncrater:618] Target variables created for 265 coins with 80/265 (30.2%) moons and 24/265 (9.1%) craters.\n",
      "[15/Sep/2024 11:20:47] INFO [dreams_core.core.split_model_input:84] y_train: 24/73 positives, y_test: 6/19 positives\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'insights' has no attribute 'train_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m modeling_folder \u001b[38;5;241m=\u001b[39m modeling_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodeling\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodeling_folder\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     68\u001b[0m max_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 69\u001b[0m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodeling_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 49\u001b[0m, in \u001b[0;36mrun_experiments\u001b[0;34m(method, config_folder, modeling_folder, max_evals)\u001b[0m\n\u001b[1;32m     46\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mbuild_configured_model_input(profits_df, prices_df, config, metrics_config, modeling_config)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# 2.4 Train the model using the current configuration and log the results\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m model, model_id \u001b[38;5;241m=\u001b[39m \u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m(X_train, y_train, modeling_folder, modeling_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# 2.5 Evaluate the model's performance on the test set\u001b[39;00m\n\u001b[1;32m     52\u001b[0m metrics \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mevaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'insights' has no attribute 'train_model'"
     ]
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe)\n",
    "importlib.reload(m)\n",
    "importlib.reload(i)\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/metrics_config.yaml')\n",
    "modeling_config = load_config('../config/modeling_config.yaml')\n",
    "experiments_config = load_config('../config/experiments_config.yaml')\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def run_experiments(method, config_folder, modeling_folder, max_evals=50):\n",
    "    \"\"\"\n",
    "    Runs experiments using a specified search method (grid or random), builds models,\n",
    "    and logs the results of each experiment.\n",
    "\n",
    "    Args:\n",
    "    - method (str): 'grid' or 'random' to select the search method.\n",
    "    - config_folder (str): Path to the folder containing all configuration files.\n",
    "    - modeling_folder (str): Path to the folder where models, logs, and results will be saved.\n",
    "    - max_evals (int): Number of iterations for Random search (default is 50).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Generate the experiment configurations\n",
    "    experiment_configurations = i.generate_experiment_configurations(config_folder, method=method, max_evals=max_evals)\n",
    "\n",
    "    # Generate prices_df\n",
    "    config = load_config(os.path.join(config_folder,'config.yaml'))\n",
    "    prices_df = td.retrieve_prices_data()\n",
    "    prices_df,_ = td.fill_prices_gaps(prices_df,config['data_cleaning']['max_gap_days'])\n",
    "\n",
    "    # 2. Iterate through each configuration with a progress bar\n",
    "    with tqdm(total=len(experiment_configurations), desc=\"Running Experiments\") as pbar:\n",
    "        for experiment in experiment_configurations:\n",
    "            \n",
    "            # 2.1 Prepare the full configuration by applying overrides from the current experiment config\n",
    "            config, metrics_config, modeling_config = i.prepare_configs(config_folder, experiment)\n",
    "            \n",
    "            # 2.2 Retrieve or rebuild profits_df based on config changes\n",
    "            profits_df = i.rebuild_profits_df_if_necessary(config, modeling_folder)\n",
    "            \n",
    "            # 2.3 Build the configured model input data (train/test data)\n",
    "            X_train, X_test, y_train, y_test = i.build_configured_model_input(profits_df, prices_df, config, metrics_config, modeling_config)\n",
    "\n",
    "            # 2.4 Train the model using the current configuration and log the results\n",
    "            model, model_id = m.train_model(X_train, y_train, modeling_folder, modeling_config['hyperparameters'])\n",
    "            \n",
    "            # 2.5 Evaluate the model's performance on the test set\n",
    "            metrics = m.evaluate_model(model, X_test, y_test, model_id, modeling_folder)\n",
    "\n",
    "            # 2.6 Log the experiment results for this configuration\n",
    "            m.log_experiment_results(modeling_folder, model_id, config, metrics)\n",
    "\n",
    "            # Update the progress bar after each experiment\n",
    "            pbar.update(1)\n",
    "\n",
    "\n",
    "    # 3. Compare all experiments and analyze the best-performing configuration\n",
    "    i.analyze_experiments(modeling_folder)\n",
    "\n",
    "\n",
    "method = 'random'\n",
    "config_folder = '../config'\n",
    "modeling_folder = modeling_config['modeling']['modeling_folder']\n",
    "max_evals = 10\n",
    "run_experiments(method, config_folder, modeling_folder, max_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modeling_config.target_variables.moon_threshold': 0.3,\n",
       " 'modeling_config.preprocessing.drop_features': ['total_sellers_sum',\n",
       "  'buyers_new_median'],\n",
       " 'metrics_config.metrics.total_bought.aggregations.sum.scaling': 'standard',\n",
       " 'metrics_config.metrics.total_bought.aggregations.median.scaling': 'None',\n",
       " 'metrics_config.metrics.buyers_new.aggregations.sum.scaling': 'minmax',\n",
       " 'metrics_config.metrics.buyers_new.aggregations.mean.scaling': 'minmax',\n",
       " 'config.wallet_cohorts.sharks.wallet_minimum_inflows': 10000,\n",
       " 'config.wallet_cohorts.sharks.wallet_min_coin_wins': 3,\n",
       " 'config.wallet_cohorts.sharks.wallet_maximum_inflows': 100000,\n",
       " 'config.wallet_cohorts.sharks.coin_return_win_threshold': 0.75,\n",
       " 'config.wallet_cohorts.sharks.coin_profits_win_threshold': 5000,\n",
       " 'config.training_data.training_period_duration': 180,\n",
       " 'config.training_data.modeling_period_duration': 14,\n",
       " 'config.data_cleaning.profitability_filter': 15000000,\n",
       " 'config.data_cleaning.inflows_filter': 10000000}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_configurations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Identify cohort of wallets (e.g., sharks) based on the cohort classification logic\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cohort_summary_df \u001b[38;5;241m=\u001b[39m \u001b[43mtd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify_wallet_cohort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofits_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwallet_cohorts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msharks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of cohort_summary_df: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcohort_summary_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 2. Generate buysell metrics for wallets in the identified cohort\u001b[39;00m\n",
      "File \u001b[0;32m~/DreamsData/GitHub/data-science/notebooks/..//src/training_data.py:698\u001b[0m, in \u001b[0;36mclassify_wallet_cohort\u001b[0;34m(profits_df, wallet_cohort_config)\u001b[0m\n\u001b[1;32m    695\u001b[0m wallet_cohort_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinning_coins\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m wallet_cohort_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinning_coins\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    697\u001b[0m \u001b[38;5;66;03m# Calculate total profits (USD value)\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m wallet_profits_df \u001b[38;5;241m=\u001b[39m \u001b[43mprofits_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwallet_address\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprofits_cumulative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m    699\u001b[0m wallet_profits_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwallet_address\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_profits\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# Calculate return rate: total profits / total inflows\u001b[39;00m\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:3146\u001b[0m, in \u001b[0;36mGroupBy.sum\u001b[0;34m(self, numeric_only, min_count, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   3141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3142\u001b[0m     \u001b[38;5;66;03m# If we are grouping on categoricals we want unobserved categories to\u001b[39;00m\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# return zero, rather than the default of NaN which the reindexing in\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# _agg_general() returns. GH #31422\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobserved\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 3146\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3149\u001b[0m \u001b[43m            \u001b[49m\u001b[43malias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnpfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3151\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_output(result, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1906\u001b[0m, in \u001b[0;36mGroupBy._agg_general\u001b[0;34m(self, numeric_only, min_count, alias, npfunc, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_agg_general\u001b[39m(\n\u001b[1;32m   1898\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1904\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1905\u001b[0m ):\n\u001b[0;32m-> 1906\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/internals/base.py:367\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[1;32m    366\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[0;32m--> 367\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[1;32m    370\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1973\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_func\u001b[39m(values: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1973\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1974\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maggregate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1976\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1977\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1978\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1979\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1980\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1981\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1982\u001b[0m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1983\u001b[0m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1985\u001b[0m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m         \u001b[38;5;66;03m# TODO: avoid special casing SparseArray here\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, SparseArray):\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/ops.py:827\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;124;03mReturns the values of a cython operation.\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 827\u001b[0m cy_op \u001b[38;5;241m=\u001b[39m WrappedCythonOp(kind\u001b[38;5;241m=\u001b[39mkind, how\u001b[38;5;241m=\u001b[39mhow, has_dropped_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_dropped_na\u001b[49m)\n\u001b[1;32m    829\u001b[0m ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[1;32m    830\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/ops.py:741\u001b[0m, in \u001b[0;36mBaseGrouper.has_dropped_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_dropped_na\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    738\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03m    Whether grouper has null value(s) that are dropped.\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_info\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many())\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/ops.py:745\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 745\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[1;32m    748\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/ops.py:769\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# FIXME: compress_group_index's second return value is int64, not intp\u001b[39;00m\n\u001b[1;32m    768\u001b[0m ping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_group_index), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:691\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]:\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:835\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uniques\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dropna\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[1;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[0;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[1;32m    803\u001b[0m         uniques,\n\u001b[1;32m    804\u001b[0m         codes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    808\u001b[0m     )\n",
      "File \u001b[0;32m~/DreamsData/.venv/lib/python3.11/site-packages/pandas/core/algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[0;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[1;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Identify cohort of wallets (e.g., sharks) based on the cohort classification logic\n",
    "cohort_summary_df = td.classify_wallet_cohort(profits_df, config['wallet_cohorts']['sharks'])\n",
    "print(f\"Shape of cohort_summary_df: {cohort_summary_df.shape}\")\n",
    "\n",
    "# 2. Generate buysell metrics for wallets in the identified cohort\n",
    "cohort_wallets = cohort_summary_df[cohort_summary_df['in_cohort']]['wallet_address']\n",
    "buysell_metrics_df = cwm.generate_buysell_metrics_df(\n",
    "    profits_df,\n",
    "    config['training_data']['training_period_end'],\n",
    "    cohort_wallets\n",
    ")\n",
    "print(f\"Shape of buysell_metrics_df: {buysell_metrics_df.shape}\")\n",
    "\n",
    "# 3. Flatten the buysell metrics DataFrame, save it, and preprocess it\n",
    "flattened_output_directory = os.path.join(\n",
    "    modeling_config['modeling']['modeling_folder'],\n",
    "    'outputs/flattened_outputs/'\n",
    ")\n",
    "cohort_name = list(config['wallet_cohorts'].keys())[0]\n",
    "metric_description = f\"{cohort_name}_cohort\"\n",
    "\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(\n",
    "    buysell_metrics_df,\n",
    "    metrics_config,\n",
    "    config['training_data']['training_period_end']\n",
    ")\n",
    "print(f\"Shape of flattened_buysell_metrics_df: {flattened_buysell_metrics_df.shape}\")\n",
    "\n",
    "# Save flattened outputs\n",
    "flattened_buysell_metrics_df, flattened_filepath = fe.save_flattened_outputs(\n",
    "    flattened_buysell_metrics_df,\n",
    "    flattened_output_directory,\n",
    "    metric_description,\n",
    "    config['training_data']['modeling_period_start']\n",
    ")\n",
    "print(f\"Shape of flattened_buysell_metrics_df after saving: {flattened_buysell_metrics_df.shape}\")\n",
    "print(f\"Flattened outputs saved at: {flattened_filepath}\")\n",
    "\n",
    "# Preprocess the flattened DataFrame\n",
    "preprocessed_df, preprocessed_filepath = fe.preprocess_coin_df(\n",
    "    flattened_filepath,\n",
    "    modeling_config,\n",
    "    metrics_config\n",
    ")\n",
    "print(f\"Shape of preprocessed_df: {preprocessed_df.shape}\")\n",
    "print(f\"Preprocessed outputs saved at: {preprocessed_filepath}\")\n",
    "\n",
    "# 4. Create training data from the preprocessed DataFrame\n",
    "input_directory = f\"{preprocessed_filepath.split('preprocessed_outputs/')[0]}preprocessed_outputs/\"\n",
    "input_filenames = [preprocessed_filepath.split('preprocessed_outputs/')[1]]\n",
    "training_data_df = fe.create_training_data_df(input_directory, input_filenames)\n",
    "print(f\"Shape of training_data_df: {training_data_df.shape}\")\n",
    "\n",
    "# 5. Create the target variable DataFrame based on price changes\n",
    "target_variable_df, _ = fe.create_target_variables_mooncrater(\n",
    "    prices_df,\n",
    "    config['training_data'],\n",
    "    modeling_config\n",
    ")\n",
    "print(f\"Shape of target_variable_df: {target_variable_df.shape}\")\n",
    "\n",
    "# 6. Merge the training data with the target variables to create the model input DataFrame\n",
    "model_input_df = fe.prepare_model_input_df(\n",
    "    training_data_df,\n",
    "    target_variable_df,\n",
    "    modeling_config['modeling']['target_column']\n",
    ")\n",
    "print(f\"Shape of model_input_df: {model_input_df.shape}\")\n",
    "\n",
    "# 7. Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = m.split_model_input(\n",
    "    model_input_df,\n",
    "    modeling_config['modeling']['target_column'],\n",
    "    modeling_config['modeling']['train_test_split'],\n",
    "    modeling_config['modeling']['random_state']\n",
    ")\n",
    "print(f\"Shapes of X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
