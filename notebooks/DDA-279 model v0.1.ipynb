{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import yaml\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# import local files if necessary\n",
    "sys.path.append('..//src')\n",
    "from utils import load_config, cw_filter_df\n",
    "import training_data as td\n",
    "importlib.reload(td)\n",
    "import feature_engineering as fe\n",
    "importlib.reload(fe)\n",
    "import coin_wallet_metrics as cwm\n",
    "importlib.reload(cwm)\n",
    "\n",
    "# load configs\n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/config_metrics.yaml')\n",
    "modeling_config = load_config('../config/config_modeling.yaml')\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Custom format function for displaying numbers\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/config_metrics.yaml')\n",
    "modeling_config = load_config('../config/config_modeling.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data and Metrics Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13/Sep/2024 21:54:12] INFO [dreams_core.core.retrieve_prices_data:42] retrieved prices data with shape (120763, 3)\n",
      "[13/Sep/2024 21:54:13] INFO [dreams_core.core.fill_prices_gaps:126] 382 coins had no gaps, 19 coins had gaps filled, and 38 coins were dropped due to large gaps.\n",
      "[13/Sep/2024 21:54:43] INFO [dreams_core.core.retrieve_transfers_data:333] retrieved transfers_df with shape (23187686, 5) after 30.7 seconds.\n",
      "[13/Sep/2024 21:54:43] INFO [dreams_core.core.prepare_profits_data:374] Preparing profits_df data...\n",
      "[13/Sep/2024 21:55:33] INFO [dreams_core.core.calculate_wallet_profitability:554] Generated profits df after 18.75 seconds\n",
      "[13/Sep/2024 21:55:54] INFO [dreams_core.core.clean_profits_df:625] Finished cleaning profits_df after 21.20 seconds.\n",
      "[13/Sep/2024 21:56:01] INFO [dreams_core.core.classify_shark_coins:691] creation of shark_coins_df complete.\n",
      "[13/Sep/2024 21:56:01] INFO [dreams_core.core.generate_buysell_metrics_df:33] Preparing buysell_metrics_df...\n",
      "[13/Sep/2024 21:56:04] INFO [dreams_core.core.generate_buysell_metrics_df:99] Generated buysell_metrics_df after 2.37 seconds.\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# retrieve and clean prices data\n",
    "prices_df = td.retrieve_prices_data()\n",
    "prices_df,_ = td.fill_prices_gaps(prices_df,config['data_cleaning']['max_gap_days'])\n",
    "\n",
    "# retrieve transfers data\n",
    "transfers_df = td.retrieve_transfers_data(\n",
    "    config['training_data']['training_period_start'],\n",
    "    config['training_data']['modeling_period_start'],\n",
    "    config['training_data']['modeling_period_end']\n",
    "    )\n",
    "\n",
    "# compile profits_df\n",
    "profits_df = td.prepare_profits_data(transfers_df, prices_df)\n",
    "profits_df = td.calculate_wallet_profitability(profits_df)\n",
    "profits_df,_ = td.clean_profits_df(profits_df, config['data_cleaning'])\n",
    "\n",
    "# identify sharks\n",
    "shark_coins_df = td.classify_shark_coins(profits_df, config['training_data'])\n",
    "shark_wallets_df = td.classify_shark_wallets(shark_coins_df,config['training_data'])\n",
    "\n",
    "# generate and flatten buysell_metrics\n",
    "cohort_wallets = shark_wallets_df[shark_wallets_df['is_shark']==True]['wallet_address'].unique()\n",
    "cohort_coins = shark_coins_df['coin_id'].unique()\n",
    "buysell_metrics_df = cwm.generate_buysell_metrics_df(profits_df,config['training_data']['training_period_end'],cohort_wallets,cohort_coins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13/Sep/2024 21:56:28] INFO [dreams_core.core.flatten_coin_date_df:82] Flattening columns ['buyers_new', 'total_bought', 'total_sold', 'total_buyers'] into coin-level features...\n",
      "[13/Sep/2024 21:56:28] INFO [dreams_core.core.flatten_coin_date_df:98] Flattened input df into coin-level features with shape (114, 56) after 0.09 seconds.\n",
      "[13/Sep/2024 21:56:28] INFO [dreams_core.core.create_training_data_df:500] 1 files were successfully merged.\n",
      "[13/Sep/2024 21:56:28] INFO [dreams_core.core.create_training_data_df:504] All specified files were found and merged successfully.\n",
      "[13/Sep/2024 21:56:28] INFO [dreams_core.core.create_target_variables_mooncrater:582] Target variables created for 334 coins with 29/334 (8.7%) moons and 91/334 (27.2%) craters.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(td)\n",
    "importlib.reload(cwm)\n",
    "importlib.reload(fe) \n",
    "config = load_config('../config/config.yaml')\n",
    "metrics_config = load_config('../config/config_metrics.yaml')\n",
    "modeling_config = load_config('../config/config_modeling.yaml')\n",
    "\n",
    "# flatten, save, and preprocess the flattened df\n",
    "output_directory = '..//modeling/outputs/flattened_outputs/'\n",
    "metric_description = 'buysell_metrics'\n",
    "modeling_period_start = config['training_data']['modeling_period_start']\n",
    "version = '0.1'\n",
    "\n",
    "flattened_buysell_metrics_df = fe.flatten_coin_date_df(buysell_metrics_df,metrics_config,config['training_data']['training_period_end'])\n",
    "flattened_df, flattened_filepath = fe.save_flattened_outputs(flattened_buysell_metrics_df, output_directory, metric_description, modeling_period_start, version)\n",
    "preprocessed_df, preprocessed_filepath = fe.preprocess_coin_df(flattened_filepath, modeling_config)\n",
    "\n",
    "# create the model input df\n",
    "input_directory = f\"{preprocessed_filepath.split('preprocessed_outputs/')[0]}preprocessed_outputs/\"\n",
    "input_filenames = [\n",
    "    preprocessed_filepath.split('preprocessed_outputs/')[1]\n",
    "]\n",
    "training_data_df = fe.create_training_data_df(input_directory, input_filenames)\n",
    "\n",
    "# create the target variables df\n",
    "target_variable_df,_ = fe.create_target_variables_mooncrater(prices_df, config['training_data'], modeling_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_input_df():\n",
    "    \"\"\"\n",
    "    Creates a mock DataFrame and saves it as a CSV for testing.\n",
    "    The CSV file is saved in the 'tests/test_modeling/outputs/flattened_outputs' directory.\n",
    "    \n",
    "    Returns:\n",
    "    - input_path: Path to the CSV file.\n",
    "    - df: Original mock DataFrame.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'feature_1_sum': [1, 2, 3],\n",
    "        'feature_to_drop': [10, 20, 30],\n",
    "        'feature_3': [100, 200, 300]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    input_path = 'temp/mock_input.csv'\n",
    "    df.to_csv(input_path, index=False)\n",
    "    return input_path, df\n",
    "\n",
    "\n",
    "\n",
    "def mock_modeling_config():\n",
    "    \"\"\"\n",
    "    Returns a mock modeling configuration dictionary.\n",
    "    The configuration includes preprocessing options such as features to drop.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'preprocessing': {\n",
    "            'drop_features': ['feature_to_drop']\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def mock_metrics_config():\n",
    "    \"\"\"\n",
    "    Returns a mock metrics configuration dictionary.\n",
    "    This configuration includes settings for scaling different features.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'metrics': {\n",
    "            'feature_1': {\n",
    "                'aggregations': {\n",
    "                    'sum': {'scaling': 'standard'}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "input_path, df  = mock_input_df()\n",
    "mock_modeling_config = mock_modeling_config()\n",
    "mock_metrics_config = mock_metrics_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1_sum</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.22474487139</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.22474487139</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1_sum  feature_3\n",
       "0 -1.22474487139        100\n",
       "1              0        200\n",
       "2  1.22474487139        300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13/Sep/2024 22:43:46] INFO [dreams_core.core.preprocess_coin_df:422] Preprocessed file saved at: temp/mock_input_preprocessed.csv\n",
      "[13/Sep/2024 22:43:46] INFO [dreams_core.core.preprocess_coin_df:423] Dropped 1 columns: feature_to_drop\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(fe) \n",
    "\n",
    "# def test_preprocess_coin_df_scaling(mock_modeling_config, mock_metrics_config, mock_input_df):\n",
    "\"\"\"\n",
    "Tests that the preprocess_coin_df function correctly applies scaling to the specified features.\n",
    "\n",
    "Steps:\n",
    "- Preprocesses the mock DataFrame by applying standard scaling to 'feature_1'.\n",
    "- Asserts that the column is scaled correctly.\n",
    "- Cleans up the test files after execution.\n",
    "\"\"\"\n",
    "input_path, original_df = mock_input_df()\n",
    "\n",
    "# Call the function\n",
    "output_df, output_path = fe.preprocess_coin_df(input_path, mock_modeling_config, mock_metrics_config)\n",
    "\n",
    "\n",
    "# Check that 'feature_1' is scaled (mean should be near 0 and std should be near 1)\n",
    "scaled_column = output_df['feature_1_sum']\n",
    "assert abs(scaled_column.mean()) < 1e-6, \"Standard scaling not applied correctly to 'feature_1_sum'.\"\n",
    "assert abs(np.std(scaled_column) - 1) < 1e-6, \"Standard scaling not applied correctly to 'feature_1_sum'.\"\n",
    "\n",
    "# # Cleanup (remove the test files)\n",
    "# os.remove(output_path)\n",
    "# os.remove(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22474487139158894)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_column = output_df['feature_1_sum']\n",
    "# abs(scaled_column.mean())\n",
    "abs(scaled_column.std() - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1.22474487139\n",
       "1                0\n",
       "2    1.22474487139\n",
       "Name: feature_1_sum, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1_sum</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.22474487139</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.22474487139</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.612372435696</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.612372435696</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.22474487139</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_1_sum  feature_3\n",
       "count               3          3\n",
       "mean                0        200\n",
       "std     1.22474487139        100\n",
       "min    -1.22474487139        100\n",
       "25%   -0.612372435696        150\n",
       "50%                 0        200\n",
       "75%    0.612372435696        250\n",
       "max     1.22474487139        300"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22474487139158894)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_column.std() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22474487,  0.        ,  1.22474487])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_array = StandardScaler().fit_transform([[1], [2], [3]]).flatten()\n",
    "scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: metrics\n",
      "setting: {'buyers_new': {'aggregations': {'sum': {'scaling': 'standard'}, 'mean': {'scaling': 'minmax'}, 'std': {'scaling': 'standard'}}, 'rolling': {'stats': {'sum': {'scaling': 'minmax'}, 'max': {'scaling': 'standard'}}, 'comparisons': {'change': {'scaling': 'standard'}, 'pct_change': {'scaling': 'None'}}, 'window_duration': 7, 'lookback_periods': 8}}, 'total_bought': {'aggregations': {'sum': {'scaling': 'standard'}, 'median': {'scaling': 'None'}}, 'rolling': {'stats': {'sum': {'scaling': 'minmax'}}, 'comparisons': {'change': {'scaling': 'standard'}}, 'window_duration': 7, 'lookback_periods': 8}}, 'total_sold': {'aggregations': {'sum': {'scaling': 'standard'}}}, 'total_buyers': {'aggregations': {'sum': {'scaling': 'None'}}}}\n"
     ]
    }
   ],
   "source": [
    "for metric, settings in metrics_config.items():\n",
    "    print(f'metric: {metric}')\n",
    "    print(f'setting: {settings}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('metrics', {'buyers_new': {'aggregations': {'sum': {'scaling': 'standard'}, 'mean': {'scaling': 'minmax'}, 'std': {'scaling': 'standard'}}, 'rolling': {'stats': {'sum': {'scaling': 'minmax'}, 'max': {'scaling': 'standard'}}, 'comparisons': {'change': {'scaling': 'standard'}, 'pct_change': {'scaling': 'None'}}, 'window_duration': 7, 'lookback_periods': 8}}, 'total_bought': {'aggregations': {'sum': {'scaling': 'standard'}, 'median': {'scaling': 'None'}}, 'rolling': {'stats': {'sum': {'scaling': 'minmax'}}, 'comparisons': {'change': {'scaling': 'standard'}}, 'window_duration': 7, 'lookback_periods': 8}}, 'total_sold': {'aggregations': {'sum': {'scaling': 'standard'}}}, 'total_buyers': {'aggregations': {'sum': {'scaling': 'None'}}}})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_config.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.816496580927726)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Original array [1, 2, 3]\n",
    "std_original = np.std([1, 2, 3])\n",
    "\n",
    "# Scaled array [-1.2247, 0, 1.2247]\n",
    "scaled_array = [-1.22474487, 0, 1.22474487]\n",
    "std_scaled = np.std(scaled_array)\n",
    "\n",
    "std_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "1.224744871391589\n"
     ]
    }
   ],
   "source": [
    "print(np.std(scaled_column))\n",
    "\n",
    "print(scaled_column.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'std'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscaled_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'std'"
     ]
    }
   ],
   "source": [
    "scaled_array.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
