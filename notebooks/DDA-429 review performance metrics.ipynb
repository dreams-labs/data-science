{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportMissingImports=false\n",
    "# pyright: reportMissingModuleSource=false\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import pdb\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import warnings\n",
    "import yaml\n",
    "from typing import Dict,Union,List,Any,Tuple\n",
    "import pytest\n",
    "import importlib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_gbq\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.signal import argrelextrema\n",
    "from dreams_core.googlecloud import GoogleCloud as dgc\n",
    "from dreams_core import core as dc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import progressbar\n",
    "\n",
    "# load_dotenv(Path(\"../../../Local/.env\"))\n",
    "\n",
    "# Custom format function for displaying |numbers/\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "# pd.reset_option('display.float_format')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"MallocStackLogging\")\n",
    "\n",
    "# silence pygame donation request\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = \"hide\"\n",
    "os.environ['ALERT_SOUND_FILEPATH']=\"../../../Local/assets/sounds/mixkit-alert-bells-echo-765.wav\"\n",
    "\n",
    "# Dark mode charts\n",
    "plt.rcParams['figure.facecolor'] = '#181818'  # Custom background color (dark gray in this case)\n",
    "plt.rcParams['axes.facecolor'] = '#181818'\n",
    "plt.rcParams['text.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.labelcolor'] = '#afc6ba'\n",
    "plt.rcParams['xtick.color'] = '#afc6ba'\n",
    "plt.rcParams['ytick.color'] = '#afc6ba'\n",
    "plt.rcParams['axes.titlecolor'] = '#afc6ba'\n",
    "\n",
    "# import local modules\n",
    "# pyright: reportMissingImports=false\n",
    "sys.path.append('..//src')\n",
    "import utils as u\n",
    "import training_data.data_retrieval as dr\n",
    "import training_data.profits_row_imputation as pri\n",
    "import coin_wallet_metrics.coin_wallet_metrics as cwm\n",
    "import coin_wallet_metrics.indicators as ind\n",
    "import feature_engineering.feature_generation as fg\n",
    "import feature_engineering.time_windows_orchestration as tw\n",
    "import feature_engineering.flattening as flt\n",
    "import feature_engineering.data_splitting as ds\n",
    "import feature_engineering.target_variables as tv\n",
    "import feature_engineering.preprocessing as prp\n",
    "import modeling as m\n",
    "import insights.analysis as ia\n",
    "import insights.experiments as exp\n",
    "\n",
    "# Wallet modeling\n",
    "import wallet_modeling.wallet_modeling_orchestrator as wmo\n",
    "import wallet_modeling.wallet_training_data as wtd\n",
    "import wallet_modeling.model_reporting as wmr\n",
    "import wallet_modeling.wallet_model as wm\n",
    "from wallet_modeling.wallets_config_manager import WalletsConfig\n",
    "\n",
    "# Wallet features\n",
    "import wallet_features.clustering_features as wcl\n",
    "import wallet_features.market_cap_features as wmc\n",
    "import wallet_features.market_timing_features as wmt\n",
    "import wallet_features.performance_features as wpf\n",
    "import wallet_features.trading_features as wtf\n",
    "import wallet_features.transfers_features as wts\n",
    "import wallet_features.features_orchestrator as wfo\n",
    "\n",
    "# Wallet insights\n",
    "import wallet_insights.wallet_model_evaluation as wime\n",
    "import wallet_insights.validation_analysis as wiv\n",
    "import wallet_insights.coin_forecasting as wicf\n",
    "\n",
    "\n",
    "# reload all modules\n",
    "modules = [u, dr, pri, cwm, ind, fg, tw, flt, ds, tv, prp, m, ia, exp,\n",
    "           wmo, wtd, wmr, wme,\n",
    "           wcl, wmc, wmt, wpf, wtf, wts, wfo,\n",
    "           wime, wiv, wicf]\n",
    "[importlib.reload(module) for module in modules]\n",
    "\n",
    "# load all configs\n",
    "config, metrics_config, modeling_config, experiments_config = u.load_all_configs('../config')\n",
    "wallets_config = WalletsConfig.load_from_yaml('../config/wallets_config.yaml')\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "# configure logger\n",
    "logger = dc.setup_logger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(\"Good morning, let's get to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "u.export_code(code_directories=['wallet_features','data_retrieval','wallet_modeling'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training Data Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "# Retrieve datasets\n",
    "profits_df,market_data_df = wmo.retrieve_datasets()\n",
    "profits_df_full = profits_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "wallets_metrics_config = u.load_config('../config/wallets_metrics_config.yaml')\n",
    "wallets_features_config = yaml.safe_load(Path('../config/wallets_features_config.yaml').read_text(encoding='utf-8'))\n",
    "\n",
    "\n",
    "profits_df = profits_df_full.copy()\n",
    "\n",
    "# Define wallet cohort after cleaning\n",
    "training_wallet_metrics_df,wallet_cohort = wmo.define_wallet_cohort(profits_df,market_data_df)\n",
    "\n",
    "# Generate profits_df for all training windows and the modeling period\n",
    "training_profits_df, training_windows_profits_dfs, modeling_profits_df, validation_profits_df = wmo.split_profits_df(profits_df,\n",
    "                                                                               market_data_df,wallet_cohort)\n",
    "\n",
    "# Market data: add indicators\n",
    "# Remove all market_data records after the training period to ensure no leakage\n",
    "training_market_data_df = (market_data_df[market_data_df['date']\n",
    "                                          <= wallets_config['training_data']['training_period_end']])\n",
    "\n",
    "# Add new columns\n",
    "# Generate basic indicators\n",
    "market_indicators_data_df = ind.add_market_data_dualcolumn_indicators(training_market_data_df)\n",
    "market_indicators_data_df = ind.generate_time_series_indicators(market_indicators_data_df,\n",
    "                                                        wallets_metrics_config['time_series']['market_data'],\n",
    "                                                        'coin_id')\n",
    "\n",
    "# Transfers data retrieval for the wallet_ids in temp.wallet_modeling_cohort\n",
    "transfers_sequencing_df = wts.retrieve_transfers_sequencing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate features for the full training dataset\n",
    "training_wallet_features_df = wfo.calculate_wallet_features(training_profits_df, market_indicators_data_df,\n",
    "                                                           transfers_sequencing_df, wallet_cohort)\n",
    "\n",
    "# Define the full feature set by appending a suffix for each window\n",
    "training_data_df = training_wallet_features_df.add_suffix(\"_all_windows\")\n",
    "\n",
    "# Generate features for each window\n",
    "for i, window_profits_df in enumerate(training_windows_profits_dfs, 1):\n",
    "    logger.info(\"Generating features for window %s...\", i)\n",
    "\n",
    "    # Generate the features\n",
    "    window_wallet_features_df = wfo.calculate_wallet_features(window_profits_df, market_indicators_data_df,\n",
    "                                                             transfers_sequencing_df, wallet_cohort)\n",
    "\n",
    "    # Add column suffix and join to training_data_df\n",
    "    window_wallet_features_df = window_wallet_features_df.add_suffix(f'_w{i}')\n",
    "    training_data_df = training_data_df.join(window_wallet_features_df, how='left')\n",
    "\n",
    "# Append clustering features based on all numeric features in the base training data\n",
    "cluster_features_df = wcl.create_basic_cluster_features(training_data_df)\n",
    "cluster_features_df = cluster_features_df.add_prefix('cluster_')\n",
    "training_data_df = training_data_df.join(cluster_features_df, how='inner')\n",
    "\n",
    "logger.info(\"Feature generation complete.\")\n",
    "\n",
    "training_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigating negative performance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result was an issue with winsorization labeling and a bug in cash flows return logic\n",
    "\n",
    "training_data_df_full = training_data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_profits_df = training_windows_profits_dfs[0].copy()\n",
    "profits_df = training_windows_profits_dfs[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "window_wallet_features_df = wfo.calculate_wallet_features(window_profits_df, market_indicators_data_df,\n",
    "                                                            transfers_sequencing_df, wallet_cohort)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_wallet_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'trading_total_inflows',\n",
    "    'trading_total_outflows',\n",
    "    'trading_total_net_flows',\n",
    "    'trading_max_investment',\n",
    "    'trading_transaction_days',\n",
    "    'trading_unique_coins_traded',\n",
    "    'trading_cash_buy_inflows',\n",
    "    'trading_cash_sell_outflows',\n",
    "    'trading_cash_net_flows',\n",
    "    'trading_total_volume',\n",
    "    'trading_average_transaction',\n",
    "    'trading_activity_density',\n",
    "    'trading_volume_vs_investment_ratio',\n",
    "    'performance_return',\n",
    "    'performance_return_unwinsorized',\n",
    "    'performance_realized_return',\n",
    "    'performance_performance_score',\n",
    "    'performance_size_adjusted_rank',\n",
    "]\n",
    "\n",
    "investigate_df = window_wallet_features_df[cols]\n",
    "investigate_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigating edge case performance nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df_full = training_data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df = training_data_df_full.copy()\n",
    "# Get all rows with any NA\n",
    "na_rows = training_data_df[training_data_df.isna().any(axis=1)]\n",
    "na_subset = na_rows.loc[:, na_rows.isna().any()]\n",
    "na_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_wallet_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = training_windows_profits_dfs[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"here we go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate all except performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all wallets that should exist\n",
    "wallet_features_df = pd.DataFrame(index=wallet_cohort)\n",
    "wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "# Store feature sets with their prefixes for bulk renaming\n",
    "feature_column_names = {}\n",
    "\n",
    "# Trading features (inner join, custom fill)\n",
    "profits_df = wtf.add_cash_flow_transfers_logic(profits_df)\n",
    "trading_features_df = wtf.calculate_wallet_trading_features(profits_df)\n",
    "trading_features_df = wtf.fill_trading_features_data(trading_features_df, wallet_cohort)\n",
    "feature_column_names['trading_'] = trading_features_df.columns\n",
    "wallet_features_df = wallet_features_df.join(trading_features_df, how='inner')\n",
    "\n",
    "# Market timing features (fill zeros)\n",
    "timing_features_df = wmt.calculate_market_timing_features(profits_df, market_indicators_data_df)\n",
    "feature_column_names['timing_'] = timing_features_df.columns\n",
    "wallet_features_df = wallet_features_df.join(timing_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in timing_features_df.columns})\n",
    "\n",
    "# Market cap features (fill zeros)\n",
    "market_features_df = wmc.calculate_market_cap_features(profits_df, market_indicators_data_df)\n",
    "feature_column_names['mktcap_'] = market_features_df.columns\n",
    "wallet_features_df = wallet_features_df.join(market_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in market_features_df.columns})\n",
    "\n",
    "# Transfers features (fill -1)\n",
    "transfers_features_df = wts.calculate_transfers_sequencing_features(profits_df, transfers_sequencing_df)\n",
    "feature_column_names['transfers_'] = transfers_features_df.columns\n",
    "wallet_features_df = wallet_features_df.join(transfers_features_df, how='left')\\\n",
    "    .fillna({col: -1 for col in transfers_features_df.columns})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base calc of performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_features_df = wpf.calculate_performance_features(wallet_features_df)\n",
    "performance_features_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows with any NA\n",
    "na_rows = performance_features_df[performance_features_df.isna().any(axis=1)]\n",
    "na_subset = na_rows.loc[:, na_rows.isna().any()]\n",
    "na_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### walk through performance_df steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_features_df_full = wallet_features_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_features_df = wallet_features_df_full.copy()\n",
    "wallet_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = wallet_features_df[['max_investment','total_net_flows']].copy().round(6)\n",
    "returns_winsorization = wallets_config['modeling']['returns_winsorization']\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Calculate base return, including unrealized price change impacts\n",
    "metrics_df['return'] = np.where(abs(metrics_df['max_investment']) == 0,0,\n",
    "                                metrics_df['total_net_flows'] / metrics_df['max_investment'])\n",
    "\n",
    "# Calculate realized return, based on actual cash flows only\n",
    "metrics_df['realized_return'] = np.where(abs(metrics_df['max_investment']) == 0,0,\n",
    "                                metrics_df['total_net_flows'] / metrics_df['max_investment'])\n",
    "\n",
    "# Apply winsorization\n",
    "if returns_winsorization > 0:\n",
    "    metrics_df['return'] = u.winsorize(metrics_df['return'],returns_winsorization)\n",
    "\n",
    "# Normalize returns\n",
    "metrics_df['norm_return'] = (metrics_df['return'] - metrics_df['return'].min()) / \\\n",
    "    (metrics_df['return'].max() - metrics_df['return'].min())\n",
    "\n",
    "# Normalize logged investments\n",
    "log_invested = np.log10(metrics_df['max_investment'] + epsilon)\n",
    "metrics_df['norm_invested'] = (log_invested - log_invested.min()) / \\\n",
    "    (log_invested.max() - log_invested.min())\n",
    "\n",
    "# # # Performance score\n",
    "# # metrics_df['performance_score'] = (0.6 * metrics_df['norm_return'] +\n",
    "# #                                     0.4 * metrics_df['norm_invested'])\n",
    "\n",
    "\n",
    "metrics_df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = wallet_features_df[['max_investment','total_net_flows']].copy().round(6)\n",
    "\n",
    "metrics_df.loc[[4157559,28800922]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_metrics_df['max_investment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows with any NA\n",
    "na_rows = metrics_df[metrics_df.isna().any(axis=1)]\n",
    "na_rows\n",
    "# na_subset = na_rows.loc[:, na_rows.isna().any()]\n",
    "# na_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features_df = wpf.calculate_performance_features(wallet_features_df)\n",
    "# feature_column_names['performance_'] = performance_features_df.drop(['max_investment', 'total_net_flows'], axis=1).columns\n",
    "# wallet_features_df = wallet_features_df.join(\n",
    "#     performance_features_df.drop(['max_investment', 'total_net_flows'], axis=1),\n",
    "#     how='inner'\n",
    "# )\n",
    "\n",
    "performance_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_perf_df = wpf.calculate_performance_features(window_wallet_features_df)\n",
    "bad_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = training_windows_profits_dfs[0].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all wallets that should exist\n",
    "wallet_features_df = pd.DataFrame(index=wallet_cohort)\n",
    "wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "# Store feature sets with their prefixes for bulk renaming\n",
    "feature_column_names = {}\n",
    "\n",
    "# Trading features (inner join, custom fill)\n",
    "profits_df = wtf.add_cash_flow_transfers_logic(profits_df)\n",
    "trading_features_df = wtf.calculate_wallet_trading_features(profits_df)\n",
    "trading_features_df = wtf.fill_trading_features_data(trading_features_df, wallet_cohort)\n",
    "feature_column_names['trading_'] = trading_features_df.columns\n",
    "wallet_features_df = wallet_features_df.join(trading_features_df, how='inner')\n",
    "\n",
    "# Market timing features (fill zeros)\n",
    "timing_features_df = wmt.calculate_market_timing_features(profits_df, market_indicators_data_df)\n",
    "feature_column_names['timing_'] = timing_features_df.columns\n",
    "wallet_features_df = wallet_features_df.join(timing_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in timing_features_df.columns})\n",
    "\n",
    "# Market cap features (fill zeros)\n",
    "market_features_df = wmc.calculate_market_cap_features(profits_df, market_indicators_data_df)\n",
    "feature_column_names['mktcap_'] = market_features_df.columns\n",
    "wallet_features_df = wallet_features_df.join(market_features_df, how='left')\\\n",
    "    .fillna({col: 0 for col in market_features_df.columns})\n",
    "\n",
    "# Transfers features (fill -1)\n",
    "transfers_features_df = wts.calculate_transfers_sequencing_features(profits_df, transfers_sequencing_df)\n",
    "feature_column_names['transfers_'] = transfers_features_df.columns\n",
    "wallet_features_df = wallet_features_df.join(transfers_features_df, how='left')\\\n",
    "    .fillna({col: -1 for col in transfers_features_df.columns})\n",
    "\n",
    "# Performance features (inner join, no fill)\n",
    "performance_features_df = wpf.calculate_performance_features(wallet_features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(training_data_df.loc[w]).T.to_csv('baddata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 4157559\n",
    "# w = 28800922\n",
    "\n",
    "wallet_features_df.loc[w]\n",
    "trading_features_df.loc[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_features_df.loc[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df[profits_df['wallet_address']==w]\n",
    "# profits_df_full[profits_df_full['wallet_address']==w].sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_profits_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '28846ace-0e04-4cbe-83d8-8390cfe04c3b'\n",
    "w = 4157559\n",
    "\n",
    "\n",
    "bad_profits_df = profits_df_full[\n",
    "    (profits_df_full['coin_id'].isin([c,'3be6bd20-cd71-496f-b963-1e76d6303984','31b3d3aa-cffb-40a1-9971-0d5d9be7fa9a']))\n",
    "    & (profits_df_full['wallet_address'].isin([w,28800922,15850862,13897369]))\n",
    "].sort_values(by='date').copy()\n",
    "\n",
    "# bad_profits_df = u.cw_filter_df(profits_df_full,c,w).sort_values(by='date')\n",
    "bad_trading_features_df = wtf.add_cash_flow_transfers_logic(bad_profits_df)\n",
    "bad_trading_features_df = wtf.calculate_wallet_trading_features(bad_trading_features_df)\n",
    "bad_trading_features_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_performance_features_df = wpf.calculate_performance_features(bad_trading_features_df)\n",
    "bad_performance_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = bad_trading_features_df[['max_investment','total_net_flows']].copy().round(6)\n",
    "metrics_df\n",
    "returns_winsorization = wallets_config['modeling']['returns_winsorization']\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Calculate base return, including unrealized price change impacts\n",
    "metrics_df['return'] = np.where(abs(metrics_df['max_investment']) == 0,0,\n",
    "                                metrics_df['total_net_flows'] / metrics_df['max_investment'])\n",
    "\n",
    "# Calculate realized return, based on actual cash flows only\n",
    "metrics_df['realized_return'] = np.where(abs(metrics_df['max_investment']) == 0,0,\n",
    "                                metrics_df['total_net_flows'] / metrics_df['max_investment'])\n",
    "\n",
    "# Apply winsorization\n",
    "if returns_winsorization > 0:\n",
    "    metrics_df['return'] = u.winsorize(metrics_df['return'],returns_winsorization)\n",
    "\n",
    "# Normalize returns\n",
    "metrics_df['norm_return'] = (metrics_df['return'] - metrics_df['return'].min()) / \\\n",
    "    (metrics_df['return'].max() - metrics_df['return'].min())\n",
    "\n",
    "# Normalize logged investments\n",
    "log_invested = np.log10(metrics_df['max_investment'] + epsilon)\n",
    "metrics_df['norm_invested'] = (log_invested - log_invested.min()) / \\\n",
    "    (log_invested.max() - log_invested.min())\n",
    "\n",
    "# Performance score\n",
    "metrics_df['performance_score'] = (0.6 * metrics_df['norm_return'] +\n",
    "                                    0.4 * metrics_df['norm_invested'])\n",
    "\n",
    "# # Size-adjusted rank\n",
    "# # Create mask for zero values\n",
    "# zero_mask = metrics_df['max_investment'] == 0\n",
    "\n",
    "# # Create quartiles series initialized with 'q0' for zero values\n",
    "# quartiles = pd.Series('q0', index=metrics_df.index)\n",
    "\n",
    "# # Calculate quartiles for non-zero values\n",
    "# non_zero_quartiles = pd.qcut(metrics_df['max_investment'][~zero_mask],\n",
    "#                             q=4,\n",
    "#                             labels=['q1', 'q2', 'q3', 'q4'])\n",
    "\n",
    "# # Assign the quartiles to non-zero values\n",
    "# quartiles[~zero_mask] = non_zero_quartiles\n",
    "\n",
    "# # Calculate size-adjusted rank within each quartile\n",
    "# metrics_df['size_adjusted_rank'] = metrics_df.groupby(quartiles)['return'].rank(pct=True)\n",
    "\n",
    "\n",
    "# # Clean up intermediate columns\n",
    "# cols_to_drop = ['norm_return', 'norm_invested', 'norm_gain']\n",
    "# metrics_df = metrics_df.drop(columns=[c for c in cols_to_drop\n",
    "#                                     if c in metrics_df.columns])\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_trading_features_df = wtf.calculate_wallet_trading_features(bad_trading_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_features_df[performance_features_df['performance_score'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wallet_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(training_data_df.isna().sum())\n",
    "df.columns = ['nan']\n",
    "df[df['nan']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time weighted returns addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [importlib.reload(module) for module in modules]\n",
    "# wallets_config.reload()\n",
    "\n",
    "# # Create a DataFrame with all wallets that should exist\n",
    "# wallet_features_df = pd.DataFrame(index=wallet_cohort)\n",
    "# wallet_features_df.index.name = 'wallet_address'\n",
    "\n",
    "# # Trading features (inner join, custom fill)\n",
    "# profits_df = wtf.add_cash_flow_transfers_logic(window_profits_df)\n",
    "# trading_features_df = wtf.calculate_wallet_trading_features(profits_df)\n",
    "# trading_features_df = wtf.fill_trading_features_data(trading_features_df, wallet_cohort)\n",
    "# wallet_features_df = wallet_features_df.join(trading_features_df, how='inner')\n",
    "\n",
    "# # Time weighted returns (fill zeros)\n",
    "# # time_weighted_returns_df = wpf.calculate_time_weighted_returns(profits_df)\n",
    "# # wallet_features_df = wallet_features_df.join(time_weighted_returns_df, how='left')\\\n",
    "# #     .fillna({col: 0 for col in time_weighted_returns_df.columns})\n",
    "\n",
    "# performance_features_df = wpf.calculate_performance_features(wallet_features_df)\n",
    "# wallet_features_df = wallet_features_df.join(performance_features_df,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [importlib.reload(module) for module in modules]\n",
    "# wallets_config.reload()\n",
    "\n",
    "# profits_df = wtf.add_cash_flow_transfers_logic(window_profits_df)\n",
    "\n",
    "\n",
    "# trading_features_df = wtf.calculate_wallet_trading_features(profits_df)\n",
    "# trading_features_df = wtf.fill_trading_features_data(trading_features_df, wallet_cohort)\n",
    "# trading_features_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_features_df.reset_index(drop=True).corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corr_matrix_viz(df: pd.DataFrame, figsize=(12, 10)) -> None:\n",
    "    \"\"\"\n",
    "    Creates and plots correlation matrix heatmap for numerical features.\n",
    "\n",
    "    Params:\n",
    "    - df (DataFrame): input feature dataframe\n",
    "    - figsize (tuple): figure size for plot, defaults to (12, 10)\n",
    "    \"\"\"\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df.reset_index(drop=True).corr(method='pearson')\n",
    "\n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=True,  # Show correlation values\n",
    "        cmap='RdBu',  # Red-Blue diverging colormap\n",
    "        center=0,     # Center colormap at 0\n",
    "        fmt='.2f',    # Round to 2 decimal places\n",
    "        square=True,  # Make cells square\n",
    "        cbar_kws={'label': 'Correlation Coefficient'}\n",
    "    )\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "\n",
    "create_corr_matrix_viz(performance_features_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_weighted_returns_df = wpf.calculate_time_weighted_returns(profits_df)\n",
    "time_weighted_returns_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 39759\n",
    "training_profits_df[training_profits_df['wallet_address']==w].sort_values(by=['coin_id','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_features_df.loc[39759]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_weighted_performance_df = wpf.calculate_time_weighted_returns(window_profits_df)\n",
    "time_weighted_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join target variable to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Clean inactive wallets from modeling period data\n",
    "modeling_wallets_df = wmo.filter_modeling_period_wallets(modeling_profits_df)\n",
    "\n",
    "# Generate target variables\n",
    "target_vars_df = wpf.calculate_performance_features(modeling_wallets_df)\n",
    "\n",
    "# Merge training data and target variables?\n",
    "modeling_df = training_data_df.join(target_vars_df[wallets_config['modeling']['target_variable']],\n",
    "                                    how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Create an experiment instance\n",
    "experiment = wme.WalletModel(wallets_config)\n",
    "\n",
    "# Run the experiment and get results\n",
    "model_results = experiment.run_experiment(modeling_df)\n",
    "\n",
    "# Extract the trained model\n",
    "model = model_results['pipeline'].named_steps['regressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model artifacts\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "# Generate and save all model artifacts\n",
    "model_id, evaluator, wallet_scores_df, coin_validation_df = wmr.generate_and_save_model_artifacts(\n",
    "    model_results=model_results,\n",
    "    validation_profits_df=validation_profits_df,\n",
    "    base_path='../wallet_modeling'\n",
    ")\n",
    "u.play_notification()\n",
    "\n",
    "# Print results\n",
    "print(evaluator.summary_report())\n",
    "evaluator.plot_evaluation()\n",
    "evaluator.importance_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model artifacts\n",
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "\n",
    "comparison_metrics = [\n",
    "    'trading_max_investment_all_windows',\n",
    "    'mktcap_portfolio_wtd_market_cap_all_windows',\n",
    "    'trading_total_net_flows_all_windows',\n",
    "    'performance_return_all_windows',\n",
    "    'performance_performance_score_all_windows',\n",
    "    'trading_max_investment_w4',\n",
    "    'mktcap_portfolio_wtd_market_cap_w4',\n",
    "    'trading_total_net_flows_w4',\n",
    "    'performance_return_w4',\n",
    "    'performance_performance_score_w4',\n",
    "]\n",
    "\n",
    "# Create df that includes comparison metrics and all cluster feature columns\n",
    "cluster_cols = [col for col in modeling_df.columns if col.startswith('cluster_')]\n",
    "cluster_analysis_df = modeling_df[cluster_cols + comparison_metrics].copy()\n",
    "\n",
    "# Assign wallets to categorical clusters based on the distance values\n",
    "cluster_analysis_df = wime.assign_clusters_from_distances(cluster_analysis_df, wallets_config['features']['clustering_n_clusters'])\n",
    "\n",
    "# Generate metrics for clusters\n",
    "cluster_profiles = wime.analyze_cluster_metrics(\n",
    "   cluster_analysis_df,\n",
    "   wallets_config['features']['clustering_n_clusters'],\n",
    "   comparison_metrics\n",
    ")\n",
    "\n",
    "# Assess model performance in the test set of each cluster\n",
    "cluster_performance = wime.analyze_cluster_performance(\n",
    "    cluster_analysis_df,\n",
    "    wallets_config['features']['clustering_n_clusters'],\n",
    "    model_results['y_test'],  # True values\n",
    "    model_results['y_pred']   # Predictions\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "\n",
    "# Join metrics with performance and display results\n",
    "cluster_results_df = cluster_profiles[n].join(cluster_performance[n]).T\n",
    "cluster_results_df = wime.format_numeric_columns(cluster_results_df)\n",
    "cluster_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "# Join metrics with performance and display results\n",
    "cluster_results_df = cluster_profiles[n].join(cluster_performance[n]).T\n",
    "cluster_results_df = wime.format_numeric_columns(cluster_results_df)\n",
    "cluster_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_rows(df: pd.DataFrame) -> pd.DataFrame.style:\n",
    "    \"\"\"\n",
    "    Apply row-wise conditional formatting to DataFrame where each row is scaled independently.\n",
    "    Uses blue gradient with transparency for dark mode compatibility.\n",
    "\n",
    "    Params:\n",
    "    - df (DataFrame): input DataFrame to style\n",
    "\n",
    "    Returns:\n",
    "    - styled_df (DataFrame.style): DataFrame with conditional formatting applied\n",
    "    \"\"\"\n",
    "    def row_style(row):\n",
    "        # Skip non-numeric rows\n",
    "        if not np.issubdtype(row.dtype, np.number):\n",
    "            return [''] * len(row)\n",
    "\n",
    "        # Handle rows with NaN values\n",
    "        valid_vals = row.dropna()\n",
    "        if len(valid_vals) == 0:\n",
    "            return [''] * len(row)\n",
    "\n",
    "        # Normalize values between 0 and 1 for each row\n",
    "        min_val = valid_vals.min()\n",
    "        max_val = valid_vals.max()\n",
    "        if min_val == max_val:\n",
    "            return ['background-color: rgba(0, 0, 255, 0)'] * len(row)\n",
    "\n",
    "        norm = (row - min_val) / (max_val - min_val)\n",
    "        # Convert to rgba colors (transparent to solid blue)\n",
    "        colors = [f'background-color: rgba(0, 0, 255, {x:.2f})' if pd.notna(x) else '' for x in norm]\n",
    "        return colors\n",
    "\n",
    "    return df.style.apply(row_style, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "\n",
    "# Join metrics with performance and display results\n",
    "cluster_results_df = cluster_profiles[n].join(cluster_performance[n]).T\n",
    "cluster_results_df = style_rows(cluster_results_df)\n",
    "# cluster_results_df = wime.format_numeric_columns(cluster_results_df)\n",
    "\n",
    "cluster_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_row_wise(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply row-wise background coloring to DataFrame relative to each row's values.\n",
    "\n",
    "    Params:\n",
    "    - df (DataFrame): Input dataframe to style\n",
    "\n",
    "    Returns:\n",
    "    - Styled DataFrame with row-wise background colors\n",
    "    \"\"\"\n",
    "    # Function to normalize single row to 0-1 scale\n",
    "    def row_background(row):\n",
    "        min_val = row.min()\n",
    "        max_val = row.max()\n",
    "        # Avoid division by zero if all values are the same\n",
    "        if min_val == max_val:\n",
    "            return ['background-color: transparent'] * len(row)\n",
    "        # Normalize to 0-1 scale\n",
    "        normalized = (row - min_val) / (max_val - min_val)\n",
    "        # Convert to colors (light blue to dark blue)\n",
    "        return ['background-color: #{:02x}{:02x}ff'.format(\n",
    "            int(255 * (1 - x)),\n",
    "            int(255 * (1 - x))\n",
    "        ) for x in normalized]\n",
    "\n",
    "    return df.style.apply(row_background, axis=1)\n",
    "\n",
    "style_row_wise(cluster_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "\n",
    "# # Access results like:\n",
    "# k2_profiles = cluster_profiles[2]  # Medians for k=2 clusters\n",
    "# k5_profiles = cluster_profiles[5]  # Medians for k=5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model_results['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2_profiles.round(3).T\n",
    "k5_profiles.round(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(highest_importances_df.sort_values(by='importance', ascending=False).groupby('prefix')).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(evaluator.metrics['importances']).head(20)\n",
    "df['prefix'] = df['feature'].str.split('_').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total importance by prefix\n",
    "df = feature_importance_df.copy()\n",
    "\n",
    "prefix_totals = (df\n",
    "    .assign(prefix=df['feature'].str.split('_').str[1])\n",
    "    .groupby('prefix')['importance']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'importance': 'total_importance'}))\n",
    "\n",
    "# Get best features by prefix\n",
    "best_features = (df\n",
    "    .assign(prefix=df['feature'].str.split('_').str[1])\n",
    "    .sort_values('importance', ascending=False)\n",
    "    .groupby('prefix')\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .rename(columns={'feature': 'best_feature', 'importance': 'best_feature_importance'}))\n",
    "\n",
    "# Join them\n",
    "result = (prefix_totals\n",
    "    .merge(best_features[['prefix', 'best_feature', 'best_feature_importance']], on='prefix')\n",
    "    .sort_values('total_importance', ascending=False))\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation period assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wallet_performance_df, bucketed_performance_df = wiv.calculate_validation_metrics(\n",
    "    X_test=model_results['X_test'],\n",
    "    y_pred=model_results['y_pred'],\n",
    "    validation_profits_df=validation_profits_df,\n",
    ")\n",
    "\n",
    "bucketed_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coin performance predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create coin_validation_df with metrics and returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Consolidate wallet scores at the coin level\n",
    "wallet_scores_df = pd.DataFrame({'score': model_results['y_pred']}, index=model_results['y_test'].index)\n",
    "coin_wallet_metrics_df = wicf.calculate_coin_metrics_from_wallet_scores(validation_profits_df, wallet_scores_df)\n",
    "\n",
    "# Calculate coin performance during the validation period\n",
    "coin_performance_df = wicf.calculate_coin_performance(market_data_df,\n",
    "                                                     wallets_config['training_data']['validation_period_start'],\n",
    "                                                     wallets_config['training_data']['validation_period_end'])\n",
    "\n",
    "# Join aggregated wallet metrics with actual coin performance\n",
    "coin_validation_df = coin_wallet_metrics_df.join(coin_performance_df, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting coin feature performance vs market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "\n",
    "# Get the analysis results\n",
    "segment_results, summary_df = wicf.analyze_market_cap_segments(\n",
    "    coin_validation_df,\n",
    "    top_n=10\n",
    ")\n",
    "\n",
    "# Or create the visualizations\n",
    "wicf.plot_segment_heatmap(summary_df)\n",
    "# wicf.plot_metric_consistency(summary_df)  # Optional secondary visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coin performance of top n for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run analysis\n",
    "top_n = wallets_config['coin_forecasting']['top_n']\n",
    "max_market_cap = wallets_config['coin_forecasting']['max_market_cap']\n",
    "min_market_cap = wallets_config['coin_forecasting']['min_market_cap']\n",
    "\n",
    "metric_top_coin_performance_df = wicf.validate_coin_performance(coin_validation_df,top_n,\n",
    "                                                                max_market_cap, min_market_cap)\n",
    "\n",
    "metric_top_coin_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare performance of high vs low score coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[importlib.reload(module) for module in modules]\n",
    "wallets_config.reload()\n",
    "\n",
    "wicf.print_performance_analysis(coin_validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame([\n",
    "    # BTC wallet with imputed values\n",
    "    {'coin_id': 'btc', 'wallet_address': 'wallet_a', 'date': '2024-01-01',\n",
    "        'usd_balance': 50, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'wallet_a', 'date': '2024-10-01',\n",
    "        'usd_balance': 70, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    # ETH wallet with transfers\n",
    "    {'coin_id': 'eth', 'wallet_address': 'wallet_a', 'date': '2024-01-01',\n",
    "        'usd_balance': 100, 'usd_net_transfers': 100, 'is_imputed': False},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'wallet_a', 'date': '2024-02-01',\n",
    "        'usd_balance': 250, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'wallet_a', 'date': '2024-10-01',\n",
    "        'usd_balance': 125, 'usd_net_transfers': 0, 'is_imputed': False}\n",
    "])\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "portfolio_test_data = test_data.copy()\n",
    "portfolio_test_data.sort_values(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @pytest.mark.unit\n",
    "# def test_calculate_time_weighted_returns_multi_coin_portfolio(portfolio_test_data):\n",
    "# \"\"\"Tests TWR calculation for a wallet holding both BTC and ETH with mixed imputed/actual balances.\"\"\"\n",
    "result = wpf.calculate_time_weighted_returns(portfolio_test_data)\n",
    "\n",
    "# Manual calculation combining BTC and ETH positions:\n",
    "# Jan 1: Total $150 ($50 BTC + $100 ETH, $100 transfer)\n",
    "# Feb 1: Total $250 ($50 BTC + $250 ETH, $50 transfer)\n",
    "# Oct 1: Total $195 ($70 BTC + $125 ETH)\n",
    "\n",
    "expected_twr = -0.157\n",
    "expected_days = 274  # Jan 1 to Oct 1\n",
    "expected_annual = ((1 + expected_twr) ** (365/274)) - 1  # ≈ -0.204\n",
    "\n",
    "# Assertions\n",
    "assert result.loc['wallet_a', 'days_held'] == expected_days\n",
    "assert abs(result.loc['wallet_a', 'time_weighted_return'] - expected_twr) < 0.01\n",
    "assert abs(result.loc['wallet_a', 'annualized_twr'] - expected_annual) < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfitsValidator:\n",
    "    \"\"\"\n",
    "    Validates profits DataFrame follows expected format and constraints.\n",
    "    Only validates training period data.\n",
    "    \"\"\"\n",
    "    def validate_all(self, profits_df, training_period_start, training_period_end):\n",
    "        \"\"\"Run all validation checks and return dict of results\"\"\"\n",
    "        dates = {\n",
    "            'training_period_start': pd.to_datetime(training_period_start),\n",
    "            'training_period_end': pd.to_datetime(training_period_end),\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'no_duplicates': self.check_no_duplicates(profits_df),\n",
    "            'period_boundaries': self.check_period_boundaries(profits_df, dates),\n",
    "            'no_negatives': self.check_no_negative_balances(profits_df),\n",
    "            'date_range': self.check_date_range(profits_df, dates),\n",
    "            'no_missing': self.check_no_missing_values(profits_df)\n",
    "        }\n",
    "\n",
    "    def check_no_duplicates(self, profits_df):\n",
    "        \"\"\"Check for duplicate records\"\"\"\n",
    "        deduped_df = profits_df[['coin_id', 'wallet_address', 'date']].drop_duplicates()\n",
    "        return len(profits_df) == len(deduped_df)\n",
    "\n",
    "    def check_period_boundaries(self, profits_df, dates):\n",
    "        \"\"\"Check records exist at period boundaries\"\"\"\n",
    "        profits_df['date'] = pd.to_datetime(profits_df['date'])\n",
    "        pairs = profits_df[['coin_id', 'wallet_address']].drop_duplicates()\n",
    "        n_pairs = len(pairs)\n",
    "\n",
    "        period_df = profits_df[profits_df['date'] == dates['training_period_end']]\n",
    "        period_pairs = period_df[['coin_id', 'wallet_address']].drop_duplicates()\n",
    "        return len(period_pairs) == n_pairs\n",
    "\n",
    "    def check_no_negative_balances(self, profits_df):\n",
    "        \"\"\"Check for negative USD balances\"\"\"\n",
    "        return (profits_df['usd_balance'] >= -0.1).all()\n",
    "\n",
    "    def check_date_range(self, profits_df, dates):\n",
    "        \"\"\"Verify date coverage\"\"\"\n",
    "        profits_df['date'] = pd.to_datetime(profits_df['date'])\n",
    "        return (profits_df['date'].min() >= dates['training_period_start'] and\n",
    "                profits_df['date'].max() == dates['training_period_end'])\n",
    "\n",
    "    def check_no_missing_values(self, profits_df):\n",
    "        \"\"\"Check for missing values\"\"\"\n",
    "        return not profits_df.isna().any().any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_data = [\n",
    "    # w01_multiple_coins - btc & eth (multiple transactions, multiple coins)\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w01_multiple_coins', 'date': '2024-01-01', 'usd_balance': 100, 'usd_net_transfers': 100, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w01_multiple_coins', 'date': '2024-05-01', 'usd_balance': 120, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w01_multiple_coins', 'date': '2024-10-01', 'usd_balance': 180, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w01_multiple_coins', 'date': '2024-01-01', 'usd_balance': 200, 'usd_net_transfers': 200, 'is_imputed': False},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w01_multiple_coins', 'date': '2024-05-01', 'usd_balance': 300, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w01_multiple_coins', 'date': '2024-10-01', 'usd_balance': 280, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w02_net_loss - btc (net loss)\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w02_net_loss', 'date': '2024-01-01', 'usd_balance': 300, 'usd_net_transfers': 300, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w02_net_loss', 'date': '2024-05-01', 'usd_balance': 250, 'usd_net_transfers': -100, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w02_net_loss', 'date': '2024-10-01', 'usd_balance': 100, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w03_sell_all_and_rebuy\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w03_sell_all_and_rebuy', 'date': '2024-01-01', 'usd_balance': 50, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w03_sell_all_and_rebuy', 'date': '2024-03-01', 'usd_balance': 0,  'usd_net_transfers': -50, 'is_imputed': False},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w03_sell_all_and_rebuy', 'date': '2024-08-01', 'usd_balance': 40, 'usd_net_transfers': 40, 'is_imputed': False},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w03_sell_all_and_rebuy', 'date': '2024-10-01', 'usd_balance': 42, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w04_only_period_end - btc (only final row)\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w04_only_period_end', 'date': '2024-10-01', 'usd_balance': 70, 'usd_net_transfers': 70, 'is_imputed': False},\n",
    "\n",
    "    # w04a_only_period_end_w_balance - btc\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w04a_only_period_end_w_balance', 'date': '2024-01-01', 'usd_balance': 30, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'eth', 'wallet_address': 'w04a_only_period_end_w_balance', 'date': '2024-10-01', 'usd_balance': 90, 'usd_net_transfers': 50, 'is_imputed': False},\n",
    "\n",
    "    # w04b_only_period_start_buy\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w04b_only_period_start_buy', 'date': '2024-01-01', 'usd_balance': 300, 'usd_net_transfers': 300, 'is_imputed': False},\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w04b_only_period_start_buy', 'date': '2024-10-01', 'usd_balance': 900, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w04c_only_period_start_buy_w_existing_balance\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w04c_only_period_start_buy_w_existing_balance', 'date': '2024-01-01', 'usd_balance': 350, 'usd_net_transfers': 300, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w04c_only_period_start_buy_w_existing_balance', 'date': '2024-10-01', 'usd_balance': 1050, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w04d_only_period_start_sell\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w04d_only_period_start_sell', 'date': '2024-01-01', 'usd_balance': 0, 'usd_net_transfers': -200, 'is_imputed': False},\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w04d_only_period_start_sell', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w04e_only_period_start_sell_partial\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w04e_only_period_start_sell_partial', 'date': '2024-01-01', 'usd_balance': 500, 'usd_net_transfers': -10, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w04e_only_period_start_sell_partial', 'date': '2024-10-01', 'usd_balance': 600, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w05_only_imputed - btc (only imputed rows at start and end)\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w05_only_imputed', 'date': '2024-01-01', 'usd_balance': 50, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w05_only_imputed', 'date': '2024-10-01', 'usd_balance': 70, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w06_tiny_transactions - very small transactions relative to portfolio size\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w06_tiny_transactions', 'date': '2024-01-01', 'usd_balance': 1250, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w06_tiny_transactions', 'date': '2024-02-01', 'usd_balance': 1220, 'usd_net_transfers': 1, 'is_imputed': False},\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w06_tiny_transactions', 'date': '2024-08-01', 'usd_balance': 0, 'usd_net_transfers': -350, 'is_imputed': False},\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w06_tiny_transactions', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w07_tiny_transactions2 - very small transactions relative to portfolio size\n",
    "    {'coin_id': 'floki', 'wallet_address': 'w07_tiny_transactions2', 'date': '2024-01-01', 'usd_balance': 400, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'floki', 'wallet_address': 'w07_tiny_transactions2', 'date': '2024-02-01', 'usd_balance': 1220, 'usd_net_transfers': -20, 'is_imputed': False},\n",
    "    {'coin_id': 'floki', 'wallet_address': 'w07_tiny_transactions2', 'date': '2024-08-01', 'usd_balance': 0, 'usd_net_transfers': -150, 'is_imputed': False},\n",
    "    {'coin_id': 'floki', 'wallet_address': 'w07_tiny_transactions2', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w08_offsetting_transactions - large offsetting transactions in the middle of the period\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w08_offsetting_transactions', 'date': '2024-01-01', 'usd_balance': 500, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w08_offsetting_transactions', 'date': '2024-02-01', 'usd_balance': 10400, 'usd_net_transfers': 10000, 'is_imputed': False},\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w08_offsetting_transactions', 'date': '2024-02-02', 'usd_balance': 400, 'usd_net_transfers': -10000, 'is_imputed': False},\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w08_offsetting_transactions', 'date': '2024-10-01', 'usd_balance': 750, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w09_memecoin_winner - Large swings in portfolio value\n",
    "    {'coin_id': 'floki', 'wallet_address': 'w09_memecoin_winner', 'date': '2024-01-01', 'usd_balance': 100, 'usd_net_transfers': 100, 'is_imputed': False},\n",
    "    {'coin_id': 'floki', 'wallet_address': 'w09_memecoin_winner', 'date': '2024-03-01', 'usd_balance': 250, 'usd_net_transfers': -500, 'is_imputed': False},\n",
    "    {'coin_id': 'floki', 'wallet_address': 'w09_memecoin_winner', 'date': '2024-05-01', 'usd_balance': 50, 'usd_net_transfers': -100, 'is_imputed': False},\n",
    "    {'coin_id': 'floki', 'wallet_address': 'w09_memecoin_winner', 'date': '2024-10-01', 'usd_balance': 10, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w10_memecoin_loser - Large swings in portfolio value\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w10_memecoin_loser', 'date': '2024-03-01', 'usd_balance': 250, 'usd_net_transfers': 250, 'is_imputed': False},\n",
    "    {'coin_id': 'myro', 'wallet_address': 'w10_memecoin_loser', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': -20, 'is_imputed': False},\n",
    "\n",
    "    # w11_sells_early\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w11_sells_early', 'date': '2024-03-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w11_sells_early', 'date': '2024-04-01', 'usd_balance': 250, 'usd_net_transfers': 250, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w11_sells_early', 'date': '2024-5-01', 'usd_balance': 0, 'usd_net_transfers': -300, 'is_imputed': False},\n",
    "    {'coin_id': 'btc', 'wallet_address': 'w11_sells_early', 'date': '2024-10-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "\n",
    "    # w12_buys_late\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w12_buys_late', 'date': '2024-03-01', 'usd_balance': 0, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w12_buys_late', 'date': '2024-09-01', 'usd_balance': 500, 'usd_net_transfers': 250, 'is_imputed': False},\n",
    "    {'coin_id': 'sol', 'wallet_address': 'w12_buys_late', 'date': '2024-10-01', 'usd_balance': 550, 'usd_net_transfers': 0, 'is_imputed': True},\n",
    "]\n",
    "\n",
    "test_profits_data = pd.DataFrame(profits_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits_df = test_profits_data.copy()\n",
    "training_period_start = '2024-01-01'\n",
    "training_period_end = '2024-10-01'\n",
    "\n",
    "# Validate test data format before proceeding\n",
    "validator = ProfitsValidator()\n",
    "validation_results = validator.validate_all(\n",
    "    profits_df,\n",
    "    training_period_start,\n",
    "    training_period_end\n",
    ")\n",
    "assert all(validation_results.values()), \"Test data failed validation checks.\"\n",
    "\n",
    "# Remove rows with a rounded 0 balance and 0 transfers which happens in wmo.retrieve_datasets() once validation checks are passed\n",
    "profits_df = profits_df[\n",
    "    ~((profits_df['usd_balance'] == 0) &\n",
    "    (profits_df['usd_net_transfers'] == 0))\n",
    "]\n",
    "\n",
    "# Add cash flow transfers logic\n",
    "cash_flow_profits_df = wtf.add_cash_flow_transfers_logic(profits_df)\n",
    "\n",
    "test_profits_df = cash_flow_profits_df.copy()\n",
    "test_trading_features_df = wtf.calculate_wallet_trading_features(test_profits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign wallets to create a lot of overlap\n",
    "reassign_dict = {\n",
    "    'w01_multiple_coins': 'w1',\n",
    "    'w02_net_loss': 'w2',\n",
    "    'w03_sell_all_and_rebuy': 'w2',\n",
    "    'w04_only_period_end': 'w3',\n",
    "    'w04a_only_period_end_w_balance': 'w3',\n",
    "    'w04b_only_period_start_buy': 'w2',\n",
    "    'w04c_only_period_start_buy_w_existing_balance': 'w4',\n",
    "    'w04d_only_period_start_sell': 'w4',\n",
    "    'w04e_only_period_start_sell_partial': 'w5',\n",
    "    'w05_only_imputed': 'w5',\n",
    "    'w06_tiny_transactions': 'w5',\n",
    "    'w07_tiny_transactions2': 'w2',\n",
    "    'w08_offsetting_transactions': 'w1',\n",
    "    'w09_memecoin_winner': 'w3',\n",
    "    'w10_memecoin_loser': 'w4',\n",
    "    'w11_sells_early': 'w6',\n",
    "    'w12_buys_late': 'w6'\n",
    "}\n",
    "remapped_profits_df = test_profits_data.copy()\n",
    "remapped_profits_df['wallet_address_original'] = remapped_profits_df['wallet_address']\n",
    "remapped_profits_df['wallet_address'] = remapped_profits_df['wallet_address'].map(reassign_dict)\n",
    "\n",
    "# Rest of the sequence remains unchanged\n",
    "profits_df = remapped_profits_df.copy()\n",
    "training_period_start = '2024-01-01'\n",
    "training_period_end = '2024-10-01'\n",
    "\n",
    "# Validate test data format before proceeding\n",
    "validator = ProfitsValidator()\n",
    "validation_results = validator.validate_all(\n",
    "    profits_df,\n",
    "    training_period_start,\n",
    "    training_period_end\n",
    ")\n",
    "assert all(validation_results.values()), \"Test data failed validation checks.\"\n",
    "\n",
    "# Remove rows with a rounded 0 balance and 0 transfers which happens in wmo.retrieve_datasets() once validation checks are passed\n",
    "profits_df = profits_df[\n",
    "    ~((profits_df['usd_balance'] == 0) &\n",
    "    (profits_df['usd_net_transfers'] == 0))\n",
    "]\n",
    "\n",
    "# Add cash flow transfers logic\n",
    "cash_flow_profits_df = wtf.add_cash_flow_transfers_logic(profits_df)\n",
    "\n",
    "# Confirm that all the addresses have been mapped\n",
    "expected_addresses = ['w1', 'w2', 'w3', 'w4', 'w5', 'w6']\n",
    "assert sorted(list(cash_flow_profits_df['wallet_address'].unique())) == expected_addresses\n",
    "\n",
    "test_remapped_profits_df = cash_flow_profits_df.copy()\n",
    "test_remapped_trading_features_df = wtf.calculate_wallet_trading_features(test_remapped_profits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytest\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# @pytest.mark.unit\n",
    "# def test_twr_aggregation_after_remapping(test_remapped_profits_df):\n",
    "\"\"\"\n",
    "Validates time-weighted return calculations by comparing:\n",
    "1. TWR calculated on individual coin-wallet pairs then aggregated\n",
    "2. TWR calculated on wallet-level portfolio values (treating all coins as one portfolio)\n",
    "\n",
    "Approach:\n",
    "1. First aggregate portfolio values and cash flows by date for each wallet\n",
    "2. Calculate TWR on wallet-level portfolio sequences\n",
    "3. Compare against calculate_time_weighted_returns() results\n",
    "\"\"\"\n",
    "# Step 1: Create wallet-level daily portfolio values and flows\n",
    "wallet_daily = (test_remapped_profits_df\n",
    "    .groupby(['wallet_address', 'date'])\n",
    "    .agg({\n",
    "        'usd_balance': 'sum',  # Total portfolio value\n",
    "        'usd_net_transfers': 'sum',  # Total cash flows\n",
    "        'is_imputed': 'any'  # Track if any coin was imputed\n",
    "    })\n",
    "    .reset_index()\n",
    "    .sort_values(['wallet_address', 'date']))\n",
    "\n",
    "# Step 2: Calculate wallet-level TWR metrics\n",
    "def calculate_portfolio_twr(wallet_data):\n",
    "    \"\"\"Calculate TWR for a single wallet's aggregated portfolio\"\"\"\n",
    "    # Pre-transfer balances\n",
    "    wallet_data['pre_transfer_balance'] = (\n",
    "        wallet_data['usd_balance'] - wallet_data['usd_net_transfers']\n",
    "    )\n",
    "\n",
    "    # Previous balances and holding periods\n",
    "    wallet_data['prev_balance'] = wallet_data['usd_balance'].shift()\n",
    "    wallet_data['days_held'] = (\n",
    "        wallet_data['date'].diff().dt.days.fillna(0)\n",
    "    )\n",
    "\n",
    "    # Period returns\n",
    "    wallet_data['period_return'] = np.where(\n",
    "        wallet_data['usd_net_transfers'] != 0,\n",
    "        wallet_data['pre_transfer_balance'] / wallet_data['prev_balance'],\n",
    "        wallet_data['usd_balance'] / wallet_data['prev_balance']\n",
    "    )\n",
    "    wallet_data['period_return'] = (\n",
    "        wallet_data['period_return']\n",
    "        .replace([np.inf, -np.inf], 1)\n",
    "        .fillna(1)\n",
    "    )\n",
    "\n",
    "    # Calculate weighted returns\n",
    "    wallet_data['weighted_return'] = (\n",
    "        (wallet_data['period_return'] - 1) * wallet_data['days_held']\n",
    "    )\n",
    "\n",
    "    # Total days held (calendar days between first and last observation)\n",
    "    total_days = max((wallet_data['date'].max() - wallet_data['date'].min()).days, 1)\n",
    "\n",
    "    # Calculate TWR\n",
    "    twr = (wallet_data['weighted_return'].sum() / total_days)\n",
    "\n",
    "    # Calculate annualized TWR\n",
    "    ann_twr = ((1 + twr) ** (365 / total_days)) - 1\n",
    "\n",
    "    return pd.Series({\n",
    "        'time_weighted_return': twr,\n",
    "        'days_held': total_days,\n",
    "        'annualized_twr': ann_twr\n",
    "    })\n",
    "\n",
    "# Calculate expected TWR using portfolio-level approach\n",
    "expected_twr = (wallet_daily\n",
    "    .groupby('wallet_address')\n",
    "    .apply(calculate_portfolio_twr)\n",
    "    .sort_index())\n",
    "\n",
    "# Calculate actual TWR using original function\n",
    "actual_twr = wpf.calculate_time_weighted_returns(test_remapped_profits_df).sort_index()\n",
    "\n",
    "# Compare results with tolerance for floating point arithmetic\n",
    "pd.testing.assert_frame_equal(\n",
    "    expected_twr,\n",
    "    actual_twr,\n",
    "    check_exact=False,\n",
    "    rtol=1e-5  # Allow 0.001% relative difference\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_twr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_twr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_twr_with_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_twr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_twr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
