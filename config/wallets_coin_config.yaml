# CheckpointValidation
# CoinModel Config

# CheckpointValidation
# CoinModel Cleaning
# Variables used to clean and filter raw data before training data is built
data_cleaning:

    # Market data filters
    max_initial_market_cap: 999150_000_000  # coins above this market cap as of the start of the training period will be removed from all datasets
    max_gap_days: 50  # Maximum consecutive missing days to fill in price gaps (e.g., price interpolation for gaps up to 2 days)
    min_daily_volume: 500 # Minimum average daily volume the coin must have


# Variables used for comnverting the wallet scores into coin forecasts
coin_validation_analysis:

    # Forecasting methods
    top_n: 5  # how many of the top coins of a given sort method will be included in performance assessments
    sort_method: "top_wallet_balance_pct"  # which coin wallet metric to use for coin forecast rankings


# CheckpointValidation
# CoinModel Segments
wallet_segments:

    # Scores to include as segments + metrics
    wallet_scores_path: "temp/wallet_modeling_score_dfs"
    wallet_scores: [
        # 'net_gain_winsorized_checkpoint_hybridized',
        'net_gain_winsorized_checkpoint',
    ]

    # score_segment_quantiles: [0.1, 0.3, 0.5, 0.7, 0.9]  # higher is better; how to assign wallet a score segment
    score_segment_quantiles: [0.05, 0.15, 0.5, 0.85, 0.95]  # higher is better; how to assign wallet a score segment
    training_period_cluster_groups: [2]  # which n clusters assignment from the training period to segment by

    # where to save local files
    parquet_folder: 'temp/coin_modeling_dfs'


# CheckpointValidation
# CoinModel Features
wallet_features:

    # Balance metrics params
    wallet_balance_dates: [
        # TODO: needs profits imputation logic to use dates other than modeling start/end
        '2024-11-20',
        # '2024-10-31',
    ]

    # Score features params
    usd_materiality: 20 # Wallets with volume/balances below this won't be counted in medians/distributions/etc

    # Metrics to drop based on low observed importance
    drop_trading_metrics: [
        'average_transaction'
    ]


# CheckpointValidation
# CoinModel Modeling Config
# Variables used in the generation of the validation period coin model
coin_modeling:

    # Thresholds for coin inclusion in training data
    min_cohort_wallets: 20  # how many wallets must hold a coin for the coin to be elegible for forecasting
    min_cohort_balance: 20000  # how much USD all wallets must hold for the coin to be elegible for forecasting

    # Thresholds for coin inclusion in training data
    min_market_cap: 00_000  # coins below this market cap will not be included in performance assessments
    max_market_cap: 999350_000_000  # coins above this market cap will not be included in performance assessments

    # Target variable parameters
    # target_variable: "coin_return_winsorized"
    # target_variable: "coin_return_pctile_full"
    target_variable: "coin_return_pctile"
    train_test_split: 0.2  # test size
    returns_winsorization: 0.01


    # CheckpointValidation
    # CoinModel Feature Selection
    # Params used to remove unnecessary features
    feature_selection:

        # Column patterns to remove
        drop_patterns: [
            'training_clusters|k2_cluster/*|trading/*',
            # 'score_quantile|net_gain_winsorized_checkpoint_residual/*',
            # 'score_quantile|net_gain_winsorized_checkpoint_residual/*|trading/*',
            # 'score_quantile|net_gain_winsorized_checkpoint_residual/*|balances/*',
        ]

        # Correlation/variance-based removal
        scale_before_selection: False # whether to apply variance thresholds before or after scaling data
        variance_threshold: 0.00 # features with this level of variance or less will be removed
        correlation_threshold: 1.999 # features above this correlation coefficient will be removed


    # CheckpointValidation
    # CoinModel Params
    model_type: "xgb"
    model_params:
        n_estimators: 300
        max_depth: 7
        learning_rate: 0.02
        subsample: 0.9
        gamma: 0.01
        min_child_weight: 5
        early_stopping_rounds: 20
        eval_metric: 'rmse'

        # non modeling metaparams
        random_state: 42
        n_jobs: -1

    # CheckpointValidation
    # CoinModel Grid Search
    grid_search_params:

        # enabled: True # whether to grid search
        enabled: False # whether to grid search

        # Search methodology
        n_iter: 60  # random search limit
        scoring: 'neg_root_mean_squared_error'
        n_splits: 2  # cv splits
        n_jobs: -1
        verbose_level: 3  # scikit-learn verbosity

        # Params
        param_grid:

            # # Depth and Child Weight
            # regressor__max_depth: [6, 8]
            # regressor__min_child_weight: [2,3,5,10]

            # Col/Row Sampling
            # regressor__subsample: [0.5, .6, .7, .8, .9, 1.0]
            regressor__colsample_bytree: [0.9, 1.0]

            # # Model Speed
            # regressor__tree_method: ['hist', 'approx', 'auto']
            # regressor__max_bin: [64, 128, 256]
            # regressor__gamma: [0.0, 0.1, 1.0]  # controls the minimum loss reduction needed to split a node


            # # Tree Training Speed Overrides
            # regressor__n_estimators: [150]
            # regressor__learning_rate: [0.05]

            # # Optimize for Speed
            # regressor__n_jobs: [4]  # how many models to build at once
            # regressor__nthread: [4]  # how many threads each model can use
            # # regressor__max_bin: [128]
            # # regressor__tree_method: ['hist']


    # Coin model workflow params
    score_name: "iterating"  # reference name for feature columns etc
